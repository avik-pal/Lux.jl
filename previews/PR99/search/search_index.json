{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00a4 Welcome to the documentation of Lux! What is Lux? \u00a4 Lux is a julia deep learning framework which decouples models and parameterization using deeply nested named tuples. Functional Design \u2013 Pure Functions and Deterministic Function Calls. No more implicit parameterization. Compiler and AD-friendly Neural Networks Installation Guide \u00a4 Install julia v1.6 or above . using Pkg Pkg . add ( \"Lux\" ) Resources to Get Started \u00a4 Go through the Quickstart Example . Read the introductory tutorials on julia and Lux Go through the examples sorted based on their complexity in the documentation Tip For usage related questions, please use Github Discussions or JuliaLang Discourse (machine learning domain) which allows questions and answers to be indexed. To report bugs use github issues or even better send in a pull request . Quickstart \u00a4 Tip You need to install Optimisers and Zygote if not done already. Pkg.add([\"Optimisers\", \"Zygote\"]) using Lux , Random , Optimisers , Zygote We take randomness very seriously # Seeding rng = Random . default_rng () Random . seed! ( rng , 0 ) Build the model # Construct the layer model = Chain ( BatchNorm ( 128 ), Dense ( 128 , 256 , tanh ), BatchNorm ( 256 ), Chain ( Dense ( 256 , 1 , tanh ), Dense ( 1 , 10 ))) Models don't hold parameters and states so initialize them. From there on, we just use our standard AD and Optimisers API. # Parameter and State Variables ps , st = Lux . setup ( rng , model ) .|> gpu # Dummy Input x = rand ( rng , Float32 , 128 , 2 ) |> gpu # Run the model y , st = Lux . apply ( model , x , ps , st ) # Gradients ## Pullback API to capture change in state ( l , st_ ), pb = pullback ( p -> Lux . apply ( model , x , p , st ), ps ) gs = pb (( one . ( l ), nothing ))[ 1 ] # Optimization st_opt = Optimisers . setup ( Optimisers . ADAM ( 0.0001 ), ps ) st_opt , ps = Optimisers . update ( st_opt , ps , gs ) How the documentation is structured \u00a4 Having a high-level overview of how this documentation is structured will help you know where to look for certain things. Introduction \u2013 Talks about why we wrote Lux and has pointers to frameworks in the extended julia ecosystem which might help users to get started with deep learning Tutorials \u2013 Contain tutorials of varying complexity. These contain worked examples of solving problems with Lux. Start here if you are new to Lux, or you have a particular problem class you want to model. Manual \u2013 Contains guides to some common problems encountered by users. API Reference \u2013 Contains a complete list of the functions you can use in Lux. Look here if you want to know how to use a particular function. Development Documentation \u2013 Contains information for people contributing to Lux development or writing Lux extensions. Don't worry about this section if you are using Lux to formulate and solve problems as a user. Citation \u00a4 If you found this library to be useful in academic work, then please cite: @misc { pal2022lux , author = {Pal, Avik} , title = {Lux: Explicit Parameterization of Deep Neural Networks in Julia} , year = {2022} , publisher = {GitHub} , journal = {GitHub repository} , howpublished = {\\url{https://github.com/avik-pal/Lux.jl/}} } Also consider starring our github repo","title":"Lux.jl: Explicitly Parameterized Neural Networks"},{"location":"#introduction","text":"Welcome to the documentation of Lux!","title":"Introduction"},{"location":"#what-is-lux","text":"Lux is a julia deep learning framework which decouples models and parameterization using deeply nested named tuples. Functional Design \u2013 Pure Functions and Deterministic Function Calls. No more implicit parameterization. Compiler and AD-friendly Neural Networks","title":"What is Lux?"},{"location":"#installation-guide","text":"Install julia v1.6 or above . using Pkg Pkg . add ( \"Lux\" )","title":"Installation Guide"},{"location":"#resources-to-get-started","text":"Go through the Quickstart Example . Read the introductory tutorials on julia and Lux Go through the examples sorted based on their complexity in the documentation Tip For usage related questions, please use Github Discussions or JuliaLang Discourse (machine learning domain) which allows questions and answers to be indexed. To report bugs use github issues or even better send in a pull request .","title":"Resources to Get Started"},{"location":"#quickstart","text":"Tip You need to install Optimisers and Zygote if not done already. Pkg.add([\"Optimisers\", \"Zygote\"]) using Lux , Random , Optimisers , Zygote We take randomness very seriously # Seeding rng = Random . default_rng () Random . seed! ( rng , 0 ) Build the model # Construct the layer model = Chain ( BatchNorm ( 128 ), Dense ( 128 , 256 , tanh ), BatchNorm ( 256 ), Chain ( Dense ( 256 , 1 , tanh ), Dense ( 1 , 10 ))) Models don't hold parameters and states so initialize them. From there on, we just use our standard AD and Optimisers API. # Parameter and State Variables ps , st = Lux . setup ( rng , model ) .|> gpu # Dummy Input x = rand ( rng , Float32 , 128 , 2 ) |> gpu # Run the model y , st = Lux . apply ( model , x , ps , st ) # Gradients ## Pullback API to capture change in state ( l , st_ ), pb = pullback ( p -> Lux . apply ( model , x , p , st ), ps ) gs = pb (( one . ( l ), nothing ))[ 1 ] # Optimization st_opt = Optimisers . setup ( Optimisers . ADAM ( 0.0001 ), ps ) st_opt , ps = Optimisers . update ( st_opt , ps , gs )","title":"Quickstart"},{"location":"#how-the-documentation-is-structured","text":"Having a high-level overview of how this documentation is structured will help you know where to look for certain things. Introduction \u2013 Talks about why we wrote Lux and has pointers to frameworks in the extended julia ecosystem which might help users to get started with deep learning Tutorials \u2013 Contain tutorials of varying complexity. These contain worked examples of solving problems with Lux. Start here if you are new to Lux, or you have a particular problem class you want to model. Manual \u2013 Contains guides to some common problems encountered by users. API Reference \u2013 Contains a complete list of the functions you can use in Lux. Look here if you want to know how to use a particular function. Development Documentation \u2013 Contains information for people contributing to Lux development or writing Lux extensions. Don't worry about this section if you are using Lux to formulate and solve problems as a user.","title":"How the documentation is structured"},{"location":"#citation","text":"If you found this library to be useful in academic work, then please cite: @misc { pal2022lux , author = {Pal, Avik} , title = {Lux: Explicit Parameterization of Deep Neural Networks in Julia} , year = {2022} , publisher = {GitHub} , journal = {GitHub repository} , howpublished = {\\url{https://github.com/avik-pal/Lux.jl/}} } Also consider starring our github repo","title":"Citation"},{"location":"api/core/","text":"Abstract Types \u00a4 # Lux.AbstractExplicitLayer \u2014 Type . AbstractExplicitLayer Abstract Type for all Lux Layers Users implementing their custom layer, must implement initialparameters(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) \u2013 This returns a NamedTuple containing the trainable parameters for the layer. initialstates(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) \u2013 This returns a NamedTuple containing the current state for the layer. For most layers this is typically empty. Layers that would potentially contain this include BatchNorm , LSTM , GRU etc. Optionally: parameterlength(layer::CustomAbstractExplicitLayer) \u2013 These can be automatically calculated, but it is recommended that the user defines these. statelength(layer::CustomAbstractExplicitLayer) \u2013 These can be automatically calculated, but it is recommended that the user defines these. See also AbstractExplicitContainerLayer source # Lux.AbstractExplicitContainerLayer \u2014 Type . AbstractExplicitContainerLayer { layers } <: AbstractExplicitLayer Abstract Container Type for certain Lux Layers. layers is a tuple containing fieldnames for the layer, and constructs the parameters and states using those. Users implementing their custom layer can extend the same functions as in AbstractExplicitLayer source General \u00a4 # Lux.apply \u2014 Function . apply ( model :: AbstractExplicitLayer , x , ps :: Union { ComponentArray , NamedTuple }, st :: NamedTuple ) Simply calls model(x, ps, st) source # Lux.setup \u2014 Function . setup ( rng :: AbstractRNG , l :: AbstractExplicitLayer ) Shorthand for getting the parameters and states of the layer l . Is equivalent to (initialparameters(rng, l), initialstates(rng, l)) . Warning This function is not pure, it mutates rng . source Parameters \u00a4 # Lux.initialparameters \u2014 Function . initialparameters ( rng :: AbstractRNG , l ) Generate the initial parameters of the layer l . source # Lux.parameterlength \u2014 Function . parameterlength ( l ) Return the total number of parameters of the layer l . source States \u00a4 # Lux.initialstates \u2014 Function . initialstates ( rng :: AbstractRNG , l ) Generate the initial states of the layer l . source # Lux.statelength \u2014 Function . statelength ( l ) Return the total number of states of the layer l . source # Lux.testmode \u2014 Function . testmode ( st :: NamedTuple ) Make all occurances of training in state st \u2013 Val(false) . source # Lux.trainmode \u2014 Function . trainmode ( st :: NamedTuple ) Make all occurances of training in state st \u2013 Val(true) . source # Lux.update_state \u2014 Function . update_state ( st :: NamedTuple , key :: Symbol , value ; layer_check = _default_layer_check ( key )) Recursively update all occurances of the key in the state st with the value . source Index \u00a4 Lux.AbstractExplicitContainerLayer Lux.AbstractExplicitLayer Lux.apply Lux.initialparameters Lux.initialstates Lux.parameterlength Lux.setup Lux.statelength Lux.testmode Lux.trainmode Lux.update_state","title":"Core"},{"location":"api/core/#abstract-types","text":"# Lux.AbstractExplicitLayer \u2014 Type . AbstractExplicitLayer Abstract Type for all Lux Layers Users implementing their custom layer, must implement initialparameters(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) \u2013 This returns a NamedTuple containing the trainable parameters for the layer. initialstates(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) \u2013 This returns a NamedTuple containing the current state for the layer. For most layers this is typically empty. Layers that would potentially contain this include BatchNorm , LSTM , GRU etc. Optionally: parameterlength(layer::CustomAbstractExplicitLayer) \u2013 These can be automatically calculated, but it is recommended that the user defines these. statelength(layer::CustomAbstractExplicitLayer) \u2013 These can be automatically calculated, but it is recommended that the user defines these. See also AbstractExplicitContainerLayer source # Lux.AbstractExplicitContainerLayer \u2014 Type . AbstractExplicitContainerLayer { layers } <: AbstractExplicitLayer Abstract Container Type for certain Lux Layers. layers is a tuple containing fieldnames for the layer, and constructs the parameters and states using those. Users implementing their custom layer can extend the same functions as in AbstractExplicitLayer source","title":"Abstract Types"},{"location":"api/core/#general","text":"# Lux.apply \u2014 Function . apply ( model :: AbstractExplicitLayer , x , ps :: Union { ComponentArray , NamedTuple }, st :: NamedTuple ) Simply calls model(x, ps, st) source # Lux.setup \u2014 Function . setup ( rng :: AbstractRNG , l :: AbstractExplicitLayer ) Shorthand for getting the parameters and states of the layer l . Is equivalent to (initialparameters(rng, l), initialstates(rng, l)) . Warning This function is not pure, it mutates rng . source","title":"General"},{"location":"api/core/#parameters","text":"# Lux.initialparameters \u2014 Function . initialparameters ( rng :: AbstractRNG , l ) Generate the initial parameters of the layer l . source # Lux.parameterlength \u2014 Function . parameterlength ( l ) Return the total number of parameters of the layer l . source","title":"Parameters"},{"location":"api/core/#states","text":"# Lux.initialstates \u2014 Function . initialstates ( rng :: AbstractRNG , l ) Generate the initial states of the layer l . source # Lux.statelength \u2014 Function . statelength ( l ) Return the total number of states of the layer l . source # Lux.testmode \u2014 Function . testmode ( st :: NamedTuple ) Make all occurances of training in state st \u2013 Val(false) . source # Lux.trainmode \u2014 Function . trainmode ( st :: NamedTuple ) Make all occurances of training in state st \u2013 Val(true) . source # Lux.update_state \u2014 Function . update_state ( st :: NamedTuple , key :: Symbol , value ; layer_check = _default_layer_check ( key )) Recursively update all occurances of the key in the state st with the value . source","title":"States"},{"location":"api/core/#index","text":"Lux.AbstractExplicitContainerLayer Lux.AbstractExplicitLayer Lux.apply Lux.initialparameters Lux.initialstates Lux.parameterlength Lux.setup Lux.statelength Lux.testmode Lux.trainmode Lux.update_state","title":"Index"},{"location":"api/functional/","text":"Functional Layers \u00a4 Note These functions expose the backend of Lux.jl . In the long-term we plan to move these into NNlib # Lux.dropout \u2014 Function . dropout ( rng :: AbstractRNG , x , p , q , dims , :: Val { training }) dropout ( rng :: AbstractRNG , x , mask , p , q , dims , t :: Val { training }, :: Val { update_mask }) If training then dropout is applied on x with probability p along dims . If mask is passed it is used if update_mask is false. If update_mask is true then the mask is generated and used. source # Lux.normalization \u2014 Function . normalization ( x , running_mean , running_var , scale , bias , activation , reduce_dims , :: Val { training }, momentum , epsilon ) Performs BatchNorm/GroupNorm/InstanceNorm based on input configuration Note Detailed docs are WIP source","title":"Functional"},{"location":"api/functional/#functional-layers","text":"Note These functions expose the backend of Lux.jl . In the long-term we plan to move these into NNlib # Lux.dropout \u2014 Function . dropout ( rng :: AbstractRNG , x , p , q , dims , :: Val { training }) dropout ( rng :: AbstractRNG , x , mask , p , q , dims , t :: Val { training }, :: Val { update_mask }) If training then dropout is applied on x with probability p along dims . If mask is passed it is used if update_mask is false. If update_mask is true then the mask is generated and used. source # Lux.normalization \u2014 Function . normalization ( x , running_mean , running_var , scale , bias , activation , reduce_dims , :: Val { training }, momentum , epsilon ) Performs BatchNorm/GroupNorm/InstanceNorm based on input configuration Note Detailed docs are WIP source","title":"Functional Layers"},{"location":"api/layers/","text":"Containers \u00a4 # Lux.BranchLayer \u2014 Type . BranchLayer ( layers ... ) Takes an input x and passes it through all the layers and returns a tuple of the outputs. Arguments layers : A list of N Lux layers Inputs x : Will be directly passed to each of the layers Returns Tuple: (layer_1(x), layer_2(x), ..., layer_N(x)) Updated state of the layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N Comparison with Parallel This is slightly different from Parallel(nothing, layers...) If the input is a tuple, Parallel will pass each element individually to each layer BranchLayer essentially assumes 1 input comes in and is branched out into N outputs Example An easy way to replicate an input to an NTuple is to do l = BranchLayer ( NoOpLayer (), NoOpLayer (), NoOpLayer ()) source # Lux.Chain \u2014 Type . Chain ( layers ... ; disable_optimizations :: Bool = false ) Collects multiple layers / functions to be called in sequence on a given input. Arguments layers : A list of N Lux layers Keyword Arguments disable_optimizations : Prevents any structural optimization Inputs Input x is passed sequentially to each layer, and must conform to the input requirements of the internal layers. Returns Output after sequentially applying all the layers to x Updated model states Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N Optimizations Performs a few optimizations to generate reasonable architectures. Can be disabled using keyword argument disable_optimizations . All sublayers are recursively optimized. If a function f is passed as a layer and it doesn't take 3 inputs, it is converted to a WrappedFunction ( f ) which takes only one input. If the layer is a Chain, it is flattened. NoOpLayer s are removed. If there is only 1 layer (left after optimizations), then it is returned without the Chain wrapper. If there are no layers (left after optimizations), a NoOpLayer is returned. Example c = Chain ( Dense ( 2 , 3 , relu ), BatchNorm ( 3 ), Dense ( 3 , 2 )) source # Lux.PairwiseFusion \u2014 Type . PairwiseFusion ( connection , layers ... ) x1 \u2192 layer1 \u2192 y1 \u2198 connection \u2192 layer2 \u2192 y2 \u2198 x2 \u2197 connection \u2192 layer3 \u2192 y3 x3 \u2197 Arguments connection : Takes 2 inputs and combines them layers : AbstractExplicitLayer s Inputs Layer behaves differently based on input type: If the input x is a tuple of length N + 1 , then the layers must be a tuple of length N . The computation is as follows y = x [ 1 ] for i in 1 : N y = connection ( x [ i + 1 ], layers [ i ]( y )) end Any other kind of input y = x for i in 1 : N y = connection ( x , layers [ i ]( y )) end Returns See Inputs section for how the return value is computed Updated model state for all the contained layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N source # Lux.Parallel \u2014 Type . Parallel ( connection , layers ... ) Create a layer which passes an input to each path in layers , before reducing the output with connection . Arguments layers : A list of N Lux layers connection : An N -argument function that is called after passing the input through each layer. If connection = nothing , we return a tuple Parallel(nothing, f, g)(x, y) = (f(x), g(y)) Inputs x : If x is not a tuple, then return is computed as connection([l(x) for l in layers]...) . Else one is passed to each layer, thus Parallel(+, f, g)(x, y) = f(x) + g(y) . Returns See the Inputs section for how the output is computed Updated state of the layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N See also SkipConnection which is Parallel with one identity. source # Lux.SkipConnection \u2014 Type . SkipConnection ( layer , connection ) Create a skip connection which consists of a layer or Chain of consecutive layers and a shortcut connection linking the block's input to the output through a user-supplied 2-argument callable. The first argument to the callable will be propagated through the given layer while the second is the unchanged, \"skipped\" input. The simplest \"ResNet\"-type connection is just SkipConnection(layer, +) . Arguments layer : Layer or Chain of layers to be applied to the input connection : A 2-argument function that takes layer(input) and the input Inputs x : Will be passed directly to layer Returns Output of connection(layer(input), input) Updated state of layer Parameters Parameters of layer States States of layer See Parallel for a more general implementation. source Convolutional Layers \u00a4 # Lux.Conv \u2014 Type . Conv ( k :: NTuple { N , Integer }, ( in_chs => out_chs ) :: Pair { <: Integer , <: Integer }, activation = identity ; init_weight = glorot_uniform , init_bias = zeros32 , stride = 1 , pad = 0 , dilation = 1 , groups = 1 , use_bias = true ) Standard convolutional layer. Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100 x 100 RGB image would be a 100 x 100 x 3 x 1 array, and a batch of 50 would be a 100 x 100 x 3 x 50 array. This has N = 2 spatial dimensions, and needs a kernel size like (5, 5) , a 2-tuple of integers. To take convolutions along N feature dimensions, this layer expects as input an array with ndims(x) == N + 2 , where size(x, N + 1) == in_chs is the number of input channels, and size(x, ndims(x)) is the number of observations in a batch. Note Frameworks like Pytorch perform cross-correlation in their convolution layers Arguments k : Tuple of integers specifying the size of the convolutional kernel. Eg, for 2D convolutions length(k) == 2 in_chs : Number of input channels out_chs : Number of input and output channels activation : Activation Function Keyword Arguments init_weight : Controls the initialization of the weight parameter init_bias : Controls the initialization of the bias parameter stride : Should each be either single integer, or a tuple with N integers dilation : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. groups : Expected to be an Int . It specifies the number of groups to divide a convolution into (set groups = in_chs for Depthwise Convolutions). in_chs and out_chs must be divisible by groups . use_bias : Trainable bias can be disabled entirely by setting this to false . Inputs x : Data satisfying ndims(x) == N + 2 && size(x, N - 1) == in_chs , i.e. size(x) = (I_N, ..., I_1, C_in, N) Returns Output of the convolution y of size (O_N, ..., O_1, C_out, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() Parameters weight : Convolution kernel bias : Bias (present if bias=true ) source Dropout Layers \u00a4 # Lux.Dropout \u2014 Type . Dropout ( p ; dims =: ) Dropout layer. Arguments p : Probability of Dropout (if p = 0 then NoOpLayer is returned) Keyword Arguments To apply dropout along certain dimension(s), specify the dims keyword. e.g. Dropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout). Inputs x : Must be an AbstractArray Returns x with dropout mask applied if training=Val(true) else just x State with updated rng States rng : Pseudo Random Number Generator training : Used to check if training/inference mode Call Lux.testmode to switch to test mode. See also VariationalHiddenDropout source # Lux.VariationalHiddenDropout \u2014 Type . VariationalHiddenDropout ( p ; dims =: ) VariationalHiddenDropout layer. The only difference from Dropout is that the mask is retained until Lux.update_state(l, :update_mask, Val(true)) is called. Arguments p : Probability of Dropout (if p = 0 then NoOpLayer is returned) Keyword Arguments To apply dropout along certain dimension(s), specify the dims keyword. e.g. VariationalHiddenDropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout). Inputs x : Must be an AbstractArray Returns x with dropout mask applied if training=Val(true) else just x State with updated rng States rng : Pseudo Random Number Generator training : Used to check if training/inference mode mask : Dropout mask. Initilly set to nothing. After every run, contains the mask applied in that call update_mask : Stores whether new mask needs to be generated in the current call Call Lux.testmode to switch to test mode. See also Dropout source Pooling Layers \u00a4 # Lux.AdaptiveMaxPool \u2014 Type . AdaptiveMaxPool ( out :: NTuple ) Adaptive Max Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out . Arguments out : Size of the first N dimensions for the output Inputs x : Expects as input an array with ndims(x) == N+2 , i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out) . Returns Output of size (out..., C, N) Empty NamedTuple() See also MaxPool , AdaptiveMeanPool . source # Lux.AdaptiveMeanPool \u2014 Type . AdaptiveMeanPool ( out :: NTuple ) Adaptive Mean Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out . Arguments out : Size of the first N dimensions for the output Inputs x : Expects as input an array with ndims(x) == N+2 , i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out) . Returns Output of size (out..., C, N) Empty NamedTuple() See also MeanPool , AdaptiveMaxPool . source # Lux.GlobalMaxPool \u2014 Type . GlobalMaxPool () Global Mean Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing max pooling on the complete (w,h)-shaped feature maps. Inputs x : Data satisfying ndims(x) > 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (1, ..., 1, C, N) Empty NamedTuple() See also MaxPool , AdaptiveMaxPool , GlobalMeanPool source # Lux.GlobalMeanPool \u2014 Type . GlobalMeanPool () Global Mean Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing mean pooling on the complete (w,h)-shaped feature maps. Inputs x : Data satisfying ndims(x) > 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (1, ..., 1, C, N) Empty NamedTuple() See also MeanPool , AdaptiveMeanPool , GlobalMaxPool source # Lux.MaxPool \u2014 Type . MaxPool ( window :: NTuple ; pad = 0 , stride = window ) Max pooling layer, which replaces all pixels in a block of size window with the maximum value. Arguments window : Tuple of integers specifying the size of the window. Eg, for 2D pooling length(window) == 2 Keyword Arguments stride : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. Inputs x : Data satisfying ndims(x) == N + 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (O_N, ..., O_1, C, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() See also Conv , MeanPool , GlobalMaxPool , AdaptiveMaxPool source # Lux.MeanPool \u2014 Type . MeanPool ( window :: NTuple ; pad = 0 , stride = window ) Mean pooling layer, which replaces all pixels in a block of size window with the mean value. Arguments window : Tuple of integers specifying the size of the window. Eg, for 2D pooling length(window) == 2 Keyword Arguments stride : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. Inputs x : Data satisfying ndims(x) == N + 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (O_N, ..., O_1, C, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() See also Conv , MaxPool , GlobalMeanPool , AdaptiveMeanPool source Recurrent Layers \u00a4 Warning Recurrent Layers API should be considered Experimental at this point # Lux.GRUCell \u2014 Type . GRUCell (( in_dims , out_dims ) :: Pair { <: Int , <: Int }; init_weight :: Tuple { Function , Function , Function } = ( glorot_uniform , glorot_uniform , glorot_uniform ), init_bias :: Tuple { Function , Function , Function } = ( zeros32 , zeros32 , zeros32 ), init_state :: Function = zeros32 ) Gated Recurrent Unit (GRU) Cell \\[ \\begin{align} r &= \\sigma(W_{ir} \\times x + W_{hr} \\times h_{prev} + b_{hr})\\\\ z &= \\sigma(W_{iz} \\times x + W_{hz} \\times h_{prev} + b_{hz})\\\\ n &= \\sigma(W_{in} \\times x + b_{in} + r \\cdot (W_{hn} \\times h_{prev} + b_{hn}))\\\\ h_{new} &= (1 - z) \\cdot n + z \\cdot h_{prev} \\end{align} \\] Arguments in_dims : Input Dimension out_dims : Output (Hidden State) Dimension init_bias : Initializer for bias. Must be a tuple containing 3 functions init_weight : Initializer for weight. Must be a tuple containing 3 functions init_state : Initializer for hidden state Inputs Case 1: Only a single input x of shape (in_dims, batch_size) - Creates a hidden state using init_state and proceeds to Case 2. Case 2: Tuple ( x , h ) is provided, then the updated hidden state is returned. Returns New hidden state \\(h_{new}\\) of shape (out_dims, batch_size) Updated model state Parameters weight_i : Concatenated Weights to map from input space \\(\\\\left\\\\{ W_{ir}, W_{iz}, W_{in} \\\\right\\\\}\\) . weight_h : Concatenated Weights to map from hidden space \\(\\\\left\\\\{ W_{hr}, W_{hz}, W_{hn} \\\\right\\\\}\\) bias_i : Bias vector ( \\(b_{in}\\) ) bias_h : Concatenated Bias vector for the hidden space \\(\\\\left\\\\{ b_{hr}, b_{hz}, b_{hn} \\\\right\\\\}\\) States rng : Controls the randomness (if any) in the initial state generation source # Lux.LSTMCell \u2014 Type . LSTMCell ( in_dims => out_dims ; init_weight = ( glorot_uniform , glorot_uniform , glorot_uniform , glorot_uniform ), init_bias = ( zeros32 , zeros32 , ones32 , zeros32 ), init_state = zeros32 ) Long Short-Term (LSTM) Cell \\[ \\begin{align} i &= \\sigma(W_{ii} \\times x + W_{hi} \\times h_{prev} + b_{i})\\\\ f &= \\sigma(W_{if} \\times x + W_{hf} \\times h_{prev} + b_{f})\\\\ g &= tanh(W_{ig} \\times x + W_{hg} \\times h_{prev} + b_{g})\\\\ o &= \\sigma(W_{io} \\times x + W_{ho} \\times h_{prev} + b_{o})\\\\ c_{new} &= f \\cdot c_{prev} + i \\cdot g\\\\ h_{new} &= o \\cdot tanh(c_{new}) \\end{align} \\] Arguments in_dims : Input Dimension out_dims : Output (Hidden State & Memory) Dimension init_bias : Initializer for bias. Must be a tuple containing 4 functions init_weight : Initializer for weight. Must be a tuple containing 4 functions init_state : Initializer for hidden state and memory Inputs Case 1: Only a single input x of shape (in_dims, batch_size) - Creates a hidden state and memory using init_state and proceeds to Case 2. Case 2: Tuple ( x , h , c ) is provided, then the updated hidden state and memory is returned. Returns Tuple Containing New hidden state \\(h_{new}\\) of shape (out_dims, batch_size) Updated Memory \\(c_{new}\\) of shape (out_dims, batch_size) Updated model state Parameters weight_i : Concatenated Weights to map from input space \\(\\left\\{ W_{ii}, W_{if}, W_{ig}, W_{io} \\right\\}\\) . weight_h : Concatenated Weights to map from hidden space \\(\\left\\{ W_{hi}, W_{hf}, W_{hg}, W_{ho} \\right\\}\\) bias : Bias vector States rng : Controls the randomness (if any) in the initial state generation source # Lux.RNNCell \u2014 Type . RNNCell ( in_dims => out_dims , activation = tanh ; bias :: Bool = true , init_bias = zeros32 , init_weight = glorot_uniform , init_state = ones32 ) An Elman RNNCell cell with activation (typically set to tanh or relu ). \\(h_{new} = activation(weight_{ih} \\times x + weight_{hh} \\times h_{prev} + bias)\\) Arguments in_dims : Input Dimension out_dims : Output (Hidden State) Dimension activation : Activation function bias : Set to false to deactivate bias init_bias : Initializer for bias init_weight : Initializer for weight init_state : Initializer for hidden state Inputs Case 1: Only a single input x of shape (in_dims, batch_size) - Creates a hidden state using init_state and proceeds to Case 2. Case 2: Tuple ( x , h ) is provided, then the updated hidden state is returned. Returns New hidden state \\(h_{new}\\) of shape (out_dims, batch_size) Updated model state Parameters weight_ih : Maps the input to the hidden state. weight_hh : Maps the hidden state to the hidden state. bias : Bias vector (not present if bias=false ) States rng : Controls the randomness (if any) in the initial state generation source Linear Layers \u00a4 # Lux.Dense \u2014 Type . Dense ( in_dims => out_dims , activation = identity ; init_weight = glorot_uniform , init_bias = zeros32 , bias :: Bool = true ) Create a traditional fully connected layer, whose forward pass is given by: y = activation.(weight * x .+ bias) Arguments in_dims : number of input dimensions out_dims : number of output dimensions activation : activation function Keyword Arguments init_weight : initializer for the weight matrix ( weight = init_weight(rng, out_dims, in_dims) ) init_bias : initializer for the bias vector (ignored if bias=false ) bias : whether to include a bias vector Input x must be a Matrix of size in_dims \u00d7 B or a Vector of length in_dims Returns Matrix of size out_dims \u00d7 B or a Vector of length out_dims Empty NamedTuple() Parameters weight : Weight Matrix of size out_dims \u00d7 in_dims bias : Bias of size out_dims \u00d7 1 (present if bias=true ) source # Lux.Scale \u2014 Type . Scale ( dims , activation = identity ; init_weight = ones32 , init_bias = zeros32 , bias :: Bool = true ) Create a Sparsely Connected Layer with a very specific structure (only Diagonal Elements are non-zero). The forward pass is given by: y = activation.(weight .* x .+ bias) Arguments dims : size of the learnable scale and bias parameters. activation : activation function Keyword Arguments init_weight : initializer for the weight matrix ( weight = init_weight(rng, out_dims, in_dims) ) init_bias : initializer for the bias vector (ignored if bias=false ) bias : whether to include a bias vector Input x must be an Array of size (dims..., B) or (dims...[0], ..., dims[k]) for k \u2264 size(dims) Returns Array of size (dims..., B) or (dims...[0], ..., dims[k]) for k \u2264 size(dims) Empty NamedTuple() Parameters weight : Weight Array of size (dims...) bias : Bias of size (dims...) Lux 0.4.3 Scale with multiple dimensions requires at least Lux 0.4.3. source Misc. Helper Layers \u00a4 # Lux.ActivationFunction \u2014 Function . ActivationFunction ( f ) Broadcast f on the input. Arguments f : Activation function Inputs x : Any array type s.t. f can be broadcasted over it Returns Broadcasted Activation f.(x) Empty NamedTuple() Warning This layer is deprecated and will be removed in v0.5. Use WrappedFunction with manual broadcasting source # Lux.FlattenLayer \u2014 Type . FlattenLayer () Flattens the passed array into a matrix. Inputs x : AbstractArray Returns AbstractMatrix of size (:, size(x, ndims(x))) Empty NamedTuple() source # Lux.NoOpLayer \u2014 Type . NoOpLayer () As the name suggests does nothing but allows pretty printing of layers. Whatever input is passed is returned. source # Lux.ReshapeLayer \u2014 Type . ReshapeLayer ( dims ) Reshapes the passed array to have a size of (dims..., :) Arguments dims : The new dimensions of the array (excluding the last dimension). Inputs x : AbstractArray of any shape which can be reshaped in (dims..., size(x, ndims(x))) Returns AbstractArray of size (dims..., size(x, ndims(x))) Empty NamedTuple() source # Lux.SelectDim \u2014 Type . SelectDim ( dim , i ) Return a view of all the data of the input x where the index for dimension dim equals i . Equivalent to view(x,:,:,...,i,:,:,...) where i is in position d . Arguments dim : Dimension for indexing i : Index for dimension dim Inputs x : AbstractArray that can be indexed with view(x,:,:,...,i,:,:,...) Returns view(x,:,:,...,i,:,:,...) where i is in position d Empty NamedTuple() source # Lux.WrappedFunction \u2014 Type . WrappedFunction ( f ) Wraps a stateless and parameter less function. Might be used when a function is added to Chain . For example, Chain(x -> relu.(x)) would not work and the right thing to do would be Chain((x, ps, st) -> (relu.(x), st)) . An easier thing to do would be Chain(WrappedFunction(Base.Fix1(broadcast, relu))) Arguments f::Function : A stateless and parameterless function Inputs x : s.t hasmethod(f, (typeof(x),)) is true Returns Output of f(x) Empty NamedTuple() source Normalization Layers \u00a4 # Lux.BatchNorm \u2014 Type . BatchNorm ( chs :: Integer , activation = identity ; init_bias = zeros32 , init_scale = ones32 , affine = true , track_stats = true , epsilon = 1f-5 , momentum = 0.1f0 ) Batch Normalization layer. BatchNorm computes the mean and variance for each D_1 \u00d7 ... \u00d7 D_{N-2} \u00d7 1 \u00d7 D_N input slice and normalises the input accordingly. Arguments chs : Size of the channel dimension in your data. Given an array with N dimensions, call the N-1 th the channel dimension. For a batch of feature vectors this is just the data dimension, for WHCN images it's the usual channel dimension. activation : After normalisation, elementwise activation activation is applied. Keyword Arguments If affine=true , it also applies a shift and a rescale to the input through to learnable per-channel bias and scale parameters. init_bias : Controls how the bias is initiliazed init_scale : Controls how the scale is initiliazed If track_stats=true , accumulates mean and variance statistics in training phase that will be used to renormalize the input in test phase. epsilon : a value added to the denominator for numerical stability momentum : the value used for the running_mean and running_var computation Inputs x : Array where size(x, N - 1) = chs and ndims(x) > 2 Returns y : Normalized Array Update model state Parameters affine=true bias : Bias of shape (chs,) scale : Scale of shape (chs,) affine=false - Empty NamedTuple() States Statistics if track_stats=true running_mean : Running mean of shape (chs,) running_var : Running variance of shape (chs,) Statistics if track_stats=false running_mean : nothing running_var : nothing training : Used to check if training/inference mode Use Lux.testmode during inference. Example m = Chain ( Dense ( 784 => 64 ), BatchNorm ( 64 , relu ), Dense ( 64 => 10 ), BatchNorm ( 10 )) Warning Passing a batch size of 1, during training will result in NaNs. See also GroupNorm source # Lux.GroupNorm \u2014 Type . GroupNorm ( chs :: Integer , groups :: Integer , activation = identity ; init_bias = zeros32 , init_scale = ones32 , affine = true , track_stats = true , epsilon = 1f-5 , momentum = 0.1f0 ) Group Normalization layer. Arguments chs : Size of the channel dimension in your data. Given an array with N dimensions, call the N-1 th the channel dimension. For a batch of feature vectors this is just the data dimension, for WHCN images it's the usual channel dimension. groups is the number of groups along which the statistics are computed. The number of channels must be an integer multiple of the number of groups. activation : After normalisation, elementwise activation activation is applied. Keyword Arguments If affine=true , it also applies a shift and a rescale to the input through to learnable per-channel bias and scale parameters. init_bias : Controls how the bias is initiliazed init_scale : Controls how the scale is initiliazed If track_stats=true , accumulates mean and variance statistics in training phase that will be used to renormalize the input in test phase. (This feature has been deprecated and will be removed in v0.5) epsilon : a value added to the denominator for numerical stability momentum : the value used for the running_mean and running_var computation (This feature has been deprecated and will be removed in v0.5) Inputs x : Array where size(x, N - 1) = chs and ndims(x) > 2 Returns y : Normalized Array Update model state Parameters affine=true bias : Bias of shape (chs,) scale : Scale of shape (chs,) affine=false - Empty NamedTuple() States Statistics if track_stats=true (DEPRECATED) running_mean : Running mean of shape (groups,) running_var : Running variance of shape (groups,) Statistics if track_stats=false running_mean : nothing running_var : nothing training : Used to check if training/inference mode Use Lux.testmode during inference. Example m = Chain ( Dense ( 784 => 64 ), GroupNorm ( 64 , 4 , relu ), Dense ( 64 => 10 ), GroupNorm ( 10 , 5 )) Warning GroupNorm doesn't have CUDNN support. The GPU fallback is not very efficient. See also BatchNorm source # Lux.WeightNorm \u2014 Type . WeightNorm ( layer :: AbstractExplicitLayer , which_params :: NTuple { N , Symbol }, dims :: Union { Tuple , Nothing } = nothing ) Applies weight normalization to a parameter in the given layer. \\(w = g\\frac{v}{\\|v\\|}\\) Weight normalization is a reparameterization that decouples the magnitude of a weight tensor from its direction. This updates the parameters in which_params (e.g. weight ) using two parameters: one specifying the magnitude (e.g. weight_g ) and one specifying the direction (e.g. weight_v ). Arguments layer whose parameters are being reparameterized which_params : parameter names for the parameters being reparameterized By default, a norm over the entire array is computed. Pass dims to modify the dimension. Inputs x : Should be of valid type for input to layer Returns Output from layer Updated model state of layer Parameters normalized : Parameters of layer that are being normalized unnormalized : Parameters of layer that are not being normalized States Same as that of layer source Upsampling \u00a4 # Lux.Upsample \u2014 Type . Upsample ( mode = :nearest ; [ scale , size ]) Upsample ( scale , mode = :nearest ) Upsampling Layer. Layer Construction Option 1 mode : Set to :nearest , :linear , :bilinear or :trilinear Exactly one of two keywords must be specified: If scale is a number, this applies to all but the last two dimensions (channel and batch) of the input. It may also be a tuple, to control dimensions individually. Alternatively, keyword size accepts a tuple, to directly specify the leading dimensions of the output. Option 2 If scale is a number, this applies to all but the last two dimensions (channel and batch) of the input. It may also be a tuple, to control dimensions individually. mode : Set to :nearest , :bilinear or :trilinear Currently supported upsampling mode s and corresponding NNlib's methods are: :nearest -> NNlib.upsample_nearest :bilinear -> NNlib.upsample_bilinear :trilinear -> NNlib.upsample_trilinear Inputs x : For the input dimensions look into the documentation for the corresponding NNlib function As a rule of thumb, :nearest should work with arrays of arbitrary dimensions :bilinear works with 4D Arrays :trilinear works with 5D Arrays Returns Upsampled Input of size size or of size (I_1 x scale[1], ..., I_N x scale[N], C, N) Empty NamedTuple() source Index \u00a4 Lux.AdaptiveMaxPool Lux.AdaptiveMeanPool Lux.BatchNorm Lux.BranchLayer Lux.Chain Lux.Conv Lux.Dense Lux.Dropout Lux.FlattenLayer Lux.GRUCell Lux.GlobalMaxPool Lux.GlobalMeanPool Lux.GroupNorm Lux.LSTMCell Lux.MaxPool Lux.MeanPool Lux.NoOpLayer Lux.PairwiseFusion Lux.Parallel Lux.RNNCell Lux.ReshapeLayer Lux.Scale Lux.SelectDim Lux.SkipConnection Lux.Upsample Lux.VariationalHiddenDropout Lux.WeightNorm Lux.WrappedFunction Lux.ActivationFunction","title":"Layers"},{"location":"api/layers/#containers","text":"# Lux.BranchLayer \u2014 Type . BranchLayer ( layers ... ) Takes an input x and passes it through all the layers and returns a tuple of the outputs. Arguments layers : A list of N Lux layers Inputs x : Will be directly passed to each of the layers Returns Tuple: (layer_1(x), layer_2(x), ..., layer_N(x)) Updated state of the layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N Comparison with Parallel This is slightly different from Parallel(nothing, layers...) If the input is a tuple, Parallel will pass each element individually to each layer BranchLayer essentially assumes 1 input comes in and is branched out into N outputs Example An easy way to replicate an input to an NTuple is to do l = BranchLayer ( NoOpLayer (), NoOpLayer (), NoOpLayer ()) source # Lux.Chain \u2014 Type . Chain ( layers ... ; disable_optimizations :: Bool = false ) Collects multiple layers / functions to be called in sequence on a given input. Arguments layers : A list of N Lux layers Keyword Arguments disable_optimizations : Prevents any structural optimization Inputs Input x is passed sequentially to each layer, and must conform to the input requirements of the internal layers. Returns Output after sequentially applying all the layers to x Updated model states Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N Optimizations Performs a few optimizations to generate reasonable architectures. Can be disabled using keyword argument disable_optimizations . All sublayers are recursively optimized. If a function f is passed as a layer and it doesn't take 3 inputs, it is converted to a WrappedFunction ( f ) which takes only one input. If the layer is a Chain, it is flattened. NoOpLayer s are removed. If there is only 1 layer (left after optimizations), then it is returned without the Chain wrapper. If there are no layers (left after optimizations), a NoOpLayer is returned. Example c = Chain ( Dense ( 2 , 3 , relu ), BatchNorm ( 3 ), Dense ( 3 , 2 )) source # Lux.PairwiseFusion \u2014 Type . PairwiseFusion ( connection , layers ... ) x1 \u2192 layer1 \u2192 y1 \u2198 connection \u2192 layer2 \u2192 y2 \u2198 x2 \u2197 connection \u2192 layer3 \u2192 y3 x3 \u2197 Arguments connection : Takes 2 inputs and combines them layers : AbstractExplicitLayer s Inputs Layer behaves differently based on input type: If the input x is a tuple of length N + 1 , then the layers must be a tuple of length N . The computation is as follows y = x [ 1 ] for i in 1 : N y = connection ( x [ i + 1 ], layers [ i ]( y )) end Any other kind of input y = x for i in 1 : N y = connection ( x , layers [ i ]( y )) end Returns See Inputs section for how the return value is computed Updated model state for all the contained layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N source # Lux.Parallel \u2014 Type . Parallel ( connection , layers ... ) Create a layer which passes an input to each path in layers , before reducing the output with connection . Arguments layers : A list of N Lux layers connection : An N -argument function that is called after passing the input through each layer. If connection = nothing , we return a tuple Parallel(nothing, f, g)(x, y) = (f(x), g(y)) Inputs x : If x is not a tuple, then return is computed as connection([l(x) for l in layers]...) . Else one is passed to each layer, thus Parallel(+, f, g)(x, y) = f(x) + g(y) . Returns See the Inputs section for how the output is computed Updated state of the layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N See also SkipConnection which is Parallel with one identity. source # Lux.SkipConnection \u2014 Type . SkipConnection ( layer , connection ) Create a skip connection which consists of a layer or Chain of consecutive layers and a shortcut connection linking the block's input to the output through a user-supplied 2-argument callable. The first argument to the callable will be propagated through the given layer while the second is the unchanged, \"skipped\" input. The simplest \"ResNet\"-type connection is just SkipConnection(layer, +) . Arguments layer : Layer or Chain of layers to be applied to the input connection : A 2-argument function that takes layer(input) and the input Inputs x : Will be passed directly to layer Returns Output of connection(layer(input), input) Updated state of layer Parameters Parameters of layer States States of layer See Parallel for a more general implementation. source","title":"Containers"},{"location":"api/layers/#convolutional-layers","text":"# Lux.Conv \u2014 Type . Conv ( k :: NTuple { N , Integer }, ( in_chs => out_chs ) :: Pair { <: Integer , <: Integer }, activation = identity ; init_weight = glorot_uniform , init_bias = zeros32 , stride = 1 , pad = 0 , dilation = 1 , groups = 1 , use_bias = true ) Standard convolutional layer. Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100 x 100 RGB image would be a 100 x 100 x 3 x 1 array, and a batch of 50 would be a 100 x 100 x 3 x 50 array. This has N = 2 spatial dimensions, and needs a kernel size like (5, 5) , a 2-tuple of integers. To take convolutions along N feature dimensions, this layer expects as input an array with ndims(x) == N + 2 , where size(x, N + 1) == in_chs is the number of input channels, and size(x, ndims(x)) is the number of observations in a batch. Note Frameworks like Pytorch perform cross-correlation in their convolution layers Arguments k : Tuple of integers specifying the size of the convolutional kernel. Eg, for 2D convolutions length(k) == 2 in_chs : Number of input channels out_chs : Number of input and output channels activation : Activation Function Keyword Arguments init_weight : Controls the initialization of the weight parameter init_bias : Controls the initialization of the bias parameter stride : Should each be either single integer, or a tuple with N integers dilation : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. groups : Expected to be an Int . It specifies the number of groups to divide a convolution into (set groups = in_chs for Depthwise Convolutions). in_chs and out_chs must be divisible by groups . use_bias : Trainable bias can be disabled entirely by setting this to false . Inputs x : Data satisfying ndims(x) == N + 2 && size(x, N - 1) == in_chs , i.e. size(x) = (I_N, ..., I_1, C_in, N) Returns Output of the convolution y of size (O_N, ..., O_1, C_out, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() Parameters weight : Convolution kernel bias : Bias (present if bias=true ) source","title":"Convolutional Layers"},{"location":"api/layers/#dropout-layers","text":"# Lux.Dropout \u2014 Type . Dropout ( p ; dims =: ) Dropout layer. Arguments p : Probability of Dropout (if p = 0 then NoOpLayer is returned) Keyword Arguments To apply dropout along certain dimension(s), specify the dims keyword. e.g. Dropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout). Inputs x : Must be an AbstractArray Returns x with dropout mask applied if training=Val(true) else just x State with updated rng States rng : Pseudo Random Number Generator training : Used to check if training/inference mode Call Lux.testmode to switch to test mode. See also VariationalHiddenDropout source # Lux.VariationalHiddenDropout \u2014 Type . VariationalHiddenDropout ( p ; dims =: ) VariationalHiddenDropout layer. The only difference from Dropout is that the mask is retained until Lux.update_state(l, :update_mask, Val(true)) is called. Arguments p : Probability of Dropout (if p = 0 then NoOpLayer is returned) Keyword Arguments To apply dropout along certain dimension(s), specify the dims keyword. e.g. VariationalHiddenDropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout). Inputs x : Must be an AbstractArray Returns x with dropout mask applied if training=Val(true) else just x State with updated rng States rng : Pseudo Random Number Generator training : Used to check if training/inference mode mask : Dropout mask. Initilly set to nothing. After every run, contains the mask applied in that call update_mask : Stores whether new mask needs to be generated in the current call Call Lux.testmode to switch to test mode. See also Dropout source","title":"Dropout Layers"},{"location":"api/layers/#pooling-layers","text":"# Lux.AdaptiveMaxPool \u2014 Type . AdaptiveMaxPool ( out :: NTuple ) Adaptive Max Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out . Arguments out : Size of the first N dimensions for the output Inputs x : Expects as input an array with ndims(x) == N+2 , i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out) . Returns Output of size (out..., C, N) Empty NamedTuple() See also MaxPool , AdaptiveMeanPool . source # Lux.AdaptiveMeanPool \u2014 Type . AdaptiveMeanPool ( out :: NTuple ) Adaptive Mean Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out . Arguments out : Size of the first N dimensions for the output Inputs x : Expects as input an array with ndims(x) == N+2 , i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out) . Returns Output of size (out..., C, N) Empty NamedTuple() See also MeanPool , AdaptiveMaxPool . source # Lux.GlobalMaxPool \u2014 Type . GlobalMaxPool () Global Mean Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing max pooling on the complete (w,h)-shaped feature maps. Inputs x : Data satisfying ndims(x) > 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (1, ..., 1, C, N) Empty NamedTuple() See also MaxPool , AdaptiveMaxPool , GlobalMeanPool source # Lux.GlobalMeanPool \u2014 Type . GlobalMeanPool () Global Mean Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing mean pooling on the complete (w,h)-shaped feature maps. Inputs x : Data satisfying ndims(x) > 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (1, ..., 1, C, N) Empty NamedTuple() See also MeanPool , AdaptiveMeanPool , GlobalMaxPool source # Lux.MaxPool \u2014 Type . MaxPool ( window :: NTuple ; pad = 0 , stride = window ) Max pooling layer, which replaces all pixels in a block of size window with the maximum value. Arguments window : Tuple of integers specifying the size of the window. Eg, for 2D pooling length(window) == 2 Keyword Arguments stride : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. Inputs x : Data satisfying ndims(x) == N + 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (O_N, ..., O_1, C, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() See also Conv , MeanPool , GlobalMaxPool , AdaptiveMaxPool source # Lux.MeanPool \u2014 Type . MeanPool ( window :: NTuple ; pad = 0 , stride = window ) Mean pooling layer, which replaces all pixels in a block of size window with the mean value. Arguments window : Tuple of integers specifying the size of the window. Eg, for 2D pooling length(window) == 2 Keyword Arguments stride : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. Inputs x : Data satisfying ndims(x) == N + 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (O_N, ..., O_1, C, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() See also Conv , MaxPool , GlobalMeanPool , AdaptiveMeanPool source","title":"Pooling Layers"},{"location":"api/layers/#recurrent-layers","text":"Warning Recurrent Layers API should be considered Experimental at this point # Lux.GRUCell \u2014 Type . GRUCell (( in_dims , out_dims ) :: Pair { <: Int , <: Int }; init_weight :: Tuple { Function , Function , Function } = ( glorot_uniform , glorot_uniform , glorot_uniform ), init_bias :: Tuple { Function , Function , Function } = ( zeros32 , zeros32 , zeros32 ), init_state :: Function = zeros32 ) Gated Recurrent Unit (GRU) Cell \\[ \\begin{align} r &= \\sigma(W_{ir} \\times x + W_{hr} \\times h_{prev} + b_{hr})\\\\ z &= \\sigma(W_{iz} \\times x + W_{hz} \\times h_{prev} + b_{hz})\\\\ n &= \\sigma(W_{in} \\times x + b_{in} + r \\cdot (W_{hn} \\times h_{prev} + b_{hn}))\\\\ h_{new} &= (1 - z) \\cdot n + z \\cdot h_{prev} \\end{align} \\] Arguments in_dims : Input Dimension out_dims : Output (Hidden State) Dimension init_bias : Initializer for bias. Must be a tuple containing 3 functions init_weight : Initializer for weight. Must be a tuple containing 3 functions init_state : Initializer for hidden state Inputs Case 1: Only a single input x of shape (in_dims, batch_size) - Creates a hidden state using init_state and proceeds to Case 2. Case 2: Tuple ( x , h ) is provided, then the updated hidden state is returned. Returns New hidden state \\(h_{new}\\) of shape (out_dims, batch_size) Updated model state Parameters weight_i : Concatenated Weights to map from input space \\(\\\\left\\\\{ W_{ir}, W_{iz}, W_{in} \\\\right\\\\}\\) . weight_h : Concatenated Weights to map from hidden space \\(\\\\left\\\\{ W_{hr}, W_{hz}, W_{hn} \\\\right\\\\}\\) bias_i : Bias vector ( \\(b_{in}\\) ) bias_h : Concatenated Bias vector for the hidden space \\(\\\\left\\\\{ b_{hr}, b_{hz}, b_{hn} \\\\right\\\\}\\) States rng : Controls the randomness (if any) in the initial state generation source # Lux.LSTMCell \u2014 Type . LSTMCell ( in_dims => out_dims ; init_weight = ( glorot_uniform , glorot_uniform , glorot_uniform , glorot_uniform ), init_bias = ( zeros32 , zeros32 , ones32 , zeros32 ), init_state = zeros32 ) Long Short-Term (LSTM) Cell \\[ \\begin{align} i &= \\sigma(W_{ii} \\times x + W_{hi} \\times h_{prev} + b_{i})\\\\ f &= \\sigma(W_{if} \\times x + W_{hf} \\times h_{prev} + b_{f})\\\\ g &= tanh(W_{ig} \\times x + W_{hg} \\times h_{prev} + b_{g})\\\\ o &= \\sigma(W_{io} \\times x + W_{ho} \\times h_{prev} + b_{o})\\\\ c_{new} &= f \\cdot c_{prev} + i \\cdot g\\\\ h_{new} &= o \\cdot tanh(c_{new}) \\end{align} \\] Arguments in_dims : Input Dimension out_dims : Output (Hidden State & Memory) Dimension init_bias : Initializer for bias. Must be a tuple containing 4 functions init_weight : Initializer for weight. Must be a tuple containing 4 functions init_state : Initializer for hidden state and memory Inputs Case 1: Only a single input x of shape (in_dims, batch_size) - Creates a hidden state and memory using init_state and proceeds to Case 2. Case 2: Tuple ( x , h , c ) is provided, then the updated hidden state and memory is returned. Returns Tuple Containing New hidden state \\(h_{new}\\) of shape (out_dims, batch_size) Updated Memory \\(c_{new}\\) of shape (out_dims, batch_size) Updated model state Parameters weight_i : Concatenated Weights to map from input space \\(\\left\\{ W_{ii}, W_{if}, W_{ig}, W_{io} \\right\\}\\) . weight_h : Concatenated Weights to map from hidden space \\(\\left\\{ W_{hi}, W_{hf}, W_{hg}, W_{ho} \\right\\}\\) bias : Bias vector States rng : Controls the randomness (if any) in the initial state generation source # Lux.RNNCell \u2014 Type . RNNCell ( in_dims => out_dims , activation = tanh ; bias :: Bool = true , init_bias = zeros32 , init_weight = glorot_uniform , init_state = ones32 ) An Elman RNNCell cell with activation (typically set to tanh or relu ). \\(h_{new} = activation(weight_{ih} \\times x + weight_{hh} \\times h_{prev} + bias)\\) Arguments in_dims : Input Dimension out_dims : Output (Hidden State) Dimension activation : Activation function bias : Set to false to deactivate bias init_bias : Initializer for bias init_weight : Initializer for weight init_state : Initializer for hidden state Inputs Case 1: Only a single input x of shape (in_dims, batch_size) - Creates a hidden state using init_state and proceeds to Case 2. Case 2: Tuple ( x , h ) is provided, then the updated hidden state is returned. Returns New hidden state \\(h_{new}\\) of shape (out_dims, batch_size) Updated model state Parameters weight_ih : Maps the input to the hidden state. weight_hh : Maps the hidden state to the hidden state. bias : Bias vector (not present if bias=false ) States rng : Controls the randomness (if any) in the initial state generation source","title":"Recurrent Layers"},{"location":"api/layers/#linear-layers","text":"# Lux.Dense \u2014 Type . Dense ( in_dims => out_dims , activation = identity ; init_weight = glorot_uniform , init_bias = zeros32 , bias :: Bool = true ) Create a traditional fully connected layer, whose forward pass is given by: y = activation.(weight * x .+ bias) Arguments in_dims : number of input dimensions out_dims : number of output dimensions activation : activation function Keyword Arguments init_weight : initializer for the weight matrix ( weight = init_weight(rng, out_dims, in_dims) ) init_bias : initializer for the bias vector (ignored if bias=false ) bias : whether to include a bias vector Input x must be a Matrix of size in_dims \u00d7 B or a Vector of length in_dims Returns Matrix of size out_dims \u00d7 B or a Vector of length out_dims Empty NamedTuple() Parameters weight : Weight Matrix of size out_dims \u00d7 in_dims bias : Bias of size out_dims \u00d7 1 (present if bias=true ) source # Lux.Scale \u2014 Type . Scale ( dims , activation = identity ; init_weight = ones32 , init_bias = zeros32 , bias :: Bool = true ) Create a Sparsely Connected Layer with a very specific structure (only Diagonal Elements are non-zero). The forward pass is given by: y = activation.(weight .* x .+ bias) Arguments dims : size of the learnable scale and bias parameters. activation : activation function Keyword Arguments init_weight : initializer for the weight matrix ( weight = init_weight(rng, out_dims, in_dims) ) init_bias : initializer for the bias vector (ignored if bias=false ) bias : whether to include a bias vector Input x must be an Array of size (dims..., B) or (dims...[0], ..., dims[k]) for k \u2264 size(dims) Returns Array of size (dims..., B) or (dims...[0], ..., dims[k]) for k \u2264 size(dims) Empty NamedTuple() Parameters weight : Weight Array of size (dims...) bias : Bias of size (dims...) Lux 0.4.3 Scale with multiple dimensions requires at least Lux 0.4.3. source","title":"Linear Layers"},{"location":"api/layers/#misc-helper-layers","text":"# Lux.ActivationFunction \u2014 Function . ActivationFunction ( f ) Broadcast f on the input. Arguments f : Activation function Inputs x : Any array type s.t. f can be broadcasted over it Returns Broadcasted Activation f.(x) Empty NamedTuple() Warning This layer is deprecated and will be removed in v0.5. Use WrappedFunction with manual broadcasting source # Lux.FlattenLayer \u2014 Type . FlattenLayer () Flattens the passed array into a matrix. Inputs x : AbstractArray Returns AbstractMatrix of size (:, size(x, ndims(x))) Empty NamedTuple() source # Lux.NoOpLayer \u2014 Type . NoOpLayer () As the name suggests does nothing but allows pretty printing of layers. Whatever input is passed is returned. source # Lux.ReshapeLayer \u2014 Type . ReshapeLayer ( dims ) Reshapes the passed array to have a size of (dims..., :) Arguments dims : The new dimensions of the array (excluding the last dimension). Inputs x : AbstractArray of any shape which can be reshaped in (dims..., size(x, ndims(x))) Returns AbstractArray of size (dims..., size(x, ndims(x))) Empty NamedTuple() source # Lux.SelectDim \u2014 Type . SelectDim ( dim , i ) Return a view of all the data of the input x where the index for dimension dim equals i . Equivalent to view(x,:,:,...,i,:,:,...) where i is in position d . Arguments dim : Dimension for indexing i : Index for dimension dim Inputs x : AbstractArray that can be indexed with view(x,:,:,...,i,:,:,...) Returns view(x,:,:,...,i,:,:,...) where i is in position d Empty NamedTuple() source # Lux.WrappedFunction \u2014 Type . WrappedFunction ( f ) Wraps a stateless and parameter less function. Might be used when a function is added to Chain . For example, Chain(x -> relu.(x)) would not work and the right thing to do would be Chain((x, ps, st) -> (relu.(x), st)) . An easier thing to do would be Chain(WrappedFunction(Base.Fix1(broadcast, relu))) Arguments f::Function : A stateless and parameterless function Inputs x : s.t hasmethod(f, (typeof(x),)) is true Returns Output of f(x) Empty NamedTuple() source","title":"Misc. Helper Layers"},{"location":"api/layers/#normalization-layers","text":"# Lux.BatchNorm \u2014 Type . BatchNorm ( chs :: Integer , activation = identity ; init_bias = zeros32 , init_scale = ones32 , affine = true , track_stats = true , epsilon = 1f-5 , momentum = 0.1f0 ) Batch Normalization layer. BatchNorm computes the mean and variance for each D_1 \u00d7 ... \u00d7 D_{N-2} \u00d7 1 \u00d7 D_N input slice and normalises the input accordingly. Arguments chs : Size of the channel dimension in your data. Given an array with N dimensions, call the N-1 th the channel dimension. For a batch of feature vectors this is just the data dimension, for WHCN images it's the usual channel dimension. activation : After normalisation, elementwise activation activation is applied. Keyword Arguments If affine=true , it also applies a shift and a rescale to the input through to learnable per-channel bias and scale parameters. init_bias : Controls how the bias is initiliazed init_scale : Controls how the scale is initiliazed If track_stats=true , accumulates mean and variance statistics in training phase that will be used to renormalize the input in test phase. epsilon : a value added to the denominator for numerical stability momentum : the value used for the running_mean and running_var computation Inputs x : Array where size(x, N - 1) = chs and ndims(x) > 2 Returns y : Normalized Array Update model state Parameters affine=true bias : Bias of shape (chs,) scale : Scale of shape (chs,) affine=false - Empty NamedTuple() States Statistics if track_stats=true running_mean : Running mean of shape (chs,) running_var : Running variance of shape (chs,) Statistics if track_stats=false running_mean : nothing running_var : nothing training : Used to check if training/inference mode Use Lux.testmode during inference. Example m = Chain ( Dense ( 784 => 64 ), BatchNorm ( 64 , relu ), Dense ( 64 => 10 ), BatchNorm ( 10 )) Warning Passing a batch size of 1, during training will result in NaNs. See also GroupNorm source # Lux.GroupNorm \u2014 Type . GroupNorm ( chs :: Integer , groups :: Integer , activation = identity ; init_bias = zeros32 , init_scale = ones32 , affine = true , track_stats = true , epsilon = 1f-5 , momentum = 0.1f0 ) Group Normalization layer. Arguments chs : Size of the channel dimension in your data. Given an array with N dimensions, call the N-1 th the channel dimension. For a batch of feature vectors this is just the data dimension, for WHCN images it's the usual channel dimension. groups is the number of groups along which the statistics are computed. The number of channels must be an integer multiple of the number of groups. activation : After normalisation, elementwise activation activation is applied. Keyword Arguments If affine=true , it also applies a shift and a rescale to the input through to learnable per-channel bias and scale parameters. init_bias : Controls how the bias is initiliazed init_scale : Controls how the scale is initiliazed If track_stats=true , accumulates mean and variance statistics in training phase that will be used to renormalize the input in test phase. (This feature has been deprecated and will be removed in v0.5) epsilon : a value added to the denominator for numerical stability momentum : the value used for the running_mean and running_var computation (This feature has been deprecated and will be removed in v0.5) Inputs x : Array where size(x, N - 1) = chs and ndims(x) > 2 Returns y : Normalized Array Update model state Parameters affine=true bias : Bias of shape (chs,) scale : Scale of shape (chs,) affine=false - Empty NamedTuple() States Statistics if track_stats=true (DEPRECATED) running_mean : Running mean of shape (groups,) running_var : Running variance of shape (groups,) Statistics if track_stats=false running_mean : nothing running_var : nothing training : Used to check if training/inference mode Use Lux.testmode during inference. Example m = Chain ( Dense ( 784 => 64 ), GroupNorm ( 64 , 4 , relu ), Dense ( 64 => 10 ), GroupNorm ( 10 , 5 )) Warning GroupNorm doesn't have CUDNN support. The GPU fallback is not very efficient. See also BatchNorm source # Lux.WeightNorm \u2014 Type . WeightNorm ( layer :: AbstractExplicitLayer , which_params :: NTuple { N , Symbol }, dims :: Union { Tuple , Nothing } = nothing ) Applies weight normalization to a parameter in the given layer. \\(w = g\\frac{v}{\\|v\\|}\\) Weight normalization is a reparameterization that decouples the magnitude of a weight tensor from its direction. This updates the parameters in which_params (e.g. weight ) using two parameters: one specifying the magnitude (e.g. weight_g ) and one specifying the direction (e.g. weight_v ). Arguments layer whose parameters are being reparameterized which_params : parameter names for the parameters being reparameterized By default, a norm over the entire array is computed. Pass dims to modify the dimension. Inputs x : Should be of valid type for input to layer Returns Output from layer Updated model state of layer Parameters normalized : Parameters of layer that are being normalized unnormalized : Parameters of layer that are not being normalized States Same as that of layer source","title":"Normalization Layers"},{"location":"api/layers/#upsampling","text":"# Lux.Upsample \u2014 Type . Upsample ( mode = :nearest ; [ scale , size ]) Upsample ( scale , mode = :nearest ) Upsampling Layer. Layer Construction Option 1 mode : Set to :nearest , :linear , :bilinear or :trilinear Exactly one of two keywords must be specified: If scale is a number, this applies to all but the last two dimensions (channel and batch) of the input. It may also be a tuple, to control dimensions individually. Alternatively, keyword size accepts a tuple, to directly specify the leading dimensions of the output. Option 2 If scale is a number, this applies to all but the last two dimensions (channel and batch) of the input. It may also be a tuple, to control dimensions individually. mode : Set to :nearest , :bilinear or :trilinear Currently supported upsampling mode s and corresponding NNlib's methods are: :nearest -> NNlib.upsample_nearest :bilinear -> NNlib.upsample_bilinear :trilinear -> NNlib.upsample_trilinear Inputs x : For the input dimensions look into the documentation for the corresponding NNlib function As a rule of thumb, :nearest should work with arrays of arbitrary dimensions :bilinear works with 4D Arrays :trilinear works with 5D Arrays Returns Upsampled Input of size size or of size (I_1 x scale[1], ..., I_N x scale[N], C, N) Empty NamedTuple() source","title":"Upsampling"},{"location":"api/layers/#index","text":"Lux.AdaptiveMaxPool Lux.AdaptiveMeanPool Lux.BatchNorm Lux.BranchLayer Lux.Chain Lux.Conv Lux.Dense Lux.Dropout Lux.FlattenLayer Lux.GRUCell Lux.GlobalMaxPool Lux.GlobalMeanPool Lux.GroupNorm Lux.LSTMCell Lux.MaxPool Lux.MeanPool Lux.NoOpLayer Lux.PairwiseFusion Lux.Parallel Lux.RNNCell Lux.ReshapeLayer Lux.Scale Lux.SelectDim Lux.SkipConnection Lux.Upsample Lux.VariationalHiddenDropout Lux.WeightNorm Lux.WrappedFunction Lux.ActivationFunction","title":"Index"},{"location":"api/utilities/","text":"Data Transfer \u00a4 # Lux.cpu \u2014 Function . cpu ( x ) Transfer x to CPU source # Lux.gpu \u2014 Function . gpu ( x ) Transfer x to GPU source Initialization \u00a4 # Lux.glorot_normal \u2014 Function . glorot_normal ( rng :: AbstractRNG , size ... ; gain = 1 ) Return an Array{Float32} of the given size containing random numbers drawn from a normal distribution with standard deviation gain * sqrt(2 / (fan_in + fan_out)) . This method is described in [1] and also known as Xavier initialization. References [1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics . 2010. source # Lux.glorot_uniform \u2014 Function . glorot_uniform ( rng :: AbstractRNG , size ... ; gain = 1 ) Return an Array{Float32} of the given size containing random numbers drawn from a uniform distribution on the interval \\([-x, x]\\) , where x = gain * sqrt(6 / (fan_in + fan_out)) . This method is described in [1] and also known as Xavier initialization. References [1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics . 2010. source # Lux.ones32 \u2014 Function . ones32 ( rng :: AbstractRNG , size ... ) = ones ( Float32 , size ... ) Return an Array{Float32} of ones of the given size . ( rng is ignored) source # Lux.zeros32 \u2014 Function . zeros32 ( rng :: AbstractRNG , size ... ) = zeros ( Float32 , size ... ) Return an Array{Float32} of zeros of the given size . ( rng is ignored) source Miscellaneous Utilities \u00a4 # Lux.applyactivation \u2014 Function . applyactivation ( f :: Function , x :: AbstractArray ) Apply the function f on x elementwise, i.e. f.(x) . Dispatches to CUDNN if possible. source # Lux.elementwise_add \u2014 Function . elementwise_add ( x , y ) Computes x .+ y . Dispatches to CUDNN if possible source # Lux.elementwise_mul \u2014 Function . elementwise_mul ( x , y ) Computes x .* y . Dispatches to CUDNN if possible source # Lux.istraining \u2014 Function . istraining ( :: Val { training }) istraining ( st :: NamedTuple ) Returns true if training is true or if st contains a training field with value true . Else returns false . Method undefined if st.training is not of type Val . source # Lux.multigate \u2014 Function . multigate ( x :: AbstractArray , :: Val { N }) Split up x into N equally sized chunks (along dimension 1 ). source # Lux.replicate \u2014 Function . replicate ( rng :: AbstractRNG ) replicate ( rng :: CUDA . RNG ) Creates a copy of the rng state depending on its type. source Index \u00a4 Lux.applyactivation Lux.cpu Lux.elementwise_add Lux.elementwise_mul Lux.glorot_normal Lux.glorot_uniform Lux.gpu Lux.istraining Lux.multigate Lux.ones32 Lux.replicate Lux.zeros32","title":"Utilities"},{"location":"api/utilities/#data-transfer","text":"# Lux.cpu \u2014 Function . cpu ( x ) Transfer x to CPU source # Lux.gpu \u2014 Function . gpu ( x ) Transfer x to GPU source","title":"Data Transfer"},{"location":"api/utilities/#initialization","text":"# Lux.glorot_normal \u2014 Function . glorot_normal ( rng :: AbstractRNG , size ... ; gain = 1 ) Return an Array{Float32} of the given size containing random numbers drawn from a normal distribution with standard deviation gain * sqrt(2 / (fan_in + fan_out)) . This method is described in [1] and also known as Xavier initialization. References [1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics . 2010. source # Lux.glorot_uniform \u2014 Function . glorot_uniform ( rng :: AbstractRNG , size ... ; gain = 1 ) Return an Array{Float32} of the given size containing random numbers drawn from a uniform distribution on the interval \\([-x, x]\\) , where x = gain * sqrt(6 / (fan_in + fan_out)) . This method is described in [1] and also known as Xavier initialization. References [1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics . 2010. source # Lux.ones32 \u2014 Function . ones32 ( rng :: AbstractRNG , size ... ) = ones ( Float32 , size ... ) Return an Array{Float32} of ones of the given size . ( rng is ignored) source # Lux.zeros32 \u2014 Function . zeros32 ( rng :: AbstractRNG , size ... ) = zeros ( Float32 , size ... ) Return an Array{Float32} of zeros of the given size . ( rng is ignored) source","title":"Initialization"},{"location":"api/utilities/#miscellaneous-utilities","text":"# Lux.applyactivation \u2014 Function . applyactivation ( f :: Function , x :: AbstractArray ) Apply the function f on x elementwise, i.e. f.(x) . Dispatches to CUDNN if possible. source # Lux.elementwise_add \u2014 Function . elementwise_add ( x , y ) Computes x .+ y . Dispatches to CUDNN if possible source # Lux.elementwise_mul \u2014 Function . elementwise_mul ( x , y ) Computes x .* y . Dispatches to CUDNN if possible source # Lux.istraining \u2014 Function . istraining ( :: Val { training }) istraining ( st :: NamedTuple ) Returns true if training is true or if st contains a training field with value true . Else returns false . Method undefined if st.training is not of type Val . source # Lux.multigate \u2014 Function . multigate ( x :: AbstractArray , :: Val { N }) Split up x into N equally sized chunks (along dimension 1 ). source # Lux.replicate \u2014 Function . replicate ( rng :: AbstractRNG ) replicate ( rng :: CUDA . RNG ) Creates a copy of the rng state depending on its type. source","title":"Miscellaneous Utilities"},{"location":"api/utilities/#index","text":"Lux.applyactivation Lux.cpu Lux.elementwise_add Lux.elementwise_mul Lux.glorot_normal Lux.glorot_uniform Lux.gpu Lux.istraining Lux.multigate Lux.ones32 Lux.replicate Lux.zeros32","title":"Index"},{"location":"devdocs/layer_implementation/","text":"Layer Implementation \u00a4 Recurrent Neural Networks \u00a4 Cell Implementations \u00a4 Explicit Management on End-User Side \u00a4 Note We currently use this implementation User is responsible for managing the memory and hidden states. Pros \u00a4 Simple Design and Implementation. Hard for the User to mess up, i.e. there is no explicit requirement to call things like Flux.reset! . In the first call user passes the input . In the subsequent calls, the user passes a tuple containing the input , hidden_state and memory (if needed). Cons \u00a4 Requires more explicit management from the user which might make it harder to use. Currently the call order convention is not enforced which could lead to sneaky errors. (Implementing a check is quite trivial if we store a call counter in the model state ). Store Hidden State and Memory in Model State \u00a4 Storing the memory and hidden state in st would allow user to just pass x without varying how calls are made at different timesteps. Pros \u00a4 Easier for the end-user. Cons \u00a4 reset ing the hidden-state and memory is slightly tricky. One way would be to store a initial_hidden_state and initial_memory in the state alongside the hidden_state and memory . RNN Blocks \u00a4 Note This is currently unimplemented An example implementation would be function ( l :: LSTM )( x :: AbstractArray { T , 3 }, ps :: NamedTuple , st :: NamedTuple ) where { T } ( h , c ), st = s . lstm_cell ( view ( x , : , 1 , : ), ps , st ) for i in 1 : size ( x , 2 ) ( h , c ), st = s . lstm_cell (( view ( x , : , i , : ), h , c ), ps , st ) end return h , st end We enforce the inputs to be of the format in_dims \u00d7 sequence_length \u00d7 batch_size .","title":"Layer Implementation"},{"location":"devdocs/layer_implementation/#layer-implementation","text":"","title":"Layer Implementation"},{"location":"devdocs/layer_implementation/#recurrent-neural-networks","text":"","title":"Recurrent Neural Networks"},{"location":"devdocs/layer_implementation/#cell-implementations","text":"","title":"Cell Implementations"},{"location":"devdocs/layer_implementation/#explicit-management-on-end-user-side","text":"Note We currently use this implementation User is responsible for managing the memory and hidden states.","title":"Explicit Management on End-User Side"},{"location":"devdocs/layer_implementation/#store-hidden-state-and-memory-in-model-state","text":"Storing the memory and hidden state in st would allow user to just pass x without varying how calls are made at different timesteps.","title":"Store Hidden State and Memory in Model State"},{"location":"devdocs/layer_implementation/#rnn-blocks","text":"Note This is currently unimplemented An example implementation would be function ( l :: LSTM )( x :: AbstractArray { T , 3 }, ps :: NamedTuple , st :: NamedTuple ) where { T } ( h , c ), st = s . lstm_cell ( view ( x , : , 1 , : ), ps , st ) for i in 1 : size ( x , 2 ) ( h , c ), st = s . lstm_cell (( view ( x , : , i , : ), h , c ), ps , st ) end return h , st end We enforce the inputs to be of the format in_dims \u00d7 sequence_length \u00d7 batch_size .","title":"RNN Blocks"},{"location":"devdocs/style_guide/","text":"Style Guide \u00a4 We strictly enforce a style guide across the repository. For the most part we rely on SciMLStyle . However, any additional guideline mentioned in this document takes precedence. How to auto-format your code? Firstly, install JuliaFormatter by running julia -e 'using Pkg; Pkg.add(PackageSpec(name=\"JuliaFormatter\"))' . Next, from the root directory of the project, simply run julia -e 'using JuliaFormatter; format(\".\")' . We do have automatic formatter, which opens PR after fixing common style issues, however, we strictly don't merge PRs without a green style check. Note If you find any existing code which doesn't adhere to these guidelines, open an issue so that we can fix that. Code Styling \u00a4 Keyword Arguments must be separated using a semicolon ; Functions must use return . Returning the last value is quite ambiguous \u2013 did the author actually want it returned? Format docstrings as you would format regular code. If the docstring constains LaTeX in multiple lines, use math block. No avoiding multiply symbol \u2013 so 2x is invalid instead do it like other languages 2 * x . Unicode Characters \u00a4 No use of unicode characters is allowed. The only exception is when defining DSLs. In this particular case, how to type the unicode must be properly documented. Testing \u00a4 Note Unfortunately we haven't yet tested all the functionality in the base library using these guidelines. The file structure of the test folder should mirror that of the src folder. Every file in src should have a complementary file in the test folder, containing tests relevant to that file's contents. Add generic utilities for testing in test/test_utils.jl and include them in the relevant files. Use JET.jl to test for dynamic dispatch in the functionality you added, specifically use run_JET_tests from test/test_utils.jl . Always test for gradient correctness. Zygote can be notorious for incorrect gradients, so add tests using test_gradient_correctness_fdm for finite differencing or use any other AD framework and tally the results. Try adding to backend packages \u00a4 Lux is mostly a frontend for defining Neural Networks. As such, if an optimization needs to be applied to lets say NNlib.jl , it is better to open a PR there since all frameworks using NNlib.jl get to benefit from these fixes. Similarly, if a bug comes to the forefront from one of the backend packages, make sure to open a corresponding issue there to ensure they are appropriately tracked. Mutability \u00a4 This is strictly enforced, i.e. all layers/functions provided as part of the external API must be pure functions, even if they come with a performance penalty. Branching \u2013 Generated Functions \u00a4 Zygote doesn't like branches in code. Like it or not, we are stuck with it for the near future. Even if julia is able to optimize branches away, Zygote will most certainly throw away those optimizations (these can be tested via Zygote.@code_ir ). Writing efficient non-branching code to make Zygote happy \u00a4 Rely on @generated functions to remove most runtime branching. Certain examples: Layers behaving differently during training and inference \u2013 we know at compile-time whether a layer is being run in training/inference mode via istraining(st) . Composite Layers relying on a variable number of internal layers \u2013 Again we know the length of the number of internal layers at compile time. Hence we can manually unroll the loops. See Parallel , Chain , etc. Pass around Val in state. Flux.jl sets training to be (:auto, true, false) . Hence, which branch will be evaluated, will have to be determined at runtime time ( bad ). Instead if we pass Val(true) , we will be able to specialize functions directly based on true , false , etc. ensuring there is no runtime cost for these operations. See BatchNorm , Dropout , etc. Deprecation \u00a4 Deprecations should be handled according to SemVar recommendations, i.e. there should be atleast one version where we throw a deprecation warning. This ensures users know how to modify their code for upcoming releases. This blog details the process of deprecating functionalities in Julia packages. We follow the same process. Some additional guidelines are: Add tests using Test.@test_deprecated to ensure that deprecations are indeed working as expected. Add a warning to the documentation about deprecations (and how to use the new recommended functionality). Add # Deprecated Functionality (Remove in <VERSION NUMBER>) before the tests and deprecated functionality not placed in src/deprecated.jl (like kwarg deprecations). This makes it easier to search and delete the functionalities before making a breaking release. Documentation \u00a4 We use Documenter.jl + mkdocs for our documentation. Adding Tutorials \u00a4 Add tutorials must be added to the examples directory. Then add an entry for the path and tutorial name in docs/make.jl . Finally, update the navigation nav in docs/mkdocs.yml Documentation for Layers \u00a4 The first line must be indented by 4 spaces and should contain the possible ways to construct the layer. This should be followed up with a description about what the layer does. If mathematical equations are needed to explain what the layer does, go for it. Often times we fuse parameters to make computation faster, this should be reflected in the equations being used, i.e. equations and the internal code must be consistent. (See LSTMCell , GRUCell for some examples.) Note There is no need to document how the layers are being called since they must adhere to layer(x, ps, st) . Any deviation from that and the PR will not be accepted. Next, we will have certain subsections (though all of them might not be necessary for all layers). Arguments : This section should be present unless the layer is constructed without any arguments (See NoOpLayer ). All the arguments and their explicit constraints must be explained. It is recommended to separate out the Keyword Arguments in their own section. Inputs : This section should always be present. List out the requirements x needs to satisfy. (Don't write about ps and st since that is expected by default.) Returns : What will the layer return? We know the second element will be a state but is that updated in any form or not? Parameters : What are the properties of the NamedTuple returned from initialparameters ? Omit if the layer is parameterless. States : What are the properties of the NamedTuple returned from initialstates ? Omit if the layer is stateless.","title":"Style Guide"},{"location":"devdocs/style_guide/#style-guide","text":"We strictly enforce a style guide across the repository. For the most part we rely on SciMLStyle . However, any additional guideline mentioned in this document takes precedence. How to auto-format your code? Firstly, install JuliaFormatter by running julia -e 'using Pkg; Pkg.add(PackageSpec(name=\"JuliaFormatter\"))' . Next, from the root directory of the project, simply run julia -e 'using JuliaFormatter; format(\".\")' . We do have automatic formatter, which opens PR after fixing common style issues, however, we strictly don't merge PRs without a green style check. Note If you find any existing code which doesn't adhere to these guidelines, open an issue so that we can fix that.","title":"Style Guide"},{"location":"devdocs/style_guide/#code-styling","text":"Keyword Arguments must be separated using a semicolon ; Functions must use return . Returning the last value is quite ambiguous \u2013 did the author actually want it returned? Format docstrings as you would format regular code. If the docstring constains LaTeX in multiple lines, use math block. No avoiding multiply symbol \u2013 so 2x is invalid instead do it like other languages 2 * x .","title":"Code Styling"},{"location":"devdocs/style_guide/#unicode-characters","text":"No use of unicode characters is allowed. The only exception is when defining DSLs. In this particular case, how to type the unicode must be properly documented.","title":"Unicode Characters"},{"location":"devdocs/style_guide/#testing","text":"Note Unfortunately we haven't yet tested all the functionality in the base library using these guidelines. The file structure of the test folder should mirror that of the src folder. Every file in src should have a complementary file in the test folder, containing tests relevant to that file's contents. Add generic utilities for testing in test/test_utils.jl and include them in the relevant files. Use JET.jl to test for dynamic dispatch in the functionality you added, specifically use run_JET_tests from test/test_utils.jl . Always test for gradient correctness. Zygote can be notorious for incorrect gradients, so add tests using test_gradient_correctness_fdm for finite differencing or use any other AD framework and tally the results.","title":"Testing"},{"location":"devdocs/style_guide/#try-adding-to-backend-packages","text":"Lux is mostly a frontend for defining Neural Networks. As such, if an optimization needs to be applied to lets say NNlib.jl , it is better to open a PR there since all frameworks using NNlib.jl get to benefit from these fixes. Similarly, if a bug comes to the forefront from one of the backend packages, make sure to open a corresponding issue there to ensure they are appropriately tracked.","title":"Try adding to backend packages"},{"location":"devdocs/style_guide/#mutability","text":"This is strictly enforced, i.e. all layers/functions provided as part of the external API must be pure functions, even if they come with a performance penalty.","title":"Mutability"},{"location":"devdocs/style_guide/#branching-generated-functions","text":"Zygote doesn't like branches in code. Like it or not, we are stuck with it for the near future. Even if julia is able to optimize branches away, Zygote will most certainly throw away those optimizations (these can be tested via Zygote.@code_ir ).","title":"Branching \u2013 Generated Functions"},{"location":"devdocs/style_guide/#writing-efficient-non-branching-code-to-make-zygote-happy","text":"Rely on @generated functions to remove most runtime branching. Certain examples: Layers behaving differently during training and inference \u2013 we know at compile-time whether a layer is being run in training/inference mode via istraining(st) . Composite Layers relying on a variable number of internal layers \u2013 Again we know the length of the number of internal layers at compile time. Hence we can manually unroll the loops. See Parallel , Chain , etc. Pass around Val in state. Flux.jl sets training to be (:auto, true, false) . Hence, which branch will be evaluated, will have to be determined at runtime time ( bad ). Instead if we pass Val(true) , we will be able to specialize functions directly based on true , false , etc. ensuring there is no runtime cost for these operations. See BatchNorm , Dropout , etc.","title":"Writing efficient non-branching code to make Zygote happy"},{"location":"devdocs/style_guide/#deprecation","text":"Deprecations should be handled according to SemVar recommendations, i.e. there should be atleast one version where we throw a deprecation warning. This ensures users know how to modify their code for upcoming releases. This blog details the process of deprecating functionalities in Julia packages. We follow the same process. Some additional guidelines are: Add tests using Test.@test_deprecated to ensure that deprecations are indeed working as expected. Add a warning to the documentation about deprecations (and how to use the new recommended functionality). Add # Deprecated Functionality (Remove in <VERSION NUMBER>) before the tests and deprecated functionality not placed in src/deprecated.jl (like kwarg deprecations). This makes it easier to search and delete the functionalities before making a breaking release.","title":"Deprecation"},{"location":"devdocs/style_guide/#documentation","text":"We use Documenter.jl + mkdocs for our documentation.","title":"Documentation"},{"location":"devdocs/style_guide/#adding-tutorials","text":"Add tutorials must be added to the examples directory. Then add an entry for the path and tutorial name in docs/make.jl . Finally, update the navigation nav in docs/mkdocs.yml","title":"Adding Tutorials"},{"location":"devdocs/style_guide/#documentation-for-layers","text":"The first line must be indented by 4 spaces and should contain the possible ways to construct the layer. This should be followed up with a description about what the layer does. If mathematical equations are needed to explain what the layer does, go for it. Often times we fuse parameters to make computation faster, this should be reflected in the equations being used, i.e. equations and the internal code must be consistent. (See LSTMCell , GRUCell for some examples.) Note There is no need to document how the layers are being called since they must adhere to layer(x, ps, st) . Any deviation from that and the PR will not be accepted. Next, we will have certain subsections (though all of them might not be necessary for all layers). Arguments : This section should be present unless the layer is constructed without any arguments (See NoOpLayer ). All the arguments and their explicit constraints must be explained. It is recommended to separate out the Keyword Arguments in their own section. Inputs : This section should always be present. List out the requirements x needs to satisfy. (Don't write about ps and st since that is expected by default.) Returns : What will the layer return? We know the second element will be a state but is that updated in any form or not? Parameters : What are the properties of the NamedTuple returned from initialparameters ? Omit if the layer is parameterless. States : What are the properties of the NamedTuple returned from initialstates ? Omit if the layer is stateless.","title":"Documentation for Layers"},{"location":"examples/examples/","text":"Tutorials & Examples using Lux \u00a4 Tutorials \u00a4 Julia & Lux for the Uninitiated Training a Simple LSTM MNIST Classification using NeuralODE Bayesian Neural Network Scipts \u00a4 ImageNet Classification Packages \u00a4 See Ecosystem for more details.","title":"Home"},{"location":"examples/examples/#tutorials-examples-using-lux","text":"","title":"Tutorials &amp; Examples using Lux"},{"location":"examples/examples/#tutorials","text":"Julia & Lux for the Uninitiated Training a Simple LSTM MNIST Classification using NeuralODE Bayesian Neural Network","title":"Tutorials"},{"location":"examples/examples/#scipts","text":"ImageNet Classification","title":"Scipts"},{"location":"examples/examples/#packages","text":"See Ecosystem for more details.","title":"Packages"},{"location":"examples/generated/beginner/Basics/main/","text":"Julia & Lux for the Uninitiated \u00a4 This is a quick intro to Lux loosely based on: PyTorch's tutorial . Flux's tutorial . Flax's tutorial . It introduces basic Julia programming, as well Zygote , a source-to-source automatic differentiation (AD) framework in Julia. We'll use these tools to build a very simple neural network. Let's start with importing Lux.jl using Lux , Random Activating project at `~/work/Lux.jl/Lux.jl/examples` Now let us control the randomness in our code using proper Pseudo Random Number Generator (PRNG) rng = Random . default_rng () Random . seed! ( rng , 0 ) Random.TaskLocalRNG() Arrays \u00a4 The starting point for all of our models is the Array (sometimes referred to as a Tensor in other frameworks). This is really just a list of numbers, which might be arranged into a shape like a square. Let's write down an array with three elements. x = [ 1 , 2 , 3 ] 3-element Vector{Int64}: 1 2 3 Here's a matrix \u2013 a square array with four elements. x = [ 1 2 ; 3 4 ] 2\u00d72 Matrix{Int64}: 1 2 3 4 We often work with arrays of thousands of elements, and don't usually write them down by hand. Here's how we can create an array of 5\u00d73 = 15 elements, each a random number from zero to one. x = rand ( rng , 5 , 3 ) 5\u00d73 Matrix{Float64}: 0.455238 0.746943 0.193291 0.547642 0.746801 0.116989 0.773354 0.97667 0.899766 0.940585 0.0869468 0.422918 0.0296477 0.351491 0.707534 There's a few functions like this; try replacing rand with ones , zeros , or randn . By default, Julia works stores numbers is a high-precision format called Float64 . In ML we often don't need all those digits, and can ask Julia to work with Float32 instead. We can even ask for more digits using BigFloat . x = rand ( BigFloat , 5 , 3 ) 5\u00d73 Matrix{BigFloat}: 0.981339 0.793159 0.459019 0.043883 0.624384 0.56055 0.164786 0.524008 0.0355555 0.414769 0.577181 0.621958 0.00823197 0.30215 0.655881 x = rand ( Float32 , 5 , 3 ) 5\u00d73 Matrix{Float32}: 0.567794 0.369178 0.342539 0.0985227 0.201145 0.587206 0.776598 0.148248 0.0851708 0.723731 0.0770206 0.839303 0.404728 0.230954 0.679087 We can ask the array how many elements it has. length ( x ) 15 Or, more specifically, what size it has. size ( x ) (5, 3) We sometimes want to see some elements of the array on their own. x 5\u00d73 Matrix{Float32}: 0.567794 0.369178 0.342539 0.0985227 0.201145 0.587206 0.776598 0.148248 0.0851708 0.723731 0.0770206 0.839303 0.404728 0.230954 0.679087 x [ 2 , 3 ] 0.58720636f0 This means get the second row and the third column. We can also get every row of the third column. x [ : , 3 ] 5-element Vector{Float32}: 0.34253937 0.58720636 0.085170805 0.8393034 0.67908657 We can add arrays, and subtract them, which adds or subtracts each element of the array. x + x 5\u00d73 Matrix{Float32}: 1.13559 0.738356 0.685079 0.197045 0.40229 1.17441 1.5532 0.296496 0.170342 1.44746 0.154041 1.67861 0.809456 0.461908 1.35817 x - x 5\u00d73 Matrix{Float32}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 Julia supports a feature called broadcasting , using the . syntax. This tiles small arrays (or single numbers) to fill bigger ones. x .+ 1 5\u00d73 Matrix{Float32}: 1.56779 1.36918 1.34254 1.09852 1.20114 1.58721 1.7766 1.14825 1.08517 1.72373 1.07702 1.8393 1.40473 1.23095 1.67909 We can see Julia tile the column vector 1:5 across all rows of the larger array. zeros ( 5 , 5 ) .+ ( 1 : 5 ) 5\u00d75 Matrix{Float64}: 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 4.0 4.0 5.0 5.0 5.0 5.0 5.0 The x' syntax is used to transpose a column 1:5 into an equivalent row, and Julia will tile that across columns. zeros ( 5 , 5 ) .+ ( 1 : 5 ) ' 5\u00d75 Matrix{Float64}: 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 We can use this to make a times table. ( 1 : 5 ) .* ( 1 : 5 ) ' 5\u00d75 Matrix{Int64}: 1 2 3 4 5 2 4 6 8 10 3 6 9 12 15 4 8 12 16 20 5 10 15 20 25 Finally, and importantly for machine learning, we can conveniently do things like matrix multiply. W = randn ( 5 , 10 ) x = rand ( 10 ) W * x 5-element Vector{Float64}: 1.2197981041108443 -2.6262587710059595 -2.8573820474674845 -2.4319346874291305 1.010866857715021 Julia's arrays are very powerful, and you can learn more about what they can do here . CUDA Arrays \u00a4 CUDA functionality is provided separately by the CUDA.jl package . If you have a GPU and CUDA available, Lux will automatically build the required CUDA dependencies using CUDA.jl . You can manually add CUDA . Once CUDA is loaded you can move any array to the GPU with the cu function (or the gpu function exported by `Lux``), and it supports all of the above operations with the same syntax. # using CUDA # x = cu(rand(5, 3)) (Im)mutability \u00a4 Lux as you might have read is Immutable by convention which means that the core library is built without any form of mutation and all functions are pure. However, we don't enforce it in any form. We do strongly recommend that users extending this framework for their respective applications don't mutate their arrays. x = reshape ( 1 : 8 , 2 , 4 ) 2\u00d74 reshape(::UnitRange{Int64}, 2, 4) with eltype Int64: 1 3 5 7 2 4 6 8 To update this array, we should first copy the array. x_copy = copy ( x ) view ( x_copy , : , 1 ) .= 0 println ( \"Original Array \" , x ) println ( \"Mutated Array \" , x_copy ) Original Array [1 3 5 7; 2 4 6 8] Mutated Array [0 3 5 7; 0 4 6 8] Note that our current default AD engine (Zygote) is unable to differentiate through this mutation, however, for these specialized cases it is quite trivial to write custom backward passes. (This problem will be fixed once we move towards Enzyme.jl) Managing Randomness \u00a4 We rely on the Julia StdLib Random for managing the randomness in our execution. First, we create an PRNG and seed it. rng = Random . default_rng () # Creates a Xoshiro PRNG Random . seed! ( rng , 0 ) Random.TaskLocalRNG() If we call any function that relies on rng and uses it via randn , rand , etc. rng will be mutated. As we have already established we care a lot about immutability, hence we should use Lux.replicate on PRNG before using them. First, let us run a random number generator 3 times with the replicate d rng. for i in 1 : 3 println ( \"Iteration $i \" , rand ( Lux . replicate ( rng ), 10 )) end Iteration 1 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 2 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 3 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] As expected we get the same output. We can remove the replicate call and we will get different outputs. for i in 1 : 3 println ( \"Iteration $i \" , rand ( rng , 10 )) end Iteration 1 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 2 [0.018743665453639813, 0.8601828553599953, 0.6556360448565952, 0.7746656838366666, 0.7817315740767116, 0.5553797706980106, 0.1261990389976131, 0.4488101521328277, 0.624383955429775, 0.05657739601024536] Iteration 3 [0.19597391412112541, 0.6830945313415872, 0.6776220912718907, 0.6456416023530093, 0.6340362477836592, 0.5595843665394066, 0.5675557670686644, 0.34351700231383653, 0.7237308297251812, 0.3691778381831775] Automatic Differentiation \u00a4 Julia has quite a few (maybe too many) AD tools. For the purpose of this tutorial, we will use AbstractDifferentiation.jl which provides a uniform API across multiple AD backends. For the backends we will use: ForwardDiff.jl \u2013 For Jacobian-Vector Product (JVP) Zygote.jl \u2013 For Vector-Jacobian Product (VJP) Slight Detour : We have had several questions regarding if we will be considering any other AD system for the reverse-diff backend. For now we will stick to Zygote.jl, however once Enzyme.jl has support for custom rules and we have tested Lux extensively with it, we will make the switch. Even though, theoretically, a VJP (Vector-Jacobian product - reverse autodiff) and a JVP (Jacobian-Vector product - forward-mode autodiff) are similar\u2014they compute a product of a Jacobian and a vector\u2014they differ by the computational complexity of the operation. In short, when you have a large number of parameters (hence a wide matrix), a JVP is less efficient computationally than a VJP, and, conversely, a JVP is more efficient when the Jacobian matrix is a tall matrix. using ForwardDiff , Zygote , AbstractDifferentiation Gradients \u00a4 For our first example, consider a simple function computing \\(f(x) = \\frac{1}{2}x^T x\\) , where \\(\\nabla f(x) = x\\) f ( x ) = x ' * x / 2 \u2207f ( x ) = x v = randn ( rng , Float32 , 4 ) 4-element Vector{Float32}: -0.4051151 -0.4593922 0.92155594 1.1871622 Let's use AbstractDifferentiation and Zygote to compute the gradients. println ( \"Actual Gradient: \" , \u2207f ( v )) println ( \"Computed Gradient via Reverse Mode AD (Zygote): \" , AD . gradient ( AD . ZygoteBackend (), f , v )[ 1 ]) println ( \"Computed Gradient via Forward Mode AD (ForwardDiff): \" , AD . gradient ( AD . ForwardDiffBackend (), f , v )[ 1 ]) Actual Gradient: Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Computed Gradient via Reverse Mode AD (Zygote): Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Computed Gradient via Forward Mode AD (ForwardDiff): Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Note that AD.gradient will only work for scalar valued outputs. Jacobian-Vector Product \u00a4 I will defer the discussion on forward-mode AD to https://book.sciml.ai/notes/08/ . Here let us just look at a mini example on how to use it. f ( x ) = x .* x ./ 2 x = randn ( rng , Float32 , 5 ) v = ones ( Float32 , 5 ) 5-element Vector{Float32}: 1.0 1.0 1.0 1.0 1.0 Construct the pushforward function. pf_f = AD . value_and_pushforward_function ( AD . ForwardDiffBackend (), f , x ) #17 (generic function with 1 method) Compute the jvp. val , jvp = pf_f ( v ) println ( \"Computed Value: f(\" , x , \") = \" , val ) println ( \"JVP: \" , jvp [ 1 ]) Computed Value: f(Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]) = Float32[0.3850005, 0.71437216, 0.0016247969, 0.031389393, 0.0043726736] JVP: Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656] Vector-Jacobian Product \u00a4 Using the same function and inputs, let us compute the VJP. pb_f = AD . value_and_pullback_function ( AD . ZygoteBackend (), f , x ) #25 (generic function with 1 method) Compute the vjp. val , vjp = pb_f ( v ) println ( \"Computed Value: f(\" , x , \") = \" , val ) println ( \"VJP: \" , vjp [ 1 ]) Computed Value: f(Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]) = Float32[0.3850005, 0.71437216, 0.0016247969, 0.031389393, 0.0043726736] VJP: Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656] Linear Regression \u00a4 Finally, now let us consider a linear regression problem. From a set of data-points \\(\\left\\{ (x_i, y_i), i \\in \\left\\{ 1, \\dots, k \\right\\}, x_i \\in \\mathbb{R}^n, y_i \\in \\mathbb{R}^m \\right\\}\\) , we try to find a set of parameters \\(W\\) and \\(b\\) , s.t. \\(f_{W,b}(x) = Wx + b\\) , which minimizes the mean squared error: \\[ L(W, b) \\longrightarrow \\sum_{i = 1}^{k} \\frac{1}{2} \\| y_i - f_{W,b}(x_i) \\|_2^2 \\] We can write f from scratch, but to demonstrate Lux , let us use the Dense layer. model = Dense ( 10 => 5 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) Random.TaskLocalRNG() Let us initialize the parameters and states (in this case it is empty) for the model. ps , st = Lux . setup ( rng , model ) ps = ps |> Lux . ComponentArray ComponentVector{Float32}(weight = Float32[-0.5583162 0.3457679 \u2026 -0.35419345 0.039559156; -0.05661944 -0.4899126 \u2026 0.22614014 0.27704597; \u2026 ; 0.06026341 -0.11202827 \u2026 0.42526972 -0.3576447; 0.23414856 -0.5949539 \u2026 0.08254115 -0.5224755], bias = Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;]) Set problem dimensions. n_samples = 20 x_dim = 10 y_dim = 5 5 Generate random ground truth W and b. W = randn ( rng , Float32 , y_dim , x_dim ) b = randn ( rng , Float32 , y_dim ) 5-element Vector{Float32}: 0.68468636 -0.57578707 0.0594993 -0.9436797 1.5164032 Generate samples with additional noise. x_samples = randn ( rng , Float32 , x_dim , n_samples ) y_samples = W * x_samples .+ b .+ 0.01f0 .* randn ( rng , Float32 , y_dim , n_samples ) println ( \"x shape: \" , size ( x_samples ), \"; y shape: \" , size ( y_samples )) x shape: (10, 20); y shape: (5, 20) For updating our parameters let's use Optimisers.jl using Optimisers opt = Optimisers . Descent ( 0.01f0 ) Optimisers.Descent{Float32}(0.01f0) Initialize the initial state of the optimiser opt_state = Optimisers . setup ( opt , ps ) Leaf(Descent{Float32}(0.01), nothing) Define the loss function mse ( model , ps , st , X , y ) = sum ( abs2 , model ( X , ps , st )[ 1 ] .- y ) mse ( weight , bias , X , y ) = sum ( abs2 , weight * X .+ bias .- y ) loss_function ( ps , X , y ) = mse ( model , ps , st , X , y ) println ( \"Loss Value with ground true W & b: \" , mse ( W , b , x_samples , y_samples )) for i in 1 : 100 # In actual code, don't use globals. But here I will simply for the sake of demonstration global ps , st , opt_state # Compute the gradient gs = gradient ( loss_function , ps , x_samples , y_samples )[ 1 ] # Perform parameter update opt_state , ps = Optimisers . update ( opt_state , ps , gs ) if i % 10 == 1 || i == 100 println ( \"Loss Value after $i iterations: \" , mse ( model , ps , st , x_samples , y_samples )) end end Loss Value with ground true W & b: 0.009175307 Loss Value after 1 iterations: 165.57005 Loss Value after 11 iterations: 4.351237 Loss Value after 21 iterations: 0.6856849 Loss Value after 31 iterations: 0.15421417 Loss Value after 41 iterations: 0.041469414 Loss Value after 51 iterations: 0.014032223 Loss Value after 61 iterations: 0.006883738 Loss Value after 71 iterations: 0.004938521 Loss Value after 81 iterations: 0.004391277 Loss Value after 91 iterations: 0.0042331247 Loss Value after 100 iterations: 0.0041888584 This page was generated using Literate.jl .","title":"Julia & Lux for the Uninitiated"},{"location":"examples/generated/beginner/Basics/main/#julia-lux-for-the-uninitiated","text":"This is a quick intro to Lux loosely based on: PyTorch's tutorial . Flux's tutorial . Flax's tutorial . It introduces basic Julia programming, as well Zygote , a source-to-source automatic differentiation (AD) framework in Julia. We'll use these tools to build a very simple neural network. Let's start with importing Lux.jl using Lux , Random Activating project at `~/work/Lux.jl/Lux.jl/examples` Now let us control the randomness in our code using proper Pseudo Random Number Generator (PRNG) rng = Random . default_rng () Random . seed! ( rng , 0 ) Random.TaskLocalRNG()","title":"Julia &amp; Lux for the Uninitiated"},{"location":"examples/generated/beginner/Basics/main/#arrays","text":"The starting point for all of our models is the Array (sometimes referred to as a Tensor in other frameworks). This is really just a list of numbers, which might be arranged into a shape like a square. Let's write down an array with three elements. x = [ 1 , 2 , 3 ] 3-element Vector{Int64}: 1 2 3 Here's a matrix \u2013 a square array with four elements. x = [ 1 2 ; 3 4 ] 2\u00d72 Matrix{Int64}: 1 2 3 4 We often work with arrays of thousands of elements, and don't usually write them down by hand. Here's how we can create an array of 5\u00d73 = 15 elements, each a random number from zero to one. x = rand ( rng , 5 , 3 ) 5\u00d73 Matrix{Float64}: 0.455238 0.746943 0.193291 0.547642 0.746801 0.116989 0.773354 0.97667 0.899766 0.940585 0.0869468 0.422918 0.0296477 0.351491 0.707534 There's a few functions like this; try replacing rand with ones , zeros , or randn . By default, Julia works stores numbers is a high-precision format called Float64 . In ML we often don't need all those digits, and can ask Julia to work with Float32 instead. We can even ask for more digits using BigFloat . x = rand ( BigFloat , 5 , 3 ) 5\u00d73 Matrix{BigFloat}: 0.981339 0.793159 0.459019 0.043883 0.624384 0.56055 0.164786 0.524008 0.0355555 0.414769 0.577181 0.621958 0.00823197 0.30215 0.655881 x = rand ( Float32 , 5 , 3 ) 5\u00d73 Matrix{Float32}: 0.567794 0.369178 0.342539 0.0985227 0.201145 0.587206 0.776598 0.148248 0.0851708 0.723731 0.0770206 0.839303 0.404728 0.230954 0.679087 We can ask the array how many elements it has. length ( x ) 15 Or, more specifically, what size it has. size ( x ) (5, 3) We sometimes want to see some elements of the array on their own. x 5\u00d73 Matrix{Float32}: 0.567794 0.369178 0.342539 0.0985227 0.201145 0.587206 0.776598 0.148248 0.0851708 0.723731 0.0770206 0.839303 0.404728 0.230954 0.679087 x [ 2 , 3 ] 0.58720636f0 This means get the second row and the third column. We can also get every row of the third column. x [ : , 3 ] 5-element Vector{Float32}: 0.34253937 0.58720636 0.085170805 0.8393034 0.67908657 We can add arrays, and subtract them, which adds or subtracts each element of the array. x + x 5\u00d73 Matrix{Float32}: 1.13559 0.738356 0.685079 0.197045 0.40229 1.17441 1.5532 0.296496 0.170342 1.44746 0.154041 1.67861 0.809456 0.461908 1.35817 x - x 5\u00d73 Matrix{Float32}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 Julia supports a feature called broadcasting , using the . syntax. This tiles small arrays (or single numbers) to fill bigger ones. x .+ 1 5\u00d73 Matrix{Float32}: 1.56779 1.36918 1.34254 1.09852 1.20114 1.58721 1.7766 1.14825 1.08517 1.72373 1.07702 1.8393 1.40473 1.23095 1.67909 We can see Julia tile the column vector 1:5 across all rows of the larger array. zeros ( 5 , 5 ) .+ ( 1 : 5 ) 5\u00d75 Matrix{Float64}: 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 4.0 4.0 5.0 5.0 5.0 5.0 5.0 The x' syntax is used to transpose a column 1:5 into an equivalent row, and Julia will tile that across columns. zeros ( 5 , 5 ) .+ ( 1 : 5 ) ' 5\u00d75 Matrix{Float64}: 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 We can use this to make a times table. ( 1 : 5 ) .* ( 1 : 5 ) ' 5\u00d75 Matrix{Int64}: 1 2 3 4 5 2 4 6 8 10 3 6 9 12 15 4 8 12 16 20 5 10 15 20 25 Finally, and importantly for machine learning, we can conveniently do things like matrix multiply. W = randn ( 5 , 10 ) x = rand ( 10 ) W * x 5-element Vector{Float64}: 1.2197981041108443 -2.6262587710059595 -2.8573820474674845 -2.4319346874291305 1.010866857715021 Julia's arrays are very powerful, and you can learn more about what they can do here .","title":"Arrays"},{"location":"examples/generated/beginner/Basics/main/#cuda-arrays","text":"CUDA functionality is provided separately by the CUDA.jl package . If you have a GPU and CUDA available, Lux will automatically build the required CUDA dependencies using CUDA.jl . You can manually add CUDA . Once CUDA is loaded you can move any array to the GPU with the cu function (or the gpu function exported by `Lux``), and it supports all of the above operations with the same syntax. # using CUDA # x = cu(rand(5, 3))","title":"CUDA Arrays"},{"location":"examples/generated/beginner/Basics/main/#immutability","text":"Lux as you might have read is Immutable by convention which means that the core library is built without any form of mutation and all functions are pure. However, we don't enforce it in any form. We do strongly recommend that users extending this framework for their respective applications don't mutate their arrays. x = reshape ( 1 : 8 , 2 , 4 ) 2\u00d74 reshape(::UnitRange{Int64}, 2, 4) with eltype Int64: 1 3 5 7 2 4 6 8 To update this array, we should first copy the array. x_copy = copy ( x ) view ( x_copy , : , 1 ) .= 0 println ( \"Original Array \" , x ) println ( \"Mutated Array \" , x_copy ) Original Array [1 3 5 7; 2 4 6 8] Mutated Array [0 3 5 7; 0 4 6 8] Note that our current default AD engine (Zygote) is unable to differentiate through this mutation, however, for these specialized cases it is quite trivial to write custom backward passes. (This problem will be fixed once we move towards Enzyme.jl)","title":"(Im)mutability"},{"location":"examples/generated/beginner/Basics/main/#managing-randomness","text":"We rely on the Julia StdLib Random for managing the randomness in our execution. First, we create an PRNG and seed it. rng = Random . default_rng () # Creates a Xoshiro PRNG Random . seed! ( rng , 0 ) Random.TaskLocalRNG() If we call any function that relies on rng and uses it via randn , rand , etc. rng will be mutated. As we have already established we care a lot about immutability, hence we should use Lux.replicate on PRNG before using them. First, let us run a random number generator 3 times with the replicate d rng. for i in 1 : 3 println ( \"Iteration $i \" , rand ( Lux . replicate ( rng ), 10 )) end Iteration 1 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 2 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 3 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] As expected we get the same output. We can remove the replicate call and we will get different outputs. for i in 1 : 3 println ( \"Iteration $i \" , rand ( rng , 10 )) end Iteration 1 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 2 [0.018743665453639813, 0.8601828553599953, 0.6556360448565952, 0.7746656838366666, 0.7817315740767116, 0.5553797706980106, 0.1261990389976131, 0.4488101521328277, 0.624383955429775, 0.05657739601024536] Iteration 3 [0.19597391412112541, 0.6830945313415872, 0.6776220912718907, 0.6456416023530093, 0.6340362477836592, 0.5595843665394066, 0.5675557670686644, 0.34351700231383653, 0.7237308297251812, 0.3691778381831775]","title":"Managing Randomness"},{"location":"examples/generated/beginner/Basics/main/#automatic-differentiation","text":"Julia has quite a few (maybe too many) AD tools. For the purpose of this tutorial, we will use AbstractDifferentiation.jl which provides a uniform API across multiple AD backends. For the backends we will use: ForwardDiff.jl \u2013 For Jacobian-Vector Product (JVP) Zygote.jl \u2013 For Vector-Jacobian Product (VJP) Slight Detour : We have had several questions regarding if we will be considering any other AD system for the reverse-diff backend. For now we will stick to Zygote.jl, however once Enzyme.jl has support for custom rules and we have tested Lux extensively with it, we will make the switch. Even though, theoretically, a VJP (Vector-Jacobian product - reverse autodiff) and a JVP (Jacobian-Vector product - forward-mode autodiff) are similar\u2014they compute a product of a Jacobian and a vector\u2014they differ by the computational complexity of the operation. In short, when you have a large number of parameters (hence a wide matrix), a JVP is less efficient computationally than a VJP, and, conversely, a JVP is more efficient when the Jacobian matrix is a tall matrix. using ForwardDiff , Zygote , AbstractDifferentiation","title":"Automatic Differentiation"},{"location":"examples/generated/beginner/Basics/main/#gradients","text":"For our first example, consider a simple function computing \\(f(x) = \\frac{1}{2}x^T x\\) , where \\(\\nabla f(x) = x\\) f ( x ) = x ' * x / 2 \u2207f ( x ) = x v = randn ( rng , Float32 , 4 ) 4-element Vector{Float32}: -0.4051151 -0.4593922 0.92155594 1.1871622 Let's use AbstractDifferentiation and Zygote to compute the gradients. println ( \"Actual Gradient: \" , \u2207f ( v )) println ( \"Computed Gradient via Reverse Mode AD (Zygote): \" , AD . gradient ( AD . ZygoteBackend (), f , v )[ 1 ]) println ( \"Computed Gradient via Forward Mode AD (ForwardDiff): \" , AD . gradient ( AD . ForwardDiffBackend (), f , v )[ 1 ]) Actual Gradient: Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Computed Gradient via Reverse Mode AD (Zygote): Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Computed Gradient via Forward Mode AD (ForwardDiff): Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Note that AD.gradient will only work for scalar valued outputs.","title":"Gradients"},{"location":"examples/generated/beginner/Basics/main/#jacobian-vector-product","text":"I will defer the discussion on forward-mode AD to https://book.sciml.ai/notes/08/ . Here let us just look at a mini example on how to use it. f ( x ) = x .* x ./ 2 x = randn ( rng , Float32 , 5 ) v = ones ( Float32 , 5 ) 5-element Vector{Float32}: 1.0 1.0 1.0 1.0 1.0 Construct the pushforward function. pf_f = AD . value_and_pushforward_function ( AD . ForwardDiffBackend (), f , x ) #17 (generic function with 1 method) Compute the jvp. val , jvp = pf_f ( v ) println ( \"Computed Value: f(\" , x , \") = \" , val ) println ( \"JVP: \" , jvp [ 1 ]) Computed Value: f(Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]) = Float32[0.3850005, 0.71437216, 0.0016247969, 0.031389393, 0.0043726736] JVP: Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]","title":"Jacobian-Vector Product"},{"location":"examples/generated/beginner/Basics/main/#vector-jacobian-product","text":"Using the same function and inputs, let us compute the VJP. pb_f = AD . value_and_pullback_function ( AD . ZygoteBackend (), f , x ) #25 (generic function with 1 method) Compute the vjp. val , vjp = pb_f ( v ) println ( \"Computed Value: f(\" , x , \") = \" , val ) println ( \"VJP: \" , vjp [ 1 ]) Computed Value: f(Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]) = Float32[0.3850005, 0.71437216, 0.0016247969, 0.031389393, 0.0043726736] VJP: Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]","title":"Vector-Jacobian Product"},{"location":"examples/generated/beginner/Basics/main/#linear-regression","text":"Finally, now let us consider a linear regression problem. From a set of data-points \\(\\left\\{ (x_i, y_i), i \\in \\left\\{ 1, \\dots, k \\right\\}, x_i \\in \\mathbb{R}^n, y_i \\in \\mathbb{R}^m \\right\\}\\) , we try to find a set of parameters \\(W\\) and \\(b\\) , s.t. \\(f_{W,b}(x) = Wx + b\\) , which minimizes the mean squared error: \\[ L(W, b) \\longrightarrow \\sum_{i = 1}^{k} \\frac{1}{2} \\| y_i - f_{W,b}(x_i) \\|_2^2 \\] We can write f from scratch, but to demonstrate Lux , let us use the Dense layer. model = Dense ( 10 => 5 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) Random.TaskLocalRNG() Let us initialize the parameters and states (in this case it is empty) for the model. ps , st = Lux . setup ( rng , model ) ps = ps |> Lux . ComponentArray ComponentVector{Float32}(weight = Float32[-0.5583162 0.3457679 \u2026 -0.35419345 0.039559156; -0.05661944 -0.4899126 \u2026 0.22614014 0.27704597; \u2026 ; 0.06026341 -0.11202827 \u2026 0.42526972 -0.3576447; 0.23414856 -0.5949539 \u2026 0.08254115 -0.5224755], bias = Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;]) Set problem dimensions. n_samples = 20 x_dim = 10 y_dim = 5 5 Generate random ground truth W and b. W = randn ( rng , Float32 , y_dim , x_dim ) b = randn ( rng , Float32 , y_dim ) 5-element Vector{Float32}: 0.68468636 -0.57578707 0.0594993 -0.9436797 1.5164032 Generate samples with additional noise. x_samples = randn ( rng , Float32 , x_dim , n_samples ) y_samples = W * x_samples .+ b .+ 0.01f0 .* randn ( rng , Float32 , y_dim , n_samples ) println ( \"x shape: \" , size ( x_samples ), \"; y shape: \" , size ( y_samples )) x shape: (10, 20); y shape: (5, 20) For updating our parameters let's use Optimisers.jl using Optimisers opt = Optimisers . Descent ( 0.01f0 ) Optimisers.Descent{Float32}(0.01f0) Initialize the initial state of the optimiser opt_state = Optimisers . setup ( opt , ps ) Leaf(Descent{Float32}(0.01), nothing) Define the loss function mse ( model , ps , st , X , y ) = sum ( abs2 , model ( X , ps , st )[ 1 ] .- y ) mse ( weight , bias , X , y ) = sum ( abs2 , weight * X .+ bias .- y ) loss_function ( ps , X , y ) = mse ( model , ps , st , X , y ) println ( \"Loss Value with ground true W & b: \" , mse ( W , b , x_samples , y_samples )) for i in 1 : 100 # In actual code, don't use globals. But here I will simply for the sake of demonstration global ps , st , opt_state # Compute the gradient gs = gradient ( loss_function , ps , x_samples , y_samples )[ 1 ] # Perform parameter update opt_state , ps = Optimisers . update ( opt_state , ps , gs ) if i % 10 == 1 || i == 100 println ( \"Loss Value after $i iterations: \" , mse ( model , ps , st , x_samples , y_samples )) end end Loss Value with ground true W & b: 0.009175307 Loss Value after 1 iterations: 165.57005 Loss Value after 11 iterations: 4.351237 Loss Value after 21 iterations: 0.6856849 Loss Value after 31 iterations: 0.15421417 Loss Value after 41 iterations: 0.041469414 Loss Value after 51 iterations: 0.014032223 Loss Value after 61 iterations: 0.006883738 Loss Value after 71 iterations: 0.004938521 Loss Value after 81 iterations: 0.004391277 Loss Value after 91 iterations: 0.0042331247 Loss Value after 100 iterations: 0.0041888584 This page was generated using Literate.jl .","title":"Linear Regression"},{"location":"examples/generated/beginner/SimpleRNN/main/","text":"Training a Simple LSTM \u00a4 In this tutorial we will go over using a recurrent neural network to classify clockwise and anticlockwise spirals. By the end of this tutorial you will be able to: Create custom Lux models. Become familiar with the Lux recurrent neural network API. Training using Optimisers.jl and Zygote.jl. Package Imports \u00a4 using Lux using MLUtils , Optimisers , Zygote , NNlib , Random , Statistics Activating project at `~/work/Lux.jl/Lux.jl/examples` Dataset \u00a4 We will use MLUtils to generate 500 (noisy) clockwise and 500 (noisy) anticlockwise spirals. Using this data we will create a MLUtils.DataLoader . Our dataloader will give us sequences of size 2 \u00d7 seq len \u00d7 batch size and we need to predict a binary value whether the sequence is clockwise or anticlockwise. function get_dataloaders (; dataset_size = 1000 , sequence_length = 50 ) # Create the spirals data = [ MLUtils . Datasets . make_spiral ( sequence_length ) for _ in 1 : dataset_size ] # Get the labels labels = vcat ( repeat ([ 0.0f0 ], dataset_size \u00f7 2 ), repeat ([ 1.0f0 ], dataset_size \u00f7 2 )) clockwise_spirals = [ reshape ( d [ 1 ][ : , 1 : sequence_length ], : , sequence_length , 1 ) for d in data [ 1 : ( dataset_size \u00f7 2 )]] anticlockwise_spirals = [ reshape ( d [ 1 ][ : , ( sequence_length + 1 ) : end ], : , sequence_length , 1 ) for d in data [(( dataset_size \u00f7 2 ) + 1 ) : end ]] x_data = Float32 . ( cat ( clockwise_spirals ... , anticlockwise_spirals ... ; dims = 3 )) # Split the dataset ( x_train , y_train ), ( x_val , y_val ) = splitobs (( x_data , labels ); at = 0.8 , shuffle = true ) # Create DataLoaders return ( # Use DataLoader to automatically minibatch and shuffle the data DataLoader ( collect . (( x_train , y_train )); batchsize = 128 , shuffle = true ), # Don't shuffle the validation data DataLoader ( collect . (( x_val , y_val )); batchsize = 128 , shuffle = false )) end get_dataloaders (generic function with 1 method) Creating a Classifier \u00a4 We will be extending the Lux.AbstractExplicitContainerLayer type for our custom model since it will contain a lstm block and a classifier head. We pass the fieldnames lstm_cell and classifier to the type to ensure that the parameters and states are automatically populated and we don't have to define Lux.initialparameters and Lux.initialstates . struct SpiralClassifier { L , C } <: Lux . AbstractExplicitContainerLayer {( :lstm_cell , :classifier )} lstm_cell :: L classifier :: C end We won't define the model from scratch but rather use the Lux.LSTMCell and Lux.Dense . function SpiralClassifier ( in_dims , hidden_dims , out_dims ) return SpiralClassifier ( LSTMCell ( in_dims => hidden_dims ), Dense ( hidden_dims => out_dims , sigmoid )) end Main.SpiralClassifier Now we need to define the behavior of the Classifier when it is invoked. function ( s :: SpiralClassifier )( x :: AbstractArray { T , 3 }, ps :: NamedTuple , st :: NamedTuple ) where { T } # First we will have to run the sequence through the LSTM Cell # The first call to LSTM Cell will create the initial hidden state # See that the parameters and states are automatically populated into a field called `lstm_cell` # We use `view(x, :, 1, :)` to get the first element in the sequence without copying it ( h , c ), st_lstm = s . lstm_cell ( view ( x , : , 1 , : ), ps . lstm_cell , st . lstm_cell ) # Now that we have the hidden state we will pass the input and hidden state jointly for i in 1 : size ( x , 2 ) ( h , c ), st_lstm = s . lstm_cell (( view ( x , : , i , : ), h , c ), ps . lstm_cell , st_lstm ) end # After running through the sequence we will pass the output through the classifier y , st_classifier = s . classifier ( h , ps . classifier , st . classifier ) # Finally remember to create the updated state st = merge ( st , ( classifier = st_classifier , lstm_cell = st_lstm )) return vec ( y ), st end Defining Accuracy, Loss and Optimiser \u00a4 Now let's define the binarycrossentropy loss. Typically it is recommended to use logitbinarycrossentropy since it is more numerically stable, but for the sake of simplicity we will use binarycrossentropy . function xlogy ( x , y ) result = x * log ( y ) return ifelse ( iszero ( x ), zero ( result ), result ) end function binarycrossentropy ( y_pred , y_true ) y_pred = y_pred .+ eps ( eltype ( y_pred )) return mean ( @. - xlogy ( y_true , y_pred ) - xlogy ( 1 - y_true , 1 - y_pred )) end function compute_loss ( x , y , model , ps , st ) y_pred , st = model ( x , ps , st ) return binarycrossentropy ( y_pred , y ), y_pred , st end matches ( y_pred , y_true ) = sum (( y_pred .> 0.5 ) .== y_true ) accuracy ( y_pred , y_true ) = matches ( y_pred , y_true ) / length ( y_pred ) accuracy (generic function with 1 method) Finally lets create an optimiser given the model parameters. function create_optimiser ( ps ) opt = Optimisers . ADAM ( 0.01f0 ) return Optimisers . setup ( opt , ps ) end create_optimiser (generic function with 1 method) Training the Model \u00a4 function main () # Get the dataloaders ( train_loader , val_loader ) = get_dataloaders () # Create the model model = SpiralClassifier ( 2 , 8 , 1 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , model ) # Create the optimiser opt_state = create_optimiser ( ps ) for epoch in 1 : 25 # Train the model for ( x , y ) in train_loader ( loss , y_pred , st ), back = pullback ( p -> compute_loss ( x , y , model , p , st ), ps ) gs = back (( one ( loss ), nothing , nothing ))[ 1 ] opt_state , ps = Optimisers . update ( opt_state , ps , gs ) println ( \"Epoch [ $epoch ]: Loss $loss \" ) end # Validate the model st_ = Lux . testmode ( st ) for ( x , y ) in val_loader ( loss , y_pred , st_ ) = compute_loss ( x , y , model , ps , st_ ) acc = accuracy ( y_pred , y ) println ( \"Validation: Loss $loss Accuracy $acc \" ) end end end main () Epoch [1]: Loss 0.56149215 Epoch [1]: Loss 0.5049322 Epoch [1]: Loss 0.4733414 Epoch [1]: Loss 0.44829383 Epoch [1]: Loss 0.43330282 Epoch [1]: Loss 0.40884122 Epoch [1]: Loss 0.3914853 Validation: Loss 0.3664357 Accuracy 1.0 Validation: Loss 0.37418374 Accuracy 1.0 Epoch [2]: Loss 0.35810766 Epoch [2]: Loss 0.3540123 Epoch [2]: Loss 0.34280917 Epoch [2]: Loss 0.31932044 Epoch [2]: Loss 0.2997916 Epoch [2]: Loss 0.2854032 Epoch [2]: Loss 0.27200705 Validation: Loss 0.25686264 Accuracy 1.0 Validation: Loss 0.26163238 Accuracy 1.0 Epoch [3]: Loss 0.25949377 Epoch [3]: Loss 0.24392252 Epoch [3]: Loss 0.23166673 Epoch [3]: Loss 0.22472435 Epoch [3]: Loss 0.2073102 Epoch [3]: Loss 0.19880316 Epoch [3]: Loss 0.1971015 Validation: Loss 0.17969233 Accuracy 1.0 Validation: Loss 0.18212943 Accuracy 1.0 Epoch [4]: Loss 0.18085611 Epoch [4]: Loss 0.17043296 Epoch [4]: Loss 0.16408414 Epoch [4]: Loss 0.15665922 Epoch [4]: Loss 0.14891377 Epoch [4]: Loss 0.14152783 Epoch [4]: Loss 0.13711959 Validation: Loss 0.12865403 Accuracy 1.0 Validation: Loss 0.13010187 Accuracy 1.0 Epoch [5]: Loss 0.12951379 Epoch [5]: Loss 0.12434522 Epoch [5]: Loss 0.11591287 Epoch [5]: Loss 0.113589324 Epoch [5]: Loss 0.10719822 Epoch [5]: Loss 0.10342899 Epoch [5]: Loss 0.09996706 Validation: Loss 0.093723565 Accuracy 1.0 Validation: Loss 0.095075384 Accuracy 1.0 Epoch [6]: Loss 0.09453923 Epoch [6]: Loss 0.09076261 Epoch [6]: Loss 0.085222095 Epoch [6]: Loss 0.08355893 Epoch [6]: Loss 0.07872702 Epoch [6]: Loss 0.07606817 Epoch [6]: Loss 0.07143451 Validation: Loss 0.06911983 Accuracy 1.0 Validation: Loss 0.07055579 Accuracy 1.0 Epoch [7]: Loss 0.07066438 Epoch [7]: Loss 0.0653572 Epoch [7]: Loss 0.06560714 Epoch [7]: Loss 0.06071301 Epoch [7]: Loss 0.05877301 Epoch [7]: Loss 0.055840574 Epoch [7]: Loss 0.054903653 Validation: Loss 0.05148246 Accuracy 1.0 Validation: Loss 0.052948043 Accuracy 1.0 Epoch [8]: Loss 0.05227324 Epoch [8]: Loss 0.049392566 Epoch [8]: Loss 0.047106378 Epoch [8]: Loss 0.046812233 Epoch [8]: Loss 0.04428931 Epoch [8]: Loss 0.042036746 Epoch [8]: Loss 0.04208009 Validation: Loss 0.03866339 Accuracy 1.0 Validation: Loss 0.040051356 Accuracy 1.0 Epoch [9]: Loss 0.039317697 Epoch [9]: Loss 0.03801973 Epoch [9]: Loss 0.035986874 Epoch [9]: Loss 0.034298975 Epoch [9]: Loss 0.03251428 Epoch [9]: Loss 0.032689683 Epoch [9]: Loss 0.03248937 Validation: Loss 0.029465735 Accuracy 1.0 Validation: Loss 0.03072252 Accuracy 1.0 Epoch [10]: Loss 0.030847818 Epoch [10]: Loss 0.028199043 Epoch [10]: Loss 0.027810697 Epoch [10]: Loss 0.027358858 Epoch [10]: Loss 0.026614796 Epoch [10]: Loss 0.023540251 Epoch [10]: Loss 0.02353118 Validation: Loss 0.023101198 Accuracy 1.0 Validation: Loss 0.024206156 Accuracy 1.0 Epoch [11]: Loss 0.025255984 Epoch [11]: Loss 0.021562638 Epoch [11]: Loss 0.020619325 Epoch [11]: Loss 0.021506941 Epoch [11]: Loss 0.02086537 Epoch [11]: Loss 0.02046011 Epoch [11]: Loss 0.020150391 Validation: Loss 0.01876291 Accuracy 1.0 Validation: Loss 0.019735087 Accuracy 1.0 Epoch [12]: Loss 0.019467236 Epoch [12]: Loss 0.01829698 Epoch [12]: Loss 0.017543327 Epoch [12]: Loss 0.017393213 Epoch [12]: Loss 0.01791834 Epoch [12]: Loss 0.01628229 Epoch [12]: Loss 0.017786933 Validation: Loss 0.015760783 Accuracy 1.0 Validation: Loss 0.016596798 Accuracy 1.0 Epoch [13]: Loss 0.016018657 Epoch [13]: Loss 0.015988274 Epoch [13]: Loss 0.016073942 Epoch [13]: Loss 0.014674229 Epoch [13]: Loss 0.013723777 Epoch [13]: Loss 0.015024222 Epoch [13]: Loss 0.0121259885 Validation: Loss 0.013574323 Accuracy 1.0 Validation: Loss 0.01431814 Accuracy 1.0 Epoch [14]: Loss 0.013762575 Epoch [14]: Loss 0.013576586 Epoch [14]: Loss 0.013685016 Epoch [14]: Loss 0.013587368 Epoch [14]: Loss 0.01199948 Epoch [14]: Loss 0.012414614 Epoch [14]: Loss 0.012820661 Validation: Loss 0.011961471 Accuracy 1.0 Validation: Loss 0.012629892 Accuracy 1.0 Epoch [15]: Loss 0.012100892 Epoch [15]: Loss 0.012052084 Epoch [15]: Loss 0.012009958 Epoch [15]: Loss 0.011165263 Epoch [15]: Loss 0.011827395 Epoch [15]: Loss 0.0110700615 Epoch [15]: Loss 0.010764804 Validation: Loss 0.0107108895 Accuracy 1.0 Validation: Loss 0.01130778 Accuracy 1.0 Epoch [16]: Loss 0.011075288 Epoch [16]: Loss 0.010561047 Epoch [16]: Loss 0.010730274 Epoch [16]: Loss 0.010405232 Epoch [16]: Loss 0.010295332 Epoch [16]: Loss 0.010239705 Epoch [16]: Loss 0.008787477 Validation: Loss 0.009679159 Accuracy 1.0 Validation: Loss 0.010235575 Accuracy 1.0 Epoch [17]: Loss 0.010150019 Epoch [17]: Loss 0.009025937 Epoch [17]: Loss 0.010305107 Epoch [17]: Loss 0.009451435 Epoch [17]: Loss 0.0087868245 Epoch [17]: Loss 0.0094613265 Epoch [17]: Loss 0.009145365 Validation: Loss 0.008837718 Accuracy 1.0 Validation: Loss 0.009345843 Accuracy 1.0 Epoch [18]: Loss 0.009202937 Epoch [18]: Loss 0.009076398 Epoch [18]: Loss 0.008618593 Epoch [18]: Loss 0.008942831 Epoch [18]: Loss 0.008269385 Epoch [18]: Loss 0.008285257 Epoch [18]: Loss 0.008135834 Validation: Loss 0.008113936 Accuracy 1.0 Validation: Loss 0.008590452 Accuracy 1.0 Epoch [19]: Loss 0.0085326275 Epoch [19]: Loss 0.00768314 Epoch [19]: Loss 0.00838451 Epoch [19]: Loss 0.00862549 Epoch [19]: Loss 0.0076436503 Epoch [19]: Loss 0.0076102773 Epoch [19]: Loss 0.0065414854 Validation: Loss 0.0074992427 Accuracy 1.0 Validation: Loss 0.0079396255 Accuracy 1.0 Epoch [20]: Loss 0.007730673 Epoch [20]: Loss 0.0077398075 Epoch [20]: Loss 0.0077788047 Epoch [20]: Loss 0.0074384087 Epoch [20]: Loss 0.0067550596 Epoch [20]: Loss 0.0070469957 Epoch [20]: Loss 0.0076075858 Validation: Loss 0.006959294 Accuracy 1.0 Validation: Loss 0.007375362 Accuracy 1.0 Epoch [21]: Loss 0.0076369494 Epoch [21]: Loss 0.0075168298 Epoch [21]: Loss 0.006784994 Epoch [21]: Loss 0.006654785 Epoch [21]: Loss 0.0058154385 Epoch [21]: Loss 0.006967115 Epoch [21]: Loss 0.0070822258 Validation: Loss 0.006485631 Accuracy 1.0 Validation: Loss 0.0068737883 Accuracy 1.0 Epoch [22]: Loss 0.006496721 Epoch [22]: Loss 0.006509331 Epoch [22]: Loss 0.0065430296 Epoch [22]: Loss 0.006421081 Epoch [22]: Loss 0.0061733024 Epoch [22]: Loss 0.0063228114 Epoch [22]: Loss 0.007062663 Validation: Loss 0.006065051 Accuracy 1.0 Validation: Loss 0.0064297775 Accuracy 1.0 Epoch [23]: Loss 0.0058548264 Epoch [23]: Loss 0.0063444655 Epoch [23]: Loss 0.0061396896 Epoch [23]: Loss 0.005889346 Epoch [23]: Loss 0.0060816044 Epoch [23]: Loss 0.0061780266 Epoch [23]: Loss 0.0047367197 Validation: Loss 0.0056867814 Accuracy 1.0 Validation: Loss 0.006031164 Accuracy 1.0 Epoch [24]: Loss 0.005546667 Epoch [24]: Loss 0.0057993727 Epoch [24]: Loss 0.005791782 Epoch [24]: Loss 0.0055120206 Epoch [24]: Loss 0.0055019194 Epoch [24]: Loss 0.0057529784 Epoch [24]: Loss 0.005866731 Validation: Loss 0.0053519555 Accuracy 1.0 Validation: Loss 0.0056774444 Accuracy 1.0 Epoch [25]: Loss 0.005498489 Epoch [25]: Loss 0.005672703 Epoch [25]: Loss 0.005231232 Epoch [25]: Loss 0.0050940597 Epoch [25]: Loss 0.005527608 Epoch [25]: Loss 0.004832496 Epoch [25]: Loss 0.0058748657 Validation: Loss 0.005047311 Accuracy 1.0 Validation: Loss 0.005354529 Accuracy 1.0 This page was generated using Literate.jl .","title":"Training a Simple LSTM"},{"location":"examples/generated/beginner/SimpleRNN/main/#training-a-simple-lstm","text":"In this tutorial we will go over using a recurrent neural network to classify clockwise and anticlockwise spirals. By the end of this tutorial you will be able to: Create custom Lux models. Become familiar with the Lux recurrent neural network API. Training using Optimisers.jl and Zygote.jl.","title":"Training a Simple LSTM"},{"location":"examples/generated/beginner/SimpleRNN/main/#package-imports","text":"using Lux using MLUtils , Optimisers , Zygote , NNlib , Random , Statistics Activating project at `~/work/Lux.jl/Lux.jl/examples`","title":"Package Imports"},{"location":"examples/generated/beginner/SimpleRNN/main/#dataset","text":"We will use MLUtils to generate 500 (noisy) clockwise and 500 (noisy) anticlockwise spirals. Using this data we will create a MLUtils.DataLoader . Our dataloader will give us sequences of size 2 \u00d7 seq len \u00d7 batch size and we need to predict a binary value whether the sequence is clockwise or anticlockwise. function get_dataloaders (; dataset_size = 1000 , sequence_length = 50 ) # Create the spirals data = [ MLUtils . Datasets . make_spiral ( sequence_length ) for _ in 1 : dataset_size ] # Get the labels labels = vcat ( repeat ([ 0.0f0 ], dataset_size \u00f7 2 ), repeat ([ 1.0f0 ], dataset_size \u00f7 2 )) clockwise_spirals = [ reshape ( d [ 1 ][ : , 1 : sequence_length ], : , sequence_length , 1 ) for d in data [ 1 : ( dataset_size \u00f7 2 )]] anticlockwise_spirals = [ reshape ( d [ 1 ][ : , ( sequence_length + 1 ) : end ], : , sequence_length , 1 ) for d in data [(( dataset_size \u00f7 2 ) + 1 ) : end ]] x_data = Float32 . ( cat ( clockwise_spirals ... , anticlockwise_spirals ... ; dims = 3 )) # Split the dataset ( x_train , y_train ), ( x_val , y_val ) = splitobs (( x_data , labels ); at = 0.8 , shuffle = true ) # Create DataLoaders return ( # Use DataLoader to automatically minibatch and shuffle the data DataLoader ( collect . (( x_train , y_train )); batchsize = 128 , shuffle = true ), # Don't shuffle the validation data DataLoader ( collect . (( x_val , y_val )); batchsize = 128 , shuffle = false )) end get_dataloaders (generic function with 1 method)","title":"Dataset"},{"location":"examples/generated/beginner/SimpleRNN/main/#creating-a-classifier","text":"We will be extending the Lux.AbstractExplicitContainerLayer type for our custom model since it will contain a lstm block and a classifier head. We pass the fieldnames lstm_cell and classifier to the type to ensure that the parameters and states are automatically populated and we don't have to define Lux.initialparameters and Lux.initialstates . struct SpiralClassifier { L , C } <: Lux . AbstractExplicitContainerLayer {( :lstm_cell , :classifier )} lstm_cell :: L classifier :: C end We won't define the model from scratch but rather use the Lux.LSTMCell and Lux.Dense . function SpiralClassifier ( in_dims , hidden_dims , out_dims ) return SpiralClassifier ( LSTMCell ( in_dims => hidden_dims ), Dense ( hidden_dims => out_dims , sigmoid )) end Main.SpiralClassifier Now we need to define the behavior of the Classifier when it is invoked. function ( s :: SpiralClassifier )( x :: AbstractArray { T , 3 }, ps :: NamedTuple , st :: NamedTuple ) where { T } # First we will have to run the sequence through the LSTM Cell # The first call to LSTM Cell will create the initial hidden state # See that the parameters and states are automatically populated into a field called `lstm_cell` # We use `view(x, :, 1, :)` to get the first element in the sequence without copying it ( h , c ), st_lstm = s . lstm_cell ( view ( x , : , 1 , : ), ps . lstm_cell , st . lstm_cell ) # Now that we have the hidden state we will pass the input and hidden state jointly for i in 1 : size ( x , 2 ) ( h , c ), st_lstm = s . lstm_cell (( view ( x , : , i , : ), h , c ), ps . lstm_cell , st_lstm ) end # After running through the sequence we will pass the output through the classifier y , st_classifier = s . classifier ( h , ps . classifier , st . classifier ) # Finally remember to create the updated state st = merge ( st , ( classifier = st_classifier , lstm_cell = st_lstm )) return vec ( y ), st end","title":"Creating a Classifier"},{"location":"examples/generated/beginner/SimpleRNN/main/#defining-accuracy-loss-and-optimiser","text":"Now let's define the binarycrossentropy loss. Typically it is recommended to use logitbinarycrossentropy since it is more numerically stable, but for the sake of simplicity we will use binarycrossentropy . function xlogy ( x , y ) result = x * log ( y ) return ifelse ( iszero ( x ), zero ( result ), result ) end function binarycrossentropy ( y_pred , y_true ) y_pred = y_pred .+ eps ( eltype ( y_pred )) return mean ( @. - xlogy ( y_true , y_pred ) - xlogy ( 1 - y_true , 1 - y_pred )) end function compute_loss ( x , y , model , ps , st ) y_pred , st = model ( x , ps , st ) return binarycrossentropy ( y_pred , y ), y_pred , st end matches ( y_pred , y_true ) = sum (( y_pred .> 0.5 ) .== y_true ) accuracy ( y_pred , y_true ) = matches ( y_pred , y_true ) / length ( y_pred ) accuracy (generic function with 1 method) Finally lets create an optimiser given the model parameters. function create_optimiser ( ps ) opt = Optimisers . ADAM ( 0.01f0 ) return Optimisers . setup ( opt , ps ) end create_optimiser (generic function with 1 method)","title":"Defining Accuracy, Loss and Optimiser"},{"location":"examples/generated/beginner/SimpleRNN/main/#training-the-model","text":"function main () # Get the dataloaders ( train_loader , val_loader ) = get_dataloaders () # Create the model model = SpiralClassifier ( 2 , 8 , 1 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , model ) # Create the optimiser opt_state = create_optimiser ( ps ) for epoch in 1 : 25 # Train the model for ( x , y ) in train_loader ( loss , y_pred , st ), back = pullback ( p -> compute_loss ( x , y , model , p , st ), ps ) gs = back (( one ( loss ), nothing , nothing ))[ 1 ] opt_state , ps = Optimisers . update ( opt_state , ps , gs ) println ( \"Epoch [ $epoch ]: Loss $loss \" ) end # Validate the model st_ = Lux . testmode ( st ) for ( x , y ) in val_loader ( loss , y_pred , st_ ) = compute_loss ( x , y , model , ps , st_ ) acc = accuracy ( y_pred , y ) println ( \"Validation: Loss $loss Accuracy $acc \" ) end end end main () Epoch [1]: Loss 0.56149215 Epoch [1]: Loss 0.5049322 Epoch [1]: Loss 0.4733414 Epoch [1]: Loss 0.44829383 Epoch [1]: Loss 0.43330282 Epoch [1]: Loss 0.40884122 Epoch [1]: Loss 0.3914853 Validation: Loss 0.3664357 Accuracy 1.0 Validation: Loss 0.37418374 Accuracy 1.0 Epoch [2]: Loss 0.35810766 Epoch [2]: Loss 0.3540123 Epoch [2]: Loss 0.34280917 Epoch [2]: Loss 0.31932044 Epoch [2]: Loss 0.2997916 Epoch [2]: Loss 0.2854032 Epoch [2]: Loss 0.27200705 Validation: Loss 0.25686264 Accuracy 1.0 Validation: Loss 0.26163238 Accuracy 1.0 Epoch [3]: Loss 0.25949377 Epoch [3]: Loss 0.24392252 Epoch [3]: Loss 0.23166673 Epoch [3]: Loss 0.22472435 Epoch [3]: Loss 0.2073102 Epoch [3]: Loss 0.19880316 Epoch [3]: Loss 0.1971015 Validation: Loss 0.17969233 Accuracy 1.0 Validation: Loss 0.18212943 Accuracy 1.0 Epoch [4]: Loss 0.18085611 Epoch [4]: Loss 0.17043296 Epoch [4]: Loss 0.16408414 Epoch [4]: Loss 0.15665922 Epoch [4]: Loss 0.14891377 Epoch [4]: Loss 0.14152783 Epoch [4]: Loss 0.13711959 Validation: Loss 0.12865403 Accuracy 1.0 Validation: Loss 0.13010187 Accuracy 1.0 Epoch [5]: Loss 0.12951379 Epoch [5]: Loss 0.12434522 Epoch [5]: Loss 0.11591287 Epoch [5]: Loss 0.113589324 Epoch [5]: Loss 0.10719822 Epoch [5]: Loss 0.10342899 Epoch [5]: Loss 0.09996706 Validation: Loss 0.093723565 Accuracy 1.0 Validation: Loss 0.095075384 Accuracy 1.0 Epoch [6]: Loss 0.09453923 Epoch [6]: Loss 0.09076261 Epoch [6]: Loss 0.085222095 Epoch [6]: Loss 0.08355893 Epoch [6]: Loss 0.07872702 Epoch [6]: Loss 0.07606817 Epoch [6]: Loss 0.07143451 Validation: Loss 0.06911983 Accuracy 1.0 Validation: Loss 0.07055579 Accuracy 1.0 Epoch [7]: Loss 0.07066438 Epoch [7]: Loss 0.0653572 Epoch [7]: Loss 0.06560714 Epoch [7]: Loss 0.06071301 Epoch [7]: Loss 0.05877301 Epoch [7]: Loss 0.055840574 Epoch [7]: Loss 0.054903653 Validation: Loss 0.05148246 Accuracy 1.0 Validation: Loss 0.052948043 Accuracy 1.0 Epoch [8]: Loss 0.05227324 Epoch [8]: Loss 0.049392566 Epoch [8]: Loss 0.047106378 Epoch [8]: Loss 0.046812233 Epoch [8]: Loss 0.04428931 Epoch [8]: Loss 0.042036746 Epoch [8]: Loss 0.04208009 Validation: Loss 0.03866339 Accuracy 1.0 Validation: Loss 0.040051356 Accuracy 1.0 Epoch [9]: Loss 0.039317697 Epoch [9]: Loss 0.03801973 Epoch [9]: Loss 0.035986874 Epoch [9]: Loss 0.034298975 Epoch [9]: Loss 0.03251428 Epoch [9]: Loss 0.032689683 Epoch [9]: Loss 0.03248937 Validation: Loss 0.029465735 Accuracy 1.0 Validation: Loss 0.03072252 Accuracy 1.0 Epoch [10]: Loss 0.030847818 Epoch [10]: Loss 0.028199043 Epoch [10]: Loss 0.027810697 Epoch [10]: Loss 0.027358858 Epoch [10]: Loss 0.026614796 Epoch [10]: Loss 0.023540251 Epoch [10]: Loss 0.02353118 Validation: Loss 0.023101198 Accuracy 1.0 Validation: Loss 0.024206156 Accuracy 1.0 Epoch [11]: Loss 0.025255984 Epoch [11]: Loss 0.021562638 Epoch [11]: Loss 0.020619325 Epoch [11]: Loss 0.021506941 Epoch [11]: Loss 0.02086537 Epoch [11]: Loss 0.02046011 Epoch [11]: Loss 0.020150391 Validation: Loss 0.01876291 Accuracy 1.0 Validation: Loss 0.019735087 Accuracy 1.0 Epoch [12]: Loss 0.019467236 Epoch [12]: Loss 0.01829698 Epoch [12]: Loss 0.017543327 Epoch [12]: Loss 0.017393213 Epoch [12]: Loss 0.01791834 Epoch [12]: Loss 0.01628229 Epoch [12]: Loss 0.017786933 Validation: Loss 0.015760783 Accuracy 1.0 Validation: Loss 0.016596798 Accuracy 1.0 Epoch [13]: Loss 0.016018657 Epoch [13]: Loss 0.015988274 Epoch [13]: Loss 0.016073942 Epoch [13]: Loss 0.014674229 Epoch [13]: Loss 0.013723777 Epoch [13]: Loss 0.015024222 Epoch [13]: Loss 0.0121259885 Validation: Loss 0.013574323 Accuracy 1.0 Validation: Loss 0.01431814 Accuracy 1.0 Epoch [14]: Loss 0.013762575 Epoch [14]: Loss 0.013576586 Epoch [14]: Loss 0.013685016 Epoch [14]: Loss 0.013587368 Epoch [14]: Loss 0.01199948 Epoch [14]: Loss 0.012414614 Epoch [14]: Loss 0.012820661 Validation: Loss 0.011961471 Accuracy 1.0 Validation: Loss 0.012629892 Accuracy 1.0 Epoch [15]: Loss 0.012100892 Epoch [15]: Loss 0.012052084 Epoch [15]: Loss 0.012009958 Epoch [15]: Loss 0.011165263 Epoch [15]: Loss 0.011827395 Epoch [15]: Loss 0.0110700615 Epoch [15]: Loss 0.010764804 Validation: Loss 0.0107108895 Accuracy 1.0 Validation: Loss 0.01130778 Accuracy 1.0 Epoch [16]: Loss 0.011075288 Epoch [16]: Loss 0.010561047 Epoch [16]: Loss 0.010730274 Epoch [16]: Loss 0.010405232 Epoch [16]: Loss 0.010295332 Epoch [16]: Loss 0.010239705 Epoch [16]: Loss 0.008787477 Validation: Loss 0.009679159 Accuracy 1.0 Validation: Loss 0.010235575 Accuracy 1.0 Epoch [17]: Loss 0.010150019 Epoch [17]: Loss 0.009025937 Epoch [17]: Loss 0.010305107 Epoch [17]: Loss 0.009451435 Epoch [17]: Loss 0.0087868245 Epoch [17]: Loss 0.0094613265 Epoch [17]: Loss 0.009145365 Validation: Loss 0.008837718 Accuracy 1.0 Validation: Loss 0.009345843 Accuracy 1.0 Epoch [18]: Loss 0.009202937 Epoch [18]: Loss 0.009076398 Epoch [18]: Loss 0.008618593 Epoch [18]: Loss 0.008942831 Epoch [18]: Loss 0.008269385 Epoch [18]: Loss 0.008285257 Epoch [18]: Loss 0.008135834 Validation: Loss 0.008113936 Accuracy 1.0 Validation: Loss 0.008590452 Accuracy 1.0 Epoch [19]: Loss 0.0085326275 Epoch [19]: Loss 0.00768314 Epoch [19]: Loss 0.00838451 Epoch [19]: Loss 0.00862549 Epoch [19]: Loss 0.0076436503 Epoch [19]: Loss 0.0076102773 Epoch [19]: Loss 0.0065414854 Validation: Loss 0.0074992427 Accuracy 1.0 Validation: Loss 0.0079396255 Accuracy 1.0 Epoch [20]: Loss 0.007730673 Epoch [20]: Loss 0.0077398075 Epoch [20]: Loss 0.0077788047 Epoch [20]: Loss 0.0074384087 Epoch [20]: Loss 0.0067550596 Epoch [20]: Loss 0.0070469957 Epoch [20]: Loss 0.0076075858 Validation: Loss 0.006959294 Accuracy 1.0 Validation: Loss 0.007375362 Accuracy 1.0 Epoch [21]: Loss 0.0076369494 Epoch [21]: Loss 0.0075168298 Epoch [21]: Loss 0.006784994 Epoch [21]: Loss 0.006654785 Epoch [21]: Loss 0.0058154385 Epoch [21]: Loss 0.006967115 Epoch [21]: Loss 0.0070822258 Validation: Loss 0.006485631 Accuracy 1.0 Validation: Loss 0.0068737883 Accuracy 1.0 Epoch [22]: Loss 0.006496721 Epoch [22]: Loss 0.006509331 Epoch [22]: Loss 0.0065430296 Epoch [22]: Loss 0.006421081 Epoch [22]: Loss 0.0061733024 Epoch [22]: Loss 0.0063228114 Epoch [22]: Loss 0.007062663 Validation: Loss 0.006065051 Accuracy 1.0 Validation: Loss 0.0064297775 Accuracy 1.0 Epoch [23]: Loss 0.0058548264 Epoch [23]: Loss 0.0063444655 Epoch [23]: Loss 0.0061396896 Epoch [23]: Loss 0.005889346 Epoch [23]: Loss 0.0060816044 Epoch [23]: Loss 0.0061780266 Epoch [23]: Loss 0.0047367197 Validation: Loss 0.0056867814 Accuracy 1.0 Validation: Loss 0.006031164 Accuracy 1.0 Epoch [24]: Loss 0.005546667 Epoch [24]: Loss 0.0057993727 Epoch [24]: Loss 0.005791782 Epoch [24]: Loss 0.0055120206 Epoch [24]: Loss 0.0055019194 Epoch [24]: Loss 0.0057529784 Epoch [24]: Loss 0.005866731 Validation: Loss 0.0053519555 Accuracy 1.0 Validation: Loss 0.0056774444 Accuracy 1.0 Epoch [25]: Loss 0.005498489 Epoch [25]: Loss 0.005672703 Epoch [25]: Loss 0.005231232 Epoch [25]: Loss 0.0050940597 Epoch [25]: Loss 0.005527608 Epoch [25]: Loss 0.004832496 Epoch [25]: Loss 0.0058748657 Validation: Loss 0.005047311 Accuracy 1.0 Validation: Loss 0.005354529 Accuracy 1.0 This page was generated using Literate.jl .","title":"Training the Model"},{"location":"examples/generated/intermediate/BayesianNN/main/","text":"Bayesian Neural Network \u00a4 We borrow this tutorial from the official Turing Docs . We will show how the explicit parameterization of Lux enables first-class composability with packages which expect flattened out parameter vectors. We will use Turing.jl with Lux.jl to implement implementing a classification algorithm. Lets start by importing the relevant libraries. # Import libraries using Lux using Turing , Plots , Random , ReverseDiff , NNlib , Functors # Hide sampling progress Turing . setprogress! ( false ); # Use reverse_diff due to the number of parameters in neural networks Turing . setadbackend ( :reversediff ) :reversediff Generating data \u00a4 Our goal here is to use a Bayesian neural network to classify points in an artificial dataset. The code below generates data points arranged in a box-like pattern and displays a graph of the dataset we'll be working with. # Number of points to generate N = 80 M = round ( Int , N / 4 ) rng = Random . default_rng () Random . seed! ( rng , 1234 ) # Generate artificial data x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; xt1s = Array ([[ x1s [ i ] + 0.5f0 ; x2s [ i ] + 0.5f0 ] for i in 1 : M ]) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; append! ( xt1s , Array ([[ x1s [ i ] - 5.0f0 ; x2s [ i ] - 5.0f0 ] for i in 1 : M ])) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; xt0s = Array ([[ x1s [ i ] + 0.5f0 ; x2s [ i ] - 5.0f0 ] for i in 1 : M ]) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; append! ( xt0s , Array ([[ x1s [ i ] - 5.0f0 ; x2s [ i ] + 0.5f0 ] for i in 1 : M ])) # Store all the data for later xs = [ xt1s ; xt0s ] ts = [ ones ( 2 * M ); zeros ( 2 * M )] # Plot data points function plot_data () x1 = first . ( xt1s ) y1 = last . ( xt1s ) x2 = first . ( xt0s ) y2 = last . ( xt0s ) plt = Plots . scatter ( x1 , y1 ; color = \"red\" , clim = ( 0 , 1 )) Plots . scatter! ( plt , x2 , y2 ; color = \"blue\" , clim = ( 0 , 1 )) return plt end plot_data () Building the Neural Network \u00a4 The next step is to define a feedforward neural network where we express our parameters as distributions, and not single points as with traditional neural networks. For this we will use Dense to define liner layers and compose them via Chain , both are neural network primitives from Lux . The network nn we will create will have two hidden layers with tanh activations and one output layer with sigmoid activation, as shown below. The nn is an instance that acts as a function and can take data, parameters and current state as inputs and output predictions. We will define distributions on the neural network parameters. # Construct a neural network using Lux nn = Chain ( Dense ( 2 , 3 , tanh ), Dense ( 3 , 2 , tanh ), Dense ( 2 , 1 , sigmoid )) # Initialize the model weights and state ps , st = Lux . setup ( rng , nn ) Lux . parameterlength ( nn ) # number of paraemters in NN 20 The probabilistic model specification below creates a parameters variable, which has IID normal variables. The parameters represents all parameters of our neural net (weights and biases). # Create a regularization term and a Gaussian prior variance term. alpha = 0.09 sig = sqrt ( 1.0 / alpha ) 3.3333333333333335 Construct named tuple from a sampled parameter vector. We could also use ComponentArrays here and simply broadcast to avoid doing this. But let's do it this way to avoid dependencies. function vector_to_parameters ( ps_new :: AbstractVector , ps :: NamedTuple ) @assert length ( ps_new ) == Lux . parameterlength ( ps ) i = 1 function get_ps ( x ) z = reshape ( view ( ps_new , i : ( i + length ( x ) - 1 )), size ( x )) i += length ( x ) return z end return fmap ( get_ps , ps ) end # Specify the probabilistic model. @model function bayes_nn ( xs , ts ) global st # Sample the parameters nparameters = Lux . parameterlength ( nn ) parameters ~ MvNormal ( zeros ( nparameters ), sig .* ones ( nparameters )) # Forward NN to make predictions preds , st = nn ( xs , vector_to_parameters ( parameters , ps ), st ) # Observe each prediction. for i in 1 : length ( ts ) ts [ i ] ~ Bernoulli ( preds [ i ]) end end bayes_nn (generic function with 2 methods) Inference can now be performed by calling sample. We use the HMC sampler here. # Perform inference. N = 5000 ch = sample ( bayes_nn ( hcat ( xs ... ), ts ), HMC ( 0.05 , 4 ), N ) Chains MCMC chain (5000\u00d729\u00d71 Array{Float64, 3}): Iterations = 1:1:5000 Number of chains = 1 Samples per chain = 5000 Wall duration = 127.79 seconds Compute duration = 127.79 seconds parameters = parameters[1], parameters[2], parameters[3], parameters[4], parameters[5], parameters[6], parameters[7], parameters[8], parameters[9], parameters[10], parameters[11], parameters[12], parameters[13], parameters[14], parameters[15], parameters[16], parameters[17], parameters[18], parameters[19], parameters[20] internals = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, step_size, nom_step_size Summary Statistics parameters mean std naive_se mcse ess rhat \u22ef Symbol Float64 Float64 Float64 Float64 Float64 Float64 \u22ef parameters[1] 1.4675 2.3083 0.0326 0.2693 11.7281 2.0767 \u22ef parameters[2] 5.5552 2.7594 0.0390 0.3231 12.4936 1.1899 \u22ef parameters[3] 0.0273 0.7531 0.0107 0.0774 18.6028 1.1024 \u22ef parameters[4] -1.8129 1.6025 0.0227 0.1796 15.6117 1.0448 \u22ef parameters[5] 0.7135 1.3562 0.0192 0.1557 13.5410 1.1842 \u22ef parameters[6] 4.7089 1.7599 0.0249 0.1976 18.8688 1.0080 \u22ef parameters[7] -5.0105 3.4342 0.0486 0.4005 12.7796 1.0072 \u22ef parameters[8] 0.1951 2.3736 0.0336 0.2763 12.0470 1.4253 \u22ef parameters[9] 0.8814 1.6137 0.0228 0.1798 19.0521 1.0278 \u22ef parameters[10] -0.9196 4.1529 0.0587 0.4896 10.7452 2.1730 \u22ef parameters[11] -0.0995 2.6126 0.0369 0.3022 12.2717 1.2131 \u22ef parameters[12] -2.0922 3.0141 0.0426 0.3552 11.4220 1.6551 \u22ef parameters[13] 4.3457 1.7685 0.0250 0.2022 14.9620 1.0385 \u22ef parameters[14] -2.9048 1.6752 0.0237 0.1877 15.8258 1.0980 \u22ef parameters[15] 2.1551 1.8145 0.0257 0.2082 13.7275 1.2178 \u22ef parameters[16] -3.2932 1.4081 0.0199 0.1561 19.8148 1.0165 \u22ef parameters[17] -3.4255 2.6896 0.0380 0.3158 12.6164 1.2372 \u22ef \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee \u22f1 1 column and 3 rows omitted Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% Symbol Float64 Float64 Float64 Float64 Float64 parameters[1] -2.8737 -0.2060 1.2397 3.2028 6.3763 parameters[2] 0.7006 3.3812 5.8509 7.5387 11.0436 parameters[3] -2.0910 -0.2111 0.1039 0.4571 1.0501 parameters[4] -5.8984 -2.5130 -1.6280 -0.7613 0.8443 parameters[5] -0.7348 -0.0564 0.4240 0.9659 5.2736 parameters[6] 1.6909 3.4942 4.5379 5.9346 8.2718 parameters[7] -11.1144 -7.4680 -5.2027 -2.8930 1.9571 parameters[8] -4.3334 -1.5037 0.2996 2.0048 4.4496 parameters[9] -1.9076 -0.1331 0.6428 1.7236 4.4656 parameters[10] -8.4372 -4.2836 0.1960 2.2765 5.9196 parameters[11] -5.1766 -1.7353 0.2017 1.6669 4.5451 parameters[12] -6.9702 -4.6678 -2.4274 0.6276 3.0518 parameters[13] 1.2283 3.0997 4.1223 5.5624 8.0027 parameters[14] -6.2349 -4.0604 -2.9481 -1.8547 0.5993 parameters[15] -1.9406 1.1370 2.4385 3.4656 5.0130 parameters[16] -5.6563 -4.2682 -3.5360 -2.4030 0.0173 parameters[17] -9.2556 -4.9700 -3.1804 -1.7896 1.5551 \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee 3 rows omitted Now we extract the parameter samples from the sampled chain as theta (this is of size 5000 x 20 where 5000 is the number of iterations and 20 is the number of parameters). We'll use these primarily to determine how good our model's classifier is. # Extract all weight and bias parameters. theta = MCMCChains . group ( ch , :parameters ) . value ; Prediction Visualization \u00a4 # A helper to run the nn through data `x` using parameters `theta` nn_forward ( x , theta ) = nn ( x , vector_to_parameters ( theta , ps ), st )[ 1 ] # Plot the data we have. plot_data () # Find the index that provided the highest log posterior in the chain. _ , i = findmax ( ch [ :lp ]) # Extract the max row value from i. i = i . I [ 1 ] # Plot the posterior distribution with a contour plot x1_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) x2_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) Z = [ nn_forward ([ x1 , x2 ], theta [ i , : ])[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ) The contour plot above shows that the MAP method is not too bad at classifying our data. Now we can visualize our predictions. \\[ p(\\tilde{x} | X, \\alpha) = \\int_{\\theta} p(\\tilde{x} | \\theta) p(\\theta | X, \\alpha) \\approx \\sum_{\\theta \\sim p(\\theta | X, \\alpha)}f_{\\theta}(\\tilde{x}) \\] The nn_predict function takes the average predicted value from a network parameterized by weights drawn from the MCMC chain. # Return the average predicted value across multiple weights. function nn_predict ( x , theta , num ) return mean ([ nn_forward ( x , view ( theta , i , : ))[ 1 ] for i in 1 : 10 : num ]) end nn_predict (generic function with 1 method) Next, we use the nn_predict function to predict the value at a sample of points where the x1 and x2 coordinates range between -6 and 6. As we can see below, we still have a satisfactory fit to our data, and more importantly, we can also see where the neural network is uncertain about its predictions much easier\u2013-those regions between cluster boundaries. Plot the average prediction. plot_data () n_end = 1500 x1_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) x2_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) Z = [ nn_predict ([ x1 , x2 ], theta , n_end )[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ) <polyline clip-path=\"url(#clip202)\" style=\"stroke:#f8c931; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\" 248.242,995.572 251.669,993.136 323.668,971.121 370.328,936.563 399.093,924.706 463.689,879.991 474.518,874.437 549.943,864.228 606.94,823.418 625.369,815.618 700.794,797.038 757.435,766.846 776.219,763.058 851.645,752.915 927.07,737.862 955.127,766.846 1002.5,814.962 1005.97,823.418 1024.16,879.991 1038.49,936.563 1057.52,993.136 1077.92,1027.06 1081.49,1049.71 1089.16,1106.28 1092,1162.85 1092.49,1219.43 1093.38,1276 1092.33,1332.57 1088.78,1389.14 1086.71,1445.72 \"/> Suppose we are interested in how the predictive power of our Bayesian neural network evolved between samples. In that case, the following graph displays an animation of the contour plot generated from the network weights in samples 1 to 1,000. # Number of iterations to plot. n_end = 1000 anim = @gif for i in 1 : n_end plot_data () Z = [ nn_forward ([ x1 , x2 ], theta [ i , : ])[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ; title = \"Iteration $i \" , clim = ( 0 , 1 )) end every 5 This page was generated using Literate.jl .","title":"Bayesian Neural Network"},{"location":"examples/generated/intermediate/BayesianNN/main/#bayesian-neural-network","text":"We borrow this tutorial from the official Turing Docs . We will show how the explicit parameterization of Lux enables first-class composability with packages which expect flattened out parameter vectors. We will use Turing.jl with Lux.jl to implement implementing a classification algorithm. Lets start by importing the relevant libraries. # Import libraries using Lux using Turing , Plots , Random , ReverseDiff , NNlib , Functors # Hide sampling progress Turing . setprogress! ( false ); # Use reverse_diff due to the number of parameters in neural networks Turing . setadbackend ( :reversediff ) :reversediff","title":"Bayesian Neural Network"},{"location":"examples/generated/intermediate/BayesianNN/main/#generating-data","text":"Our goal here is to use a Bayesian neural network to classify points in an artificial dataset. The code below generates data points arranged in a box-like pattern and displays a graph of the dataset we'll be working with. # Number of points to generate N = 80 M = round ( Int , N / 4 ) rng = Random . default_rng () Random . seed! ( rng , 1234 ) # Generate artificial data x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; xt1s = Array ([[ x1s [ i ] + 0.5f0 ; x2s [ i ] + 0.5f0 ] for i in 1 : M ]) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; append! ( xt1s , Array ([[ x1s [ i ] - 5.0f0 ; x2s [ i ] - 5.0f0 ] for i in 1 : M ])) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; xt0s = Array ([[ x1s [ i ] + 0.5f0 ; x2s [ i ] - 5.0f0 ] for i in 1 : M ]) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; append! ( xt0s , Array ([[ x1s [ i ] - 5.0f0 ; x2s [ i ] + 0.5f0 ] for i in 1 : M ])) # Store all the data for later xs = [ xt1s ; xt0s ] ts = [ ones ( 2 * M ); zeros ( 2 * M )] # Plot data points function plot_data () x1 = first . ( xt1s ) y1 = last . ( xt1s ) x2 = first . ( xt0s ) y2 = last . ( xt0s ) plt = Plots . scatter ( x1 , y1 ; color = \"red\" , clim = ( 0 , 1 )) Plots . scatter! ( plt , x2 , y2 ; color = \"blue\" , clim = ( 0 , 1 )) return plt end plot_data ()","title":"Generating data"},{"location":"examples/generated/intermediate/BayesianNN/main/#building-the-neural-network","text":"The next step is to define a feedforward neural network where we express our parameters as distributions, and not single points as with traditional neural networks. For this we will use Dense to define liner layers and compose them via Chain , both are neural network primitives from Lux . The network nn we will create will have two hidden layers with tanh activations and one output layer with sigmoid activation, as shown below. The nn is an instance that acts as a function and can take data, parameters and current state as inputs and output predictions. We will define distributions on the neural network parameters. # Construct a neural network using Lux nn = Chain ( Dense ( 2 , 3 , tanh ), Dense ( 3 , 2 , tanh ), Dense ( 2 , 1 , sigmoid )) # Initialize the model weights and state ps , st = Lux . setup ( rng , nn ) Lux . parameterlength ( nn ) # number of paraemters in NN 20 The probabilistic model specification below creates a parameters variable, which has IID normal variables. The parameters represents all parameters of our neural net (weights and biases). # Create a regularization term and a Gaussian prior variance term. alpha = 0.09 sig = sqrt ( 1.0 / alpha ) 3.3333333333333335 Construct named tuple from a sampled parameter vector. We could also use ComponentArrays here and simply broadcast to avoid doing this. But let's do it this way to avoid dependencies. function vector_to_parameters ( ps_new :: AbstractVector , ps :: NamedTuple ) @assert length ( ps_new ) == Lux . parameterlength ( ps ) i = 1 function get_ps ( x ) z = reshape ( view ( ps_new , i : ( i + length ( x ) - 1 )), size ( x )) i += length ( x ) return z end return fmap ( get_ps , ps ) end # Specify the probabilistic model. @model function bayes_nn ( xs , ts ) global st # Sample the parameters nparameters = Lux . parameterlength ( nn ) parameters ~ MvNormal ( zeros ( nparameters ), sig .* ones ( nparameters )) # Forward NN to make predictions preds , st = nn ( xs , vector_to_parameters ( parameters , ps ), st ) # Observe each prediction. for i in 1 : length ( ts ) ts [ i ] ~ Bernoulli ( preds [ i ]) end end bayes_nn (generic function with 2 methods) Inference can now be performed by calling sample. We use the HMC sampler here. # Perform inference. N = 5000 ch = sample ( bayes_nn ( hcat ( xs ... ), ts ), HMC ( 0.05 , 4 ), N ) Chains MCMC chain (5000\u00d729\u00d71 Array{Float64, 3}): Iterations = 1:1:5000 Number of chains = 1 Samples per chain = 5000 Wall duration = 127.79 seconds Compute duration = 127.79 seconds parameters = parameters[1], parameters[2], parameters[3], parameters[4], parameters[5], parameters[6], parameters[7], parameters[8], parameters[9], parameters[10], parameters[11], parameters[12], parameters[13], parameters[14], parameters[15], parameters[16], parameters[17], parameters[18], parameters[19], parameters[20] internals = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, step_size, nom_step_size Summary Statistics parameters mean std naive_se mcse ess rhat \u22ef Symbol Float64 Float64 Float64 Float64 Float64 Float64 \u22ef parameters[1] 1.4675 2.3083 0.0326 0.2693 11.7281 2.0767 \u22ef parameters[2] 5.5552 2.7594 0.0390 0.3231 12.4936 1.1899 \u22ef parameters[3] 0.0273 0.7531 0.0107 0.0774 18.6028 1.1024 \u22ef parameters[4] -1.8129 1.6025 0.0227 0.1796 15.6117 1.0448 \u22ef parameters[5] 0.7135 1.3562 0.0192 0.1557 13.5410 1.1842 \u22ef parameters[6] 4.7089 1.7599 0.0249 0.1976 18.8688 1.0080 \u22ef parameters[7] -5.0105 3.4342 0.0486 0.4005 12.7796 1.0072 \u22ef parameters[8] 0.1951 2.3736 0.0336 0.2763 12.0470 1.4253 \u22ef parameters[9] 0.8814 1.6137 0.0228 0.1798 19.0521 1.0278 \u22ef parameters[10] -0.9196 4.1529 0.0587 0.4896 10.7452 2.1730 \u22ef parameters[11] -0.0995 2.6126 0.0369 0.3022 12.2717 1.2131 \u22ef parameters[12] -2.0922 3.0141 0.0426 0.3552 11.4220 1.6551 \u22ef parameters[13] 4.3457 1.7685 0.0250 0.2022 14.9620 1.0385 \u22ef parameters[14] -2.9048 1.6752 0.0237 0.1877 15.8258 1.0980 \u22ef parameters[15] 2.1551 1.8145 0.0257 0.2082 13.7275 1.2178 \u22ef parameters[16] -3.2932 1.4081 0.0199 0.1561 19.8148 1.0165 \u22ef parameters[17] -3.4255 2.6896 0.0380 0.3158 12.6164 1.2372 \u22ef \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee \u22f1 1 column and 3 rows omitted Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% Symbol Float64 Float64 Float64 Float64 Float64 parameters[1] -2.8737 -0.2060 1.2397 3.2028 6.3763 parameters[2] 0.7006 3.3812 5.8509 7.5387 11.0436 parameters[3] -2.0910 -0.2111 0.1039 0.4571 1.0501 parameters[4] -5.8984 -2.5130 -1.6280 -0.7613 0.8443 parameters[5] -0.7348 -0.0564 0.4240 0.9659 5.2736 parameters[6] 1.6909 3.4942 4.5379 5.9346 8.2718 parameters[7] -11.1144 -7.4680 -5.2027 -2.8930 1.9571 parameters[8] -4.3334 -1.5037 0.2996 2.0048 4.4496 parameters[9] -1.9076 -0.1331 0.6428 1.7236 4.4656 parameters[10] -8.4372 -4.2836 0.1960 2.2765 5.9196 parameters[11] -5.1766 -1.7353 0.2017 1.6669 4.5451 parameters[12] -6.9702 -4.6678 -2.4274 0.6276 3.0518 parameters[13] 1.2283 3.0997 4.1223 5.5624 8.0027 parameters[14] -6.2349 -4.0604 -2.9481 -1.8547 0.5993 parameters[15] -1.9406 1.1370 2.4385 3.4656 5.0130 parameters[16] -5.6563 -4.2682 -3.5360 -2.4030 0.0173 parameters[17] -9.2556 -4.9700 -3.1804 -1.7896 1.5551 \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee 3 rows omitted Now we extract the parameter samples from the sampled chain as theta (this is of size 5000 x 20 where 5000 is the number of iterations and 20 is the number of parameters). We'll use these primarily to determine how good our model's classifier is. # Extract all weight and bias parameters. theta = MCMCChains . group ( ch , :parameters ) . value ;","title":"Building the Neural Network"},{"location":"examples/generated/intermediate/BayesianNN/main/#prediction-visualization","text":"# A helper to run the nn through data `x` using parameters `theta` nn_forward ( x , theta ) = nn ( x , vector_to_parameters ( theta , ps ), st )[ 1 ] # Plot the data we have. plot_data () # Find the index that provided the highest log posterior in the chain. _ , i = findmax ( ch [ :lp ]) # Extract the max row value from i. i = i . I [ 1 ] # Plot the posterior distribution with a contour plot x1_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) x2_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) Z = [ nn_forward ([ x1 , x2 ], theta [ i , : ])[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ) The contour plot above shows that the MAP method is not too bad at classifying our data. Now we can visualize our predictions. \\[ p(\\tilde{x} | X, \\alpha) = \\int_{\\theta} p(\\tilde{x} | \\theta) p(\\theta | X, \\alpha) \\approx \\sum_{\\theta \\sim p(\\theta | X, \\alpha)}f_{\\theta}(\\tilde{x}) \\] The nn_predict function takes the average predicted value from a network parameterized by weights drawn from the MCMC chain. # Return the average predicted value across multiple weights. function nn_predict ( x , theta , num ) return mean ([ nn_forward ( x , view ( theta , i , : ))[ 1 ] for i in 1 : 10 : num ]) end nn_predict (generic function with 1 method) Next, we use the nn_predict function to predict the value at a sample of points where the x1 and x2 coordinates range between -6 and 6. As we can see below, we still have a satisfactory fit to our data, and more importantly, we can also see where the neural network is uncertain about its predictions much easier\u2013-those regions between cluster boundaries. Plot the average prediction. plot_data () n_end = 1500 x1_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) x2_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) Z = [ nn_predict ([ x1 , x2 ], theta , n_end )[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ) <polyline clip-path=\"url(#clip202)\" style=\"stroke:#f8c931; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\" 248.242,995.572 251.669,993.136 323.668,971.121 370.328,936.563 399.093,924.706 463.689,879.991 474.518,874.437 549.943,864.228 606.94,823.418 625.369,815.618 700.794,797.038 757.435,766.846 776.219,763.058 851.645,752.915 927.07,737.862 955.127,766.846 1002.5,814.962 1005.97,823.418 1024.16,879.991 1038.49,936.563 1057.52,993.136 1077.92,1027.06 1081.49,1049.71 1089.16,1106.28 1092,1162.85 1092.49,1219.43 1093.38,1276 1092.33,1332.57 1088.78,1389.14 1086.71,1445.72 \"/> Suppose we are interested in how the predictive power of our Bayesian neural network evolved between samples. In that case, the following graph displays an animation of the contour plot generated from the network weights in samples 1 to 1,000. # Number of iterations to plot. n_end = 1000 anim = @gif for i in 1 : n_end plot_data () Z = [ nn_forward ([ x1 , x2 ], theta [ i , : ])[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ; title = \"Iteration $i \" , clim = ( 0 , 1 )) end every 5 This page was generated using Literate.jl .","title":"Prediction Visualization"},{"location":"examples/generated/intermediate/NeuralODE/main/","text":"MNIST Classification using Neural ODEs \u00a4 Package Imports \u00a4 using Lux using ComponentArrays , CUDA , DiffEqSensitivity , NNlib , Optimisers , OrdinaryDiffEq , Random , Statistics , Zygote import MLDatasets : MNIST import MLDataUtils : convertlabel , LabelEnc import MLUtils : DataLoader , splitobs CUDA . allowscalar ( false ) Activating project at `~/work/Lux.jl/Lux.jl/examples` Loading MNIST \u00a4 # Use MLDataUtils LabelEnc for natural onehot conversion function onehot ( labels_raw ) return convertlabel ( LabelEnc . OneOfK , labels_raw , LabelEnc . NativeLabels ( collect ( 0 : 9 ))) end function loadmnist ( batchsize , train_split ) # Load MNIST: Only 1500 for demonstration purposes N = 1500 imgs = MNIST . traintensor ( 1 : N ) labels_raw = MNIST . trainlabels ( 1 : N ) # Process images into (H,W,C,BS) batches x_data = Float32 . ( reshape ( imgs , size ( imgs , 1 ), size ( imgs , 2 ), 1 , size ( imgs , 3 ))) y_data = onehot ( labels_raw ) ( x_train , y_train ), ( x_test , y_test ) = splitobs (( x_data , y_data ); at = train_split ) return ( # Use DataLoader to automatically minibatch and shuffle the data DataLoader ( collect . (( x_train , y_train )); batchsize = batchsize , shuffle = true ), # Don't shuffle the test data DataLoader ( collect . (( x_test , y_test )); batchsize = batchsize , shuffle = false )) end loadmnist (generic function with 1 method) Define the Neural ODE Layer \u00a4 The NeuralODE is a ContainerLayer, which stores a model . The parameters and states of the NeuralODE are same as those of the underlying model. struct NeuralODE { M <: Lux . AbstractExplicitLayer , So , Se , T , K } <: Lux . AbstractExplicitContainerLayer {( :model ,)} model :: M solver :: So sensealg :: Se tspan :: T kwargs :: K end function NeuralODE ( model :: Lux . AbstractExplicitLayer ; solver = Tsit5 (), sensealg = InterpolatingAdjoint (; autojacvec = ZygoteVJP ()), tspan = ( 0.0f0 , 1.0f0 ), kwargs ... ) return NeuralODE ( model , solver , sensealg , tspan , kwargs ) end function ( n :: NeuralODE )( x , ps , st ) function dudt ( u , p , t ) u_ , st = n . model ( u , p , st ) return u_ end prob = ODEProblem { false }( ODEFunction { false }( dudt ), x , n . tspan , ps ) return solve ( prob , n . solver ; sensealg = n . sensealg , n . kwargs ... ), st end function diffeqsol_to_array ( x :: ODESolution { T , N , <: AbstractVector { <: CuArray }}) where { T , N } return dropdims ( gpu ( x ); dims = 3 ) end diffeqsol_to_array ( x :: ODESolution ) = dropdims ( Array ( x ); dims = 3 ) diffeqsol_to_array (generic function with 2 methods) Create and Initialize the Neural ODE Layer \u00a4 function create_model () # Construct the Neural ODE Model model = Chain ( FlattenLayer (), Dense ( 784 , 20 , tanh ), NeuralODE ( Chain ( Dense ( 20 , 10 , tanh ), Dense ( 10 , 10 , tanh ), Dense ( 10 , 20 , tanh )); save_everystep = false , reltol = 1.0f-3 , abstol = 1.0f-3 , save_start = false ), diffeqsol_to_array , Dense ( 20 , 10 )) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , model ) ps = ComponentArray ( ps ) |> gpu st = st |> gpu return model , ps , st end create_model (generic function with 1 method) Define Utility Functions \u00a4 get_class ( x ) = argmax . ( eachcol ( x )) logitcrossentropy ( y_pred , y ) = mean ( - sum ( y .* logsoftmax ( y_pred ); dims = 1 )) function loss ( x , y , model , ps , st ) y_pred , st = model ( x , ps , st ) return logitcrossentropy ( y_pred , y ), st end function accuracy ( model , ps , st , dataloader ) total_correct , total = 0 , 0 st = Lux . testmode ( st ) iterator = CUDA . functional () ? CuIterator ( dataloader ) : dataloader for ( x , y ) in iterator target_class = get_class ( cpu ( y )) predicted_class = get_class ( cpu ( model ( x , ps , st )[ 1 ])) total_correct += sum ( target_class .== predicted_class ) total += length ( target_class ) end return total_correct / total end accuracy (generic function with 1 method) Training \u00a4 function train () model , ps , st = create_model () # Training train_dataloader , test_dataloader = loadmnist ( 128 , 0.9 ) opt = Optimisers . ADAM ( 0.001f0 ) st_opt = Optimisers . setup ( opt , ps ) ### Warmup the Model img , lab = gpu ( train_dataloader . data [ 1 ][ : , : , : , 1 : 1 ]), gpu ( train_dataloader . data [ 2 ][ : , 1 : 1 ]) loss ( img , lab , model , ps , st ) ( l , _ ), back = pullback ( p -> loss ( img , lab , model , p , st ), ps ) back (( one ( l ), nothing )) ### Lets train the model nepochs = 9 for epoch in 1 : nepochs stime = time () iterator = CUDA . functional () ? CuIterator ( train_dataloader ) : train_dataloader for ( x , y ) in iterator ( l , _ ), back = pullback ( p -> loss ( x , y , model , p , st ), ps ) gs = back (( one ( l ), nothing ))[ 1 ] st_opt , ps = Optimisers . update ( st_opt , ps , gs ) end ttime = time () - stime println ( \"[ $epoch / $nepochs ] \\t Time $ ( round ( ttime ; digits = 2 )) s \\t Training Accuracy: \" * \" $ ( round ( accuracy ( model , ps , st , train_dataloader ) * 100 ; digits = 2 )) % \\t \" * \"Test Accuracy: $ ( round ( accuracy ( model , ps , st , test_dataloader ) * 100 ; digits = 2 )) %\" ) end end train () \u250c Info: The GPU function is being called but the GPU is not accessible. \u2502 Defaulting back to the CPU. (No action is required if you want \u2514 to run on the CPU). \u250c Warning: MNIST.traintensor() is deprecated, use `MNIST(split=:train).features` instead. \u2514 @ MLDatasets ~/.julia/packages/MLDatasets/eZ0Va/src/datasets/vision/mnist.jl:157 \u250c Warning: MNIST.trainlabels() is deprecated, use `MNIST(split=:train).targets` instead. \u2514 @ MLDatasets ~/.julia/packages/MLDatasets/eZ0Va/src/datasets/vision/mnist.jl:173 [1/9] Time 2.05s Training Accuracy: 51.7% Test Accuracy: 44.0% [2/9] Time 0.12s Training Accuracy: 71.04% Test Accuracy: 66.67% [3/9] Time 0.19s Training Accuracy: 78.07% Test Accuracy: 72.0% [4/9] Time 0.2s Training Accuracy: 79.93% Test Accuracy: 73.33% [5/9] Time 0.11s Training Accuracy: 82.89% Test Accuracy: 78.0% [6/9] Time 0.16s Training Accuracy: 84.52% Test Accuracy: 78.67% [7/9] Time 0.11s Training Accuracy: 85.78% Test Accuracy: 80.67% [8/9] Time 0.12s Training Accuracy: 86.81% Test Accuracy: 81.33% [9/9] Time 0.17s Training Accuracy: 87.48% Test Accuracy: 82.67% This page was generated using Literate.jl .","title":"MNIST Classification using NeuralODE"},{"location":"examples/generated/intermediate/NeuralODE/main/#mnist-classification-using-neural-odes","text":"","title":"MNIST Classification using Neural ODEs"},{"location":"examples/generated/intermediate/NeuralODE/main/#package-imports","text":"using Lux using ComponentArrays , CUDA , DiffEqSensitivity , NNlib , Optimisers , OrdinaryDiffEq , Random , Statistics , Zygote import MLDatasets : MNIST import MLDataUtils : convertlabel , LabelEnc import MLUtils : DataLoader , splitobs CUDA . allowscalar ( false ) Activating project at `~/work/Lux.jl/Lux.jl/examples`","title":"Package Imports"},{"location":"examples/generated/intermediate/NeuralODE/main/#loading-mnist","text":"# Use MLDataUtils LabelEnc for natural onehot conversion function onehot ( labels_raw ) return convertlabel ( LabelEnc . OneOfK , labels_raw , LabelEnc . NativeLabels ( collect ( 0 : 9 ))) end function loadmnist ( batchsize , train_split ) # Load MNIST: Only 1500 for demonstration purposes N = 1500 imgs = MNIST . traintensor ( 1 : N ) labels_raw = MNIST . trainlabels ( 1 : N ) # Process images into (H,W,C,BS) batches x_data = Float32 . ( reshape ( imgs , size ( imgs , 1 ), size ( imgs , 2 ), 1 , size ( imgs , 3 ))) y_data = onehot ( labels_raw ) ( x_train , y_train ), ( x_test , y_test ) = splitobs (( x_data , y_data ); at = train_split ) return ( # Use DataLoader to automatically minibatch and shuffle the data DataLoader ( collect . (( x_train , y_train )); batchsize = batchsize , shuffle = true ), # Don't shuffle the test data DataLoader ( collect . (( x_test , y_test )); batchsize = batchsize , shuffle = false )) end loadmnist (generic function with 1 method)","title":"Loading MNIST"},{"location":"examples/generated/intermediate/NeuralODE/main/#define-the-neural-ode-layer","text":"The NeuralODE is a ContainerLayer, which stores a model . The parameters and states of the NeuralODE are same as those of the underlying model. struct NeuralODE { M <: Lux . AbstractExplicitLayer , So , Se , T , K } <: Lux . AbstractExplicitContainerLayer {( :model ,)} model :: M solver :: So sensealg :: Se tspan :: T kwargs :: K end function NeuralODE ( model :: Lux . AbstractExplicitLayer ; solver = Tsit5 (), sensealg = InterpolatingAdjoint (; autojacvec = ZygoteVJP ()), tspan = ( 0.0f0 , 1.0f0 ), kwargs ... ) return NeuralODE ( model , solver , sensealg , tspan , kwargs ) end function ( n :: NeuralODE )( x , ps , st ) function dudt ( u , p , t ) u_ , st = n . model ( u , p , st ) return u_ end prob = ODEProblem { false }( ODEFunction { false }( dudt ), x , n . tspan , ps ) return solve ( prob , n . solver ; sensealg = n . sensealg , n . kwargs ... ), st end function diffeqsol_to_array ( x :: ODESolution { T , N , <: AbstractVector { <: CuArray }}) where { T , N } return dropdims ( gpu ( x ); dims = 3 ) end diffeqsol_to_array ( x :: ODESolution ) = dropdims ( Array ( x ); dims = 3 ) diffeqsol_to_array (generic function with 2 methods)","title":"Define the Neural ODE Layer"},{"location":"examples/generated/intermediate/NeuralODE/main/#create-and-initialize-the-neural-ode-layer","text":"function create_model () # Construct the Neural ODE Model model = Chain ( FlattenLayer (), Dense ( 784 , 20 , tanh ), NeuralODE ( Chain ( Dense ( 20 , 10 , tanh ), Dense ( 10 , 10 , tanh ), Dense ( 10 , 20 , tanh )); save_everystep = false , reltol = 1.0f-3 , abstol = 1.0f-3 , save_start = false ), diffeqsol_to_array , Dense ( 20 , 10 )) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , model ) ps = ComponentArray ( ps ) |> gpu st = st |> gpu return model , ps , st end create_model (generic function with 1 method)","title":"Create and Initialize the Neural ODE Layer"},{"location":"examples/generated/intermediate/NeuralODE/main/#define-utility-functions","text":"get_class ( x ) = argmax . ( eachcol ( x )) logitcrossentropy ( y_pred , y ) = mean ( - sum ( y .* logsoftmax ( y_pred ); dims = 1 )) function loss ( x , y , model , ps , st ) y_pred , st = model ( x , ps , st ) return logitcrossentropy ( y_pred , y ), st end function accuracy ( model , ps , st , dataloader ) total_correct , total = 0 , 0 st = Lux . testmode ( st ) iterator = CUDA . functional () ? CuIterator ( dataloader ) : dataloader for ( x , y ) in iterator target_class = get_class ( cpu ( y )) predicted_class = get_class ( cpu ( model ( x , ps , st )[ 1 ])) total_correct += sum ( target_class .== predicted_class ) total += length ( target_class ) end return total_correct / total end accuracy (generic function with 1 method)","title":"Define Utility Functions"},{"location":"examples/generated/intermediate/NeuralODE/main/#training","text":"function train () model , ps , st = create_model () # Training train_dataloader , test_dataloader = loadmnist ( 128 , 0.9 ) opt = Optimisers . ADAM ( 0.001f0 ) st_opt = Optimisers . setup ( opt , ps ) ### Warmup the Model img , lab = gpu ( train_dataloader . data [ 1 ][ : , : , : , 1 : 1 ]), gpu ( train_dataloader . data [ 2 ][ : , 1 : 1 ]) loss ( img , lab , model , ps , st ) ( l , _ ), back = pullback ( p -> loss ( img , lab , model , p , st ), ps ) back (( one ( l ), nothing )) ### Lets train the model nepochs = 9 for epoch in 1 : nepochs stime = time () iterator = CUDA . functional () ? CuIterator ( train_dataloader ) : train_dataloader for ( x , y ) in iterator ( l , _ ), back = pullback ( p -> loss ( x , y , model , p , st ), ps ) gs = back (( one ( l ), nothing ))[ 1 ] st_opt , ps = Optimisers . update ( st_opt , ps , gs ) end ttime = time () - stime println ( \"[ $epoch / $nepochs ] \\t Time $ ( round ( ttime ; digits = 2 )) s \\t Training Accuracy: \" * \" $ ( round ( accuracy ( model , ps , st , train_dataloader ) * 100 ; digits = 2 )) % \\t \" * \"Test Accuracy: $ ( round ( accuracy ( model , ps , st , test_dataloader ) * 100 ; digits = 2 )) %\" ) end end train () \u250c Info: The GPU function is being called but the GPU is not accessible. \u2502 Defaulting back to the CPU. (No action is required if you want \u2514 to run on the CPU). \u250c Warning: MNIST.traintensor() is deprecated, use `MNIST(split=:train).features` instead. \u2514 @ MLDatasets ~/.julia/packages/MLDatasets/eZ0Va/src/datasets/vision/mnist.jl:157 \u250c Warning: MNIST.trainlabels() is deprecated, use `MNIST(split=:train).targets` instead. \u2514 @ MLDatasets ~/.julia/packages/MLDatasets/eZ0Va/src/datasets/vision/mnist.jl:173 [1/9] Time 2.05s Training Accuracy: 51.7% Test Accuracy: 44.0% [2/9] Time 0.12s Training Accuracy: 71.04% Test Accuracy: 66.67% [3/9] Time 0.19s Training Accuracy: 78.07% Test Accuracy: 72.0% [4/9] Time 0.2s Training Accuracy: 79.93% Test Accuracy: 73.33% [5/9] Time 0.11s Training Accuracy: 82.89% Test Accuracy: 78.0% [6/9] Time 0.16s Training Accuracy: 84.52% Test Accuracy: 78.67% [7/9] Time 0.11s Training Accuracy: 85.78% Test Accuracy: 80.67% [8/9] Time 0.12s Training Accuracy: 86.81% Test Accuracy: 81.33% [9/9] Time 0.17s Training Accuracy: 87.48% Test Accuracy: 82.67% This page was generated using Literate.jl .","title":"Training"},{"location":"introduction/ecosystem/","text":"Ecosystem \u00a4 Frameworks extending Lux \u00a4 Boltz.jl \u2013 Prebuilt deep learning models for image classification tasks DeepEquilibriumNetworks.jl \u2013 Continuous and Discrete Deep Equilibrium Networks DiffEqFlux.jl \u2013 Neural Differential Equations, Continuous Normalizing Flows, etc. Extended Julia Ecosystem \u00a4 As you might have noticed we don't do much apart from Neural Networks. All other parts of the DL training/evaluation pipeline should be offloaded to: Automatic Differentiation \u00a4 Zygote.jl \u2013 Currently the default and recommended AD library Enzyme.jl \u2013 Experimental Support (but will most likely become the future default) ForwardDiff.jl \u2013 For forward mode AD support ReverseDiff.jl \u2013 Tape based reverse mode AD (mostly untested) Data Manipulation and Loading \u00a4 Augmentor.jl DataLoaders.jl Images.jl DataAugmentation.jl Distributed DataParallel Training \u00a4 FluxMPI.jl Neural Network Primitives \u00a4 NNlib.jl Optimisation \u00a4 Optimisers.jl ParameterSchedulers.jl Optimization.jl Parameter Manipulation \u00a4 Functors.jl Serialization \u00a4 Serialization.jl JLD2.jl Testing Utilities \u00a4 FiniteDifferences.jl \u2013 Finite Differencing. Useful for testing gradient correctness JET.jl Training Visualization & Logging \u00a4 Wandb.jl TensorBoardLogger.jl","title":"Ecosystem"},{"location":"introduction/ecosystem/#ecosystem","text":"","title":"Ecosystem"},{"location":"introduction/ecosystem/#frameworks-extending-lux","text":"Boltz.jl \u2013 Prebuilt deep learning models for image classification tasks DeepEquilibriumNetworks.jl \u2013 Continuous and Discrete Deep Equilibrium Networks DiffEqFlux.jl \u2013 Neural Differential Equations, Continuous Normalizing Flows, etc.","title":"Frameworks extending Lux"},{"location":"introduction/ecosystem/#extended-julia-ecosystem","text":"As you might have noticed we don't do much apart from Neural Networks. All other parts of the DL training/evaluation pipeline should be offloaded to:","title":"Extended Julia Ecosystem"},{"location":"introduction/ecosystem/#automatic-differentiation","text":"Zygote.jl \u2013 Currently the default and recommended AD library Enzyme.jl \u2013 Experimental Support (but will most likely become the future default) ForwardDiff.jl \u2013 For forward mode AD support ReverseDiff.jl \u2013 Tape based reverse mode AD (mostly untested)","title":"Automatic Differentiation"},{"location":"introduction/ecosystem/#data-manipulation-and-loading","text":"Augmentor.jl DataLoaders.jl Images.jl DataAugmentation.jl","title":"Data Manipulation and Loading"},{"location":"introduction/ecosystem/#distributed-dataparallel-training","text":"FluxMPI.jl","title":"Distributed DataParallel Training"},{"location":"introduction/ecosystem/#neural-network-primitives","text":"NNlib.jl","title":"Neural Network Primitives"},{"location":"introduction/ecosystem/#optimisation","text":"Optimisers.jl ParameterSchedulers.jl Optimization.jl","title":"Optimisation"},{"location":"introduction/ecosystem/#parameter-manipulation","text":"Functors.jl","title":"Parameter Manipulation"},{"location":"introduction/ecosystem/#serialization","text":"Serialization.jl JLD2.jl","title":"Serialization"},{"location":"introduction/ecosystem/#testing-utilities","text":"FiniteDifferences.jl \u2013 Finite Differencing. Useful for testing gradient correctness JET.jl","title":"Testing Utilities"},{"location":"introduction/ecosystem/#training-visualization-logging","text":"Wandb.jl TensorBoardLogger.jl","title":"Training Visualization &amp; Logging"},{"location":"introduction/overview/","text":"Why we wrote Lux? \u00a4 Julia already has quite a few well established Neural Network Frameworks \u2013 Flux & KNet . However, certain design elements \u2013 Coupled Model and Parameters & Internal Mutations \u2013 associated with these frameworks make them less compiler and user friendly. Making changes to address these problems in the respective frameworks would be too disruptive for users. Here comes in Lux : a neural network framework built completely using pure functions to make it both compiler and autodiff friendly. Design Principles \u00a4 Layers must be immutable \u2013 cannot store any parameter/state but rather store the information to construct them Layers are pure functions Layers return a Tuple containing the result and the updated state Given same inputs the outputs must be same \u2013 yes this must hold true even for stochastic functions. Randomness must be controlled using rng s passed in the state. Easily extensible Why use Lux over Flux? \u00a4 Neural Networks for SciML : For SciML Applications (Neural ODEs, Deep Equilibrium Models) solvers typically expect a monolithic parameter vector. Flux enables this via its destructure mechanism, but destructure comes with various edge cases and limitations . Lux forces users to make an explicit distinction between state variables and parameter variables to avoid these issues. Also, it comes battery-included for distributed training using FluxMPI.jl (I know :P the naming) Sensible display of Custom Layers \u2013 Ever wanted to see Pytorch like Network printouts or wondered how to extend the pretty printing of Flux's layers? Lux handles all of that by default. Truly immutable models - No unexpected internal mutations since all layers are implemented as pure functions. All layers are also deterministic given the parameters and state: if a layer is supposed to be stochastic (say Dropout ), the state must contain a seed which is then updated after the function call. Easy Parameter Manipulation \u2013 By separating parameter data and layer structures, Lux makes implementing WeightNorm , SpectralNorm , etc. downright trivial. Without this separation, it is much harder to pass such parameters around without mutations which AD systems don't like. Why not use Lux? \u00a4 Small Neural Networks on CPU \u2013 Lux is developed for training large neural networks. For smaller architectures, we recommend using SimpleChains.jl . Lux won't magically speed up your code (yet) \u2013 Lux shares the same backend with Flux and so if your primary desire to shift is driven by performance, you will be disappointed. Special Architecture Support \u2013 Unfortunately, we currently don't support Cloud TPUs and even AMD GPUs are not well tested. (We do plan to support these in the nearish future)","title":"All about Lux"},{"location":"introduction/overview/#why-we-wrote-lux","text":"Julia already has quite a few well established Neural Network Frameworks \u2013 Flux & KNet . However, certain design elements \u2013 Coupled Model and Parameters & Internal Mutations \u2013 associated with these frameworks make them less compiler and user friendly. Making changes to address these problems in the respective frameworks would be too disruptive for users. Here comes in Lux : a neural network framework built completely using pure functions to make it both compiler and autodiff friendly.","title":"Why we wrote Lux?"},{"location":"introduction/overview/#design-principles","text":"Layers must be immutable \u2013 cannot store any parameter/state but rather store the information to construct them Layers are pure functions Layers return a Tuple containing the result and the updated state Given same inputs the outputs must be same \u2013 yes this must hold true even for stochastic functions. Randomness must be controlled using rng s passed in the state. Easily extensible","title":"Design Principles"},{"location":"introduction/overview/#why-use-lux-over-flux","text":"Neural Networks for SciML : For SciML Applications (Neural ODEs, Deep Equilibrium Models) solvers typically expect a monolithic parameter vector. Flux enables this via its destructure mechanism, but destructure comes with various edge cases and limitations . Lux forces users to make an explicit distinction between state variables and parameter variables to avoid these issues. Also, it comes battery-included for distributed training using FluxMPI.jl (I know :P the naming) Sensible display of Custom Layers \u2013 Ever wanted to see Pytorch like Network printouts or wondered how to extend the pretty printing of Flux's layers? Lux handles all of that by default. Truly immutable models - No unexpected internal mutations since all layers are implemented as pure functions. All layers are also deterministic given the parameters and state: if a layer is supposed to be stochastic (say Dropout ), the state must contain a seed which is then updated after the function call. Easy Parameter Manipulation \u2013 By separating parameter data and layer structures, Lux makes implementing WeightNorm , SpectralNorm , etc. downright trivial. Without this separation, it is much harder to pass such parameters around without mutations which AD systems don't like.","title":"Why use Lux over Flux?"},{"location":"introduction/overview/#why-not-use-lux","text":"Small Neural Networks on CPU \u2013 Lux is developed for training large neural networks. For smaller architectures, we recommend using SimpleChains.jl . Lux won't magically speed up your code (yet) \u2013 Lux shares the same backend with Flux and so if your primary desire to shift is driven by performance, you will be disappointed. Special Architecture Support \u2013 Unfortunately, we currently don't support Cloud TPUs and even AMD GPUs are not well tested. (We do plan to support these in the nearish future)","title":"Why not use Lux?"},{"location":"lib/Boltz/","text":"Boltz \u26a1 \u00a4 Accelerate \u26a1 your ML research using pre-built Deep Learning Models with Lux. Installation \u00a4 using Pkg Pkg . add ( \"Boltz\" ) Getting Started \u00a4 using Boltz , Lux model , ps , st = resnet ( :resnet18 ; pretrained = true ) Classification Models \u00a4 MODEL NAME FUNCTION NAME PRETRAINED TOP 1 ACCURACY (%) TOP 5 ACCURACY (%) AlexNet alexnet :alexnet \u2705 54.48 77.72 ResNet resnet :resnet18 \u2705 68.08 88.44 ResNet resnet :resnet34 \u2705 72.13 90.91 ResNet resnet :resnet50 \u2705 74.55 92.36 ResNet resnet :resnet101 \u2705 74.81 92.36 ResNet resnet :resnet152 \u2705 77.63 93.84 VGG vgg :vgg11 \u2705 67.35 87.91 VGG vgg :vgg13 \u2705 68.40 88.48 VGG vgg :vgg16 \u2705 70.24 89.80 VGG vgg :vgg19 \u2705 71.09 90.27 VGG vgg :vgg11_bn \u2705 69.09 88.94 VGG vgg :vgg13_bn \u2705 69.66 89.49 VGG vgg :vgg16_bn \u2705 72.11 91.02 VGG vgg :vgg19_bn \u2705 72.95 91.32 ConvMixer convmixer :small \ud83d\udeab ConvMixer convmixer :base \ud83d\udeab ConvMixer convmixer :large \ud83d\udeab DenseNet densenet :densenet121 \ud83d\udeab DenseNet densenet :densenet161 \ud83d\udeab DenseNet densenet :densenet169 \ud83d\udeab DenseNet densenet :densenet201 \ud83d\udeab GoogleNet googlenet :googlenet \ud83d\udeab MobileNet mobilenet :mobilenet_v1 \ud83d\udeab MobileNet mobilenet :mobilenet_v2 \ud83d\udeab MobileNet mobilenet :mobilenet_v3_small \ud83d\udeab MobileNet mobilenet :mobilenet_v3_large \ud83d\udeab ResNeXT resnext :resnext50 \ud83d\udeab ResNeXT resnext :resnext101 \ud83d\udeab ResNeXT resnext :resnext152 \ud83d\udeab Vision Transformer vision_transformer :tiny \ud83d\udeab Vision Transformer vision_transformer :small \ud83d\udeab Vision Transformer vision_transformer :base \ud83d\udeab Vision Transformer vision_transformer :large \ud83d\udeab Vision Transformer vision_transformer :huge \ud83d\udeab Vision Transformer vision_transformer :giant \ud83d\udeab Vision Transformer vision_transformer :gigantic \ud83d\udeab These models can be created using <FUNCTION>(<NAME>; pretrained = <PRETRAINED>) . Preprocessing \u00a4 All the pretrained models require that the images be normalized with the parameters mean = [0.485f0, 0.456f0, 0.406f0] and std = [0.229f0, 0.224f0, 0.225f0] .","title":"Boltz.jl"},{"location":"lib/Boltz/#boltz","text":"Accelerate \u26a1 your ML research using pre-built Deep Learning Models with Lux.","title":"Boltz \u26a1"},{"location":"lib/Boltz/#installation","text":"using Pkg Pkg . add ( \"Boltz\" )","title":"Installation"},{"location":"lib/Boltz/#getting-started","text":"using Boltz , Lux model , ps , st = resnet ( :resnet18 ; pretrained = true )","title":"Getting Started"},{"location":"lib/Boltz/#classification-models","text":"MODEL NAME FUNCTION NAME PRETRAINED TOP 1 ACCURACY (%) TOP 5 ACCURACY (%) AlexNet alexnet :alexnet \u2705 54.48 77.72 ResNet resnet :resnet18 \u2705 68.08 88.44 ResNet resnet :resnet34 \u2705 72.13 90.91 ResNet resnet :resnet50 \u2705 74.55 92.36 ResNet resnet :resnet101 \u2705 74.81 92.36 ResNet resnet :resnet152 \u2705 77.63 93.84 VGG vgg :vgg11 \u2705 67.35 87.91 VGG vgg :vgg13 \u2705 68.40 88.48 VGG vgg :vgg16 \u2705 70.24 89.80 VGG vgg :vgg19 \u2705 71.09 90.27 VGG vgg :vgg11_bn \u2705 69.09 88.94 VGG vgg :vgg13_bn \u2705 69.66 89.49 VGG vgg :vgg16_bn \u2705 72.11 91.02 VGG vgg :vgg19_bn \u2705 72.95 91.32 ConvMixer convmixer :small \ud83d\udeab ConvMixer convmixer :base \ud83d\udeab ConvMixer convmixer :large \ud83d\udeab DenseNet densenet :densenet121 \ud83d\udeab DenseNet densenet :densenet161 \ud83d\udeab DenseNet densenet :densenet169 \ud83d\udeab DenseNet densenet :densenet201 \ud83d\udeab GoogleNet googlenet :googlenet \ud83d\udeab MobileNet mobilenet :mobilenet_v1 \ud83d\udeab MobileNet mobilenet :mobilenet_v2 \ud83d\udeab MobileNet mobilenet :mobilenet_v3_small \ud83d\udeab MobileNet mobilenet :mobilenet_v3_large \ud83d\udeab ResNeXT resnext :resnext50 \ud83d\udeab ResNeXT resnext :resnext101 \ud83d\udeab ResNeXT resnext :resnext152 \ud83d\udeab Vision Transformer vision_transformer :tiny \ud83d\udeab Vision Transformer vision_transformer :small \ud83d\udeab Vision Transformer vision_transformer :base \ud83d\udeab Vision Transformer vision_transformer :large \ud83d\udeab Vision Transformer vision_transformer :huge \ud83d\udeab Vision Transformer vision_transformer :giant \ud83d\udeab Vision Transformer vision_transformer :gigantic \ud83d\udeab These models can be created using <FUNCTION>(<NAME>; pretrained = <PRETRAINED>) .","title":"Classification Models"},{"location":"lib/Boltz/#preprocessing","text":"All the pretrained models require that the images be normalized with the parameters mean = [0.485f0, 0.456f0, 0.406f0] and std = [0.229f0, 0.224f0, 0.225f0] .","title":"Preprocessing"},{"location":"manual/interface/","text":"Lux Interface \u00a4 First let's set the expectations straight. Do you have to follow the interface? No . Should you follow it? Probably yes . Why? It provides the ability for frameworks built on top of Lux to be cross compatible. Additionally, any new functionality built into Lux, will just work for your framework. Warning The interface is optional for frameworks being developed independent of Lux. All functionality in the core library (and officially supported ones) must adhere to the interface Layer Interface \u00a4 Singular Layer \u00a4 If the layer doesn't contain any other Lux layer, then it is a Singular Layer . This means it should optionally subtype Lux.AbstractExplicitLayer but mandatorily define all the necessary functions mentioned in the docstrings. Consider a simplified version of Dense called Linear . First, setup the architectural details for this layer. Note, that the architecture doesn't contain any mutable structure like arrays. When in doubt, remember, once constructed a model architecture cannot change. Tip For people coming from Flux.jl background this might be weird. We recommend checking out the Flux to Lux migration guide first before proceeding. using Lux , Random struct Linear { F1 , F2 } <: Lux . AbstractExplicitLayer in_dims :: Int out_dims :: Int init_weight :: F1 init_bias :: F2 end function Linear ( in_dims :: Int , out_dims :: Int ; init_weight = Lux . glorot_uniform , init_bias = Lux . zeros32 ) return Linear { typeof ( init_weight ), typeof ( init_bias )}( in_dims , out_dims , init_weight , init_bias ) end l = Linear ( 2 , 4 ) Linear() Next, we need to implement functions which return the parameters and states for the layer. In case of Linear , the parameters are weight and bias while the states are empty. States become important when defining layers like BatchNorm , WeightNorm , etc. The recommended data structure for returning parameters is a NamedTuple, though anything satisfying the Parameter Interface is valid. function Lux . initialparameters ( rng :: AbstractRNG , l :: Linear ) return ( weight = l . init_weight ( rng , l . out_dims , l . in_dims ), bias = l . init_bias ( rng , l . out_dims , 1 )) end Lux . initialstates ( :: AbstractRNG , :: Linear ) = NamedTuple () You could also implement Lux.parameterlength and Lux.statelength to prevent wasteful reconstruction of the parameters and states. # This works println ( \"Parameter Length: \" , Lux . parameterlength ( l ), \"; State Length: \" , Lux . statelength ( l )) # But still recommened to define these Lux . parameterlength ( l :: Linear ) = l . out_dims * l . in_dims + l . out_dims Lux . statelength ( :: Linear ) = 0 Parameter Length: 12; State Length: 0 Tip You might notice that we don't pass in a PRNG for these functions. If your parameter length and/or state length depend on a random number generator, you should think really hard about what you are trying to do and why. Now, we need to define how the layer works. For this you make your layer a function with exactly 3 arguments \u2013 x the input, ps the parameters, and st the states. This function must return two things \u2013 y the output, and st_new the updated state. function ( l :: Linear )( x :: AbstractMatrix , ps , st :: NamedTuple ) y = ps . weight * x .+ ps . bias return y , st end Finally, let's run this layer. If you have made this far into the documentation, we don't feel you need a refresher on that. rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , l ) println ( \"Parameter Length: \" , Lux . parameterlength ( l ), \"; State Length: \" , Lux . statelength ( l )) x = randn ( rng , Float32 , 2 , 1 ) Lux . apply ( l , x , ps , st ) # or `l(x, ps, st)` (Float32[-0.15276335; 0.45325348; 1.0207279; 0.78226817;;], NamedTuple()) Container Layer \u00a4 If your layer comprises of other Lux layers, then it is a Container Layer . Note that you could treat it as a Singular Layer , and it is still fine. FWIW, if you cannot subtype your layer with Lux.AbstractExplicitContainerLayer then you should go down the Singular Layer route. But subtyping allows us to bypass some of these common definitions. Let us now define a layer, which is basically a composition of two linear layers. struct ComposedLinear { L1 , L2 } <: Lux . AbstractExplicitContainerLayer {( :linear_1 , :linear_2 )} linear_1 :: L1 linear_2 :: L2 end function ( cl :: ComposedLinear )( x :: AbstractMatrix , ps , st :: NamedTuple ) # To access the parameters and states for `linear_1` we do `ps.linear_1` and # `st.linear_1`. Similarly for `linear_2` y , st_l1 = cl . linear_1 ( x , ps . linear_1 , st . linear_1 ) y , st_l2 = cl . linear_2 ( y , ps . linear_2 , st . linear_2 ) # Finally, we need to return the new state which has the exact structure as `st` return y , ( linear_1 = st_l1 , linear_2 = st_l2 ) end Here, you will notice we have passed (:linear_1, :linear_2) to the supertype. It essentially informs the type that, <obj>.linear_1 and <obj>.linear_2 are Lux layers and we need to construct parameters and states for those. Let's construct these and see: model = ComposedLinear ( Linear ( 2 , 4 ), Linear ( 4 , 2 )) display ( model ) ps , st = Lux . setup ( rng , model ) println ( \"Parameters: \" , ps ) println ( \"States: \" , st ) println ( \"Parameter Length: \" , Lux . parameterlength ( model ), \"; State Length: \" , Lux . statelength ( model )) x = randn ( rng , Float32 , 2 , 1 ) Lux . apply ( model , x , ps , st ) # or `model(x, ps, st)` (Float32[1.3410565; 0.78000563;;], (linear_1 = NamedTuple(), linear_2 = NamedTuple())) Parameter Interface \u00a4 We accept any parameter type as long as we can fetch the parameters using getproperty(obj, :parameter_name) . This allows us to simulaneously support NamedTuple s and ComponentArray s. Let us go through a concrete example of what it means. Consider Dense which expects two parameters named weight and bias . Note If you are defining your own parameter type, it is your responsibility to make sure that it works with the AutoDiff System you are using. using Lux , Random d = Dense ( 2 , 3 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps_default , st = Lux . setup ( rng , d ) x = randn ( rng , Float32 , 2 , 1 ) println ( \"Result with `NamedTuple` parameters: \" , first ( d ( x , ps_default , st ))) Result with `NamedTuple` parameters: Float32[1.135916; 0.7668784; -1.0876652;;] Let, us define a custom paramter type with fields myweight and mybias but if we try to access weight we get back myweight , similar for bias . Warning This is for demonstrative purposes, don't try this at home! struct DenseLayerParameters { W , B } myweight :: W mybias :: B end function Base . getproperty ( ps :: DenseLayerParameters , x :: Symbol ) if x == :weight return getfield ( ps , :myweight ) elseif x == :bias return getfield ( ps , :mybias ) end return getfield ( ps , x ) end ps = DenseLayerParameters ( ps_default . weight , ps_default . bias ) println ( \"Result with `DenseLayerParameters` parameters: \" , first ( d ( x , ps , st ))) Result with `DenseLayerParameters` parameters: Float32[1.135916; 0.7668784; -1.0876652;;] The takeaway from this shouldn't be \u2013 lets define weird parameter types . Simply because you can do weird things like this doesn't mean you should, since it only leads to bugs. Instead this shows the flexibility you have for how your parameters can be structured. State Interface \u00a4 States are always type constrained to be NamedTuple . The structure of the input state must match that of the output state, i.e. keys(st_in) == keys(st_out) . This doesn't imply that types of the input and output state match. To generate efficient code, we often do dispatch on the state, for example, Dropout , BatchNorm , etc.","title":"Lux Interface"},{"location":"manual/interface/#lux-interface","text":"First let's set the expectations straight. Do you have to follow the interface? No . Should you follow it? Probably yes . Why? It provides the ability for frameworks built on top of Lux to be cross compatible. Additionally, any new functionality built into Lux, will just work for your framework. Warning The interface is optional for frameworks being developed independent of Lux. All functionality in the core library (and officially supported ones) must adhere to the interface","title":"Lux Interface"},{"location":"manual/interface/#layer-interface","text":"","title":"Layer Interface"},{"location":"manual/interface/#singular-layer","text":"If the layer doesn't contain any other Lux layer, then it is a Singular Layer . This means it should optionally subtype Lux.AbstractExplicitLayer but mandatorily define all the necessary functions mentioned in the docstrings. Consider a simplified version of Dense called Linear . First, setup the architectural details for this layer. Note, that the architecture doesn't contain any mutable structure like arrays. When in doubt, remember, once constructed a model architecture cannot change. Tip For people coming from Flux.jl background this might be weird. We recommend checking out the Flux to Lux migration guide first before proceeding. using Lux , Random struct Linear { F1 , F2 } <: Lux . AbstractExplicitLayer in_dims :: Int out_dims :: Int init_weight :: F1 init_bias :: F2 end function Linear ( in_dims :: Int , out_dims :: Int ; init_weight = Lux . glorot_uniform , init_bias = Lux . zeros32 ) return Linear { typeof ( init_weight ), typeof ( init_bias )}( in_dims , out_dims , init_weight , init_bias ) end l = Linear ( 2 , 4 ) Linear() Next, we need to implement functions which return the parameters and states for the layer. In case of Linear , the parameters are weight and bias while the states are empty. States become important when defining layers like BatchNorm , WeightNorm , etc. The recommended data structure for returning parameters is a NamedTuple, though anything satisfying the Parameter Interface is valid. function Lux . initialparameters ( rng :: AbstractRNG , l :: Linear ) return ( weight = l . init_weight ( rng , l . out_dims , l . in_dims ), bias = l . init_bias ( rng , l . out_dims , 1 )) end Lux . initialstates ( :: AbstractRNG , :: Linear ) = NamedTuple () You could also implement Lux.parameterlength and Lux.statelength to prevent wasteful reconstruction of the parameters and states. # This works println ( \"Parameter Length: \" , Lux . parameterlength ( l ), \"; State Length: \" , Lux . statelength ( l )) # But still recommened to define these Lux . parameterlength ( l :: Linear ) = l . out_dims * l . in_dims + l . out_dims Lux . statelength ( :: Linear ) = 0 Parameter Length: 12; State Length: 0 Tip You might notice that we don't pass in a PRNG for these functions. If your parameter length and/or state length depend on a random number generator, you should think really hard about what you are trying to do and why. Now, we need to define how the layer works. For this you make your layer a function with exactly 3 arguments \u2013 x the input, ps the parameters, and st the states. This function must return two things \u2013 y the output, and st_new the updated state. function ( l :: Linear )( x :: AbstractMatrix , ps , st :: NamedTuple ) y = ps . weight * x .+ ps . bias return y , st end Finally, let's run this layer. If you have made this far into the documentation, we don't feel you need a refresher on that. rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , l ) println ( \"Parameter Length: \" , Lux . parameterlength ( l ), \"; State Length: \" , Lux . statelength ( l )) x = randn ( rng , Float32 , 2 , 1 ) Lux . apply ( l , x , ps , st ) # or `l(x, ps, st)` (Float32[-0.15276335; 0.45325348; 1.0207279; 0.78226817;;], NamedTuple())","title":"Singular Layer"},{"location":"manual/interface/#container-layer","text":"If your layer comprises of other Lux layers, then it is a Container Layer . Note that you could treat it as a Singular Layer , and it is still fine. FWIW, if you cannot subtype your layer with Lux.AbstractExplicitContainerLayer then you should go down the Singular Layer route. But subtyping allows us to bypass some of these common definitions. Let us now define a layer, which is basically a composition of two linear layers. struct ComposedLinear { L1 , L2 } <: Lux . AbstractExplicitContainerLayer {( :linear_1 , :linear_2 )} linear_1 :: L1 linear_2 :: L2 end function ( cl :: ComposedLinear )( x :: AbstractMatrix , ps , st :: NamedTuple ) # To access the parameters and states for `linear_1` we do `ps.linear_1` and # `st.linear_1`. Similarly for `linear_2` y , st_l1 = cl . linear_1 ( x , ps . linear_1 , st . linear_1 ) y , st_l2 = cl . linear_2 ( y , ps . linear_2 , st . linear_2 ) # Finally, we need to return the new state which has the exact structure as `st` return y , ( linear_1 = st_l1 , linear_2 = st_l2 ) end Here, you will notice we have passed (:linear_1, :linear_2) to the supertype. It essentially informs the type that, <obj>.linear_1 and <obj>.linear_2 are Lux layers and we need to construct parameters and states for those. Let's construct these and see: model = ComposedLinear ( Linear ( 2 , 4 ), Linear ( 4 , 2 )) display ( model ) ps , st = Lux . setup ( rng , model ) println ( \"Parameters: \" , ps ) println ( \"States: \" , st ) println ( \"Parameter Length: \" , Lux . parameterlength ( model ), \"; State Length: \" , Lux . statelength ( model )) x = randn ( rng , Float32 , 2 , 1 ) Lux . apply ( model , x , ps , st ) # or `model(x, ps, st)` (Float32[1.3410565; 0.78000563;;], (linear_1 = NamedTuple(), linear_2 = NamedTuple()))","title":"Container Layer"},{"location":"manual/interface/#parameter-interface","text":"We accept any parameter type as long as we can fetch the parameters using getproperty(obj, :parameter_name) . This allows us to simulaneously support NamedTuple s and ComponentArray s. Let us go through a concrete example of what it means. Consider Dense which expects two parameters named weight and bias . Note If you are defining your own parameter type, it is your responsibility to make sure that it works with the AutoDiff System you are using. using Lux , Random d = Dense ( 2 , 3 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps_default , st = Lux . setup ( rng , d ) x = randn ( rng , Float32 , 2 , 1 ) println ( \"Result with `NamedTuple` parameters: \" , first ( d ( x , ps_default , st ))) Result with `NamedTuple` parameters: Float32[1.135916; 0.7668784; -1.0876652;;] Let, us define a custom paramter type with fields myweight and mybias but if we try to access weight we get back myweight , similar for bias . Warning This is for demonstrative purposes, don't try this at home! struct DenseLayerParameters { W , B } myweight :: W mybias :: B end function Base . getproperty ( ps :: DenseLayerParameters , x :: Symbol ) if x == :weight return getfield ( ps , :myweight ) elseif x == :bias return getfield ( ps , :mybias ) end return getfield ( ps , x ) end ps = DenseLayerParameters ( ps_default . weight , ps_default . bias ) println ( \"Result with `DenseLayerParameters` parameters: \" , first ( d ( x , ps , st ))) Result with `DenseLayerParameters` parameters: Float32[1.135916; 0.7668784; -1.0876652;;] The takeaway from this shouldn't be \u2013 lets define weird parameter types . Simply because you can do weird things like this doesn't mean you should, since it only leads to bugs. Instead this shows the flexibility you have for how your parameters can be structured.","title":"Parameter Interface"},{"location":"manual/interface/#state-interface","text":"States are always type constrained to be NamedTuple . The structure of the input state must match that of the output state, i.e. keys(st_in) == keys(st_out) . This doesn't imply that types of the input and output state match. To generate efficient code, we often do dispatch on the state, for example, Dropout , BatchNorm , etc.","title":"State Interface"},{"location":"manual/migrate_from_flux/","text":"Migrating from Flux to Lux \u00a4 For the core library layers like Dense , Conv , etc. we have intentionlly kept the API very similar to Flux. In most cases, replacing using Flux with using Lux should be enough to get you started. We cover the additional changes that you will have to make in the following example. Lux Flux using Lux , Random , NNlib , Zygote model = Chain ( Dense ( 2 => 4 ), BatchNorm ( 4 , relu ), Dense ( 4 => 2 )) rng = Random . default_rng () x = randn ( rng , Float32 , 2 , 4 ) ps , st = Lux . setup ( rng , model ) model ( x , ps , st ) gradient ( ps -> sum ( first ( model ( x , ps , st ))), ps ) using Flux , Random , NNlib , Zygote model = Chain ( Dense ( 2 => 4 ), BatchNorm ( 4 , relu ), Dense ( 4 => 2 )) rng = Random . default_rng () x = randn ( rng , Float32 , 2 , 4 ) model ( x ) gradient ( model -> sum ( model ( x )), model ) Implementing Custom Layers \u00a4 Flux and Lux operate under extremely different design philosophies regarding how layers should be implemented. A summary of the differences would be: Flux stores everything in a single struct and relies on Functors.@functor and Flux.trainable to distinguish between trainable and non-trainable parameters. Lux relies on the user to define Lux.initialparameters and Lux.initialstates to distinguish between trainable parameters (called \"parameters\") and non-trainable parameters (called \"states\"). Additionally Lux layers define the model architecture, hence device transfer utilities like gpu , cpu , etc. cannot be applied on Lux layers, instead they need to be applied on the parameters and states. Let's work through a concrete example to demonstrate this. We will implement a very simple layer that computes \\(A \\times B \\times x\\) where \\(A\\) is not trainable and \\(B\\) is trainable. Lux Flux using Lux , Random , NNlib , Zygote struct LuxLinear <: Lux . AbstractExplicitLayer init_A init_B end function LuxLinear ( A :: AbstractArray , B :: AbstractArray ) # Storing Arrays or any mutable structure inside a Lux Layer is not recommended # instead we will convert this to a function to perform lazy initialization return LuxLinear (() -> copy ( A ), () -> copy ( B )) end # `B` is a parameter Lux . initialparameters ( rng :: AbstractRNG , layer :: LuxLinear ) = ( B = layer . init_B (),) # `A` is a state Lux . initialstates ( rng :: AbstractRNG , layer :: LuxLinear ) = ( A = layer . init_A (),) ( l :: LuxLinear )( x , ps , st ) = st . A * ps . B * x , st using Flux , Random , NNlib , Zygote , Optimisers struct FluxLinear A B end # `A` is not trainable Optimisers . trainable ( f :: FluxLinear ) = ( B = f . B ,) # Needed so that both `A` and `B` can be transfered between devices Flux . @functor FluxLinear ( l :: FluxLinear )( x ) = l . A * l . B * x Now let us run the model. Lux Flux rng = Random . default_rng () model = LuxLinear ( randn ( rng , 2 , 4 ), randn ( rng , 4 , 2 )) x = randn ( rng , 2 , 1 ) ps , st = Lux . setup ( rng , model ) model ( x , ps , st ) gradient ( ps -> sum ( first ( model ( x , ps , st ))), ps ) rng = Random . default_rng () model = FluxLinear ( randn ( rng , 2 , 4 ), randn ( rng , 4 , 2 )) x = randn ( rng , 2 , 1 ) model ( x ) gradient ( model -> sum ( model ( x )), model ) To reiterate some of the important points: Don't store mutables like Arrays inside a Lux Layer. Parameters and States should be constructured inside the respective initial* functions. Certain Important Implementation Details \u00a4 Training/Inference Mode \u00a4 Flux supports a mode called :auto which automatically decides if the user is training the model or running inference. This is the default mode for Flux.BatchNorm , Flux.GroupNorm , Flux.Dropout , etc. Lux doesn't support this mode (specifically to keep code simple and do exactly what the user wants), hence our default mode is training . This can be changed using Lux.testmode . Can't access functions like relu , sigmoid , etc? \u00a4 Unlike Flux we don't reexport functionality from NNlib , all you need to do to fix this is add using NNlib . Missing some common layers from Flux \u00a4 Lux is a very new framework, as such we haven't implemented all Layers that are a part of Flux. We are tracking the missing features in this issue , and hope to have them implemented soon. If you really need those functionality check out the next section. Can we still use Flux Layers? \u00a4 We don't recommend this method, but here is a way to compose Flux with Lux. using Lux , NNlib , Random , Optimisers import Flux # Layer Implementation struct FluxCompatLayer { L , I } <: Lux . AbstractExplicitLayer layer :: L init_parameters :: I end function FluxCompatLayer ( flayer ) p , re = Optimisers . destructure ( flayer ) p_ = copy ( p ) return FluxCompatLayer ( re , () -> p_ ) end Lux . initialparameters ( rng :: AbstractRNG , l :: FluxCompatLayer ) = ( p = l . init_parameters (),) ( f :: FluxCompatLayer )( x , ps , st ) = f . layer ( ps . p )( x ), st # Running the model fmodel = Flux . Chain ( Flux . Dense ( 3 => 4 , relu ), Flux . Dense ( 4 => 1 )) lmodel = FluxCompatLayer ( fmodel ) rng = Random . default_rng () x = randn ( rng , 3 , 1 ) ps , st = Lux . setup ( rng , lmodel ) lmodel ( x , ps , st )[ 1 ] == fmodel ( x )","title":"Migrating from Flux to Lux"},{"location":"manual/migrate_from_flux/#migrating-from-flux-to-lux","text":"For the core library layers like Dense , Conv , etc. we have intentionlly kept the API very similar to Flux. In most cases, replacing using Flux with using Lux should be enough to get you started. We cover the additional changes that you will have to make in the following example. Lux Flux using Lux , Random , NNlib , Zygote model = Chain ( Dense ( 2 => 4 ), BatchNorm ( 4 , relu ), Dense ( 4 => 2 )) rng = Random . default_rng () x = randn ( rng , Float32 , 2 , 4 ) ps , st = Lux . setup ( rng , model ) model ( x , ps , st ) gradient ( ps -> sum ( first ( model ( x , ps , st ))), ps ) using Flux , Random , NNlib , Zygote model = Chain ( Dense ( 2 => 4 ), BatchNorm ( 4 , relu ), Dense ( 4 => 2 )) rng = Random . default_rng () x = randn ( rng , Float32 , 2 , 4 ) model ( x ) gradient ( model -> sum ( model ( x )), model )","title":"Migrating from Flux to Lux"},{"location":"manual/migrate_from_flux/#implementing-custom-layers","text":"Flux and Lux operate under extremely different design philosophies regarding how layers should be implemented. A summary of the differences would be: Flux stores everything in a single struct and relies on Functors.@functor and Flux.trainable to distinguish between trainable and non-trainable parameters. Lux relies on the user to define Lux.initialparameters and Lux.initialstates to distinguish between trainable parameters (called \"parameters\") and non-trainable parameters (called \"states\"). Additionally Lux layers define the model architecture, hence device transfer utilities like gpu , cpu , etc. cannot be applied on Lux layers, instead they need to be applied on the parameters and states. Let's work through a concrete example to demonstrate this. We will implement a very simple layer that computes \\(A \\times B \\times x\\) where \\(A\\) is not trainable and \\(B\\) is trainable. Lux Flux using Lux , Random , NNlib , Zygote struct LuxLinear <: Lux . AbstractExplicitLayer init_A init_B end function LuxLinear ( A :: AbstractArray , B :: AbstractArray ) # Storing Arrays or any mutable structure inside a Lux Layer is not recommended # instead we will convert this to a function to perform lazy initialization return LuxLinear (() -> copy ( A ), () -> copy ( B )) end # `B` is a parameter Lux . initialparameters ( rng :: AbstractRNG , layer :: LuxLinear ) = ( B = layer . init_B (),) # `A` is a state Lux . initialstates ( rng :: AbstractRNG , layer :: LuxLinear ) = ( A = layer . init_A (),) ( l :: LuxLinear )( x , ps , st ) = st . A * ps . B * x , st using Flux , Random , NNlib , Zygote , Optimisers struct FluxLinear A B end # `A` is not trainable Optimisers . trainable ( f :: FluxLinear ) = ( B = f . B ,) # Needed so that both `A` and `B` can be transfered between devices Flux . @functor FluxLinear ( l :: FluxLinear )( x ) = l . A * l . B * x Now let us run the model. Lux Flux rng = Random . default_rng () model = LuxLinear ( randn ( rng , 2 , 4 ), randn ( rng , 4 , 2 )) x = randn ( rng , 2 , 1 ) ps , st = Lux . setup ( rng , model ) model ( x , ps , st ) gradient ( ps -> sum ( first ( model ( x , ps , st ))), ps ) rng = Random . default_rng () model = FluxLinear ( randn ( rng , 2 , 4 ), randn ( rng , 4 , 2 )) x = randn ( rng , 2 , 1 ) model ( x ) gradient ( model -> sum ( model ( x )), model ) To reiterate some of the important points: Don't store mutables like Arrays inside a Lux Layer. Parameters and States should be constructured inside the respective initial* functions.","title":"Implementing Custom Layers"},{"location":"manual/migrate_from_flux/#certain-important-implementation-details","text":"","title":"Certain Important Implementation Details"},{"location":"manual/migrate_from_flux/#traininginference-mode","text":"Flux supports a mode called :auto which automatically decides if the user is training the model or running inference. This is the default mode for Flux.BatchNorm , Flux.GroupNorm , Flux.Dropout , etc. Lux doesn't support this mode (specifically to keep code simple and do exactly what the user wants), hence our default mode is training . This can be changed using Lux.testmode .","title":"Training/Inference Mode"},{"location":"manual/migrate_from_flux/#cant-access-functions-like-relu-sigmoid-etc","text":"Unlike Flux we don't reexport functionality from NNlib , all you need to do to fix this is add using NNlib .","title":"Can't access functions like relu, sigmoid, etc?"},{"location":"manual/migrate_from_flux/#missing-some-common-layers-from-flux","text":"Lux is a very new framework, as such we haven't implemented all Layers that are a part of Flux. We are tracking the missing features in this issue , and hope to have them implemented soon. If you really need those functionality check out the next section.","title":"Missing some common layers from Flux"},{"location":"manual/migrate_from_flux/#can-we-still-use-flux-layers","text":"We don't recommend this method, but here is a way to compose Flux with Lux. using Lux , NNlib , Random , Optimisers import Flux # Layer Implementation struct FluxCompatLayer { L , I } <: Lux . AbstractExplicitLayer layer :: L init_parameters :: I end function FluxCompatLayer ( flayer ) p , re = Optimisers . destructure ( flayer ) p_ = copy ( p ) return FluxCompatLayer ( re , () -> p_ ) end Lux . initialparameters ( rng :: AbstractRNG , l :: FluxCompatLayer ) = ( p = l . init_parameters (),) ( f :: FluxCompatLayer )( x , ps , st ) = f . layer ( ps . p )( x ), st # Running the model fmodel = Flux . Chain ( Flux . Dense ( 3 => 4 , relu ), Flux . Dense ( 4 => 1 )) lmodel = FluxCompatLayer ( fmodel ) rng = Random . default_rng () x = randn ( rng , 3 , 1 ) ps , st = Lux . setup ( rng , lmodel ) lmodel ( x , ps , st )[ 1 ] == fmodel ( x )","title":"Can we still use Flux Layers?"}]}